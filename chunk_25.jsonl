{"idx": 210204, "project": "linux", "commit_id": "cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "commit_message": "openvswitch: fix OOB access in reserve_sfa_size()\n\nGiven a sufficiently large number of actions, while copying and\nreserving memory for a new action of a new flow, if next_offset is\ngreater than MAX_ACTIONS_BUFSIZE, the function reserve_sfa_size() does\nnot return -EMSGSIZE as expected, but it allocates MAX_ACTIONS_BUFSIZE\nbytes increasing actions_len by req_size. This can then lead to an OOB\nwrite access, especially when further actions need to be copied.\n\nFix it by rearranging the flow action size check.\n\nKASAN splat below:\n\n==================================================================\nBUG: KASAN: slab-out-of-bounds in reserve_sfa_size+0x1ba/0x380 [openvswitch]\nWrite of size 65360 at addr ffff888147e4001c by task handler15/836\n\nCPU: 1 PID: 836 Comm: handler15 Not tainted 5.18.0-rc1+ #27\n...\nCall Trace:\n <TASK>\n dump_stack_lvl+0x45/0x5a\n print_report.cold+0x5e/0x5db\n ? __lock_text_start+0x8/0x8\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_report+0xb5/0x130\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_check_range+0xf5/0x1d0\n memcpy+0x39/0x60\n reserve_sfa_size+0x1ba/0x380 [openvswitch]\n __add_action+0x24/0x120 [openvswitch]\n ovs_nla_add_action+0xe/0x20 [openvswitch]\n ovs_ct_copy_action+0x29d/0x1130 [openvswitch]\n ? __kernel_text_address+0xe/0x30\n ? unwind_get_return_address+0x56/0xa0\n ? create_prof_cpu_mask+0x20/0x20\n ? ovs_ct_verify+0xf0/0xf0 [openvswitch]\n ? prep_compound_page+0x198/0x2a0\n ? __kasan_check_byte+0x10/0x40\n ? kasan_unpoison+0x40/0x70\n ? ksize+0x44/0x60\n ? reserve_sfa_size+0x75/0x380 [openvswitch]\n __ovs_nla_copy_actions+0xc26/0x2070 [openvswitch]\n ? __zone_watermark_ok+0x420/0x420\n ? validate_set.constprop.0+0xc90/0xc90 [openvswitch]\n ? __alloc_pages+0x1a9/0x3e0\n ? __alloc_pages_slowpath.constprop.0+0x1da0/0x1da0\n ? unwind_next_frame+0x991/0x1e40\n ? __mod_node_page_state+0x99/0x120\n ? __mod_lruvec_page_state+0x2e3/0x470\n ? __kasan_kmalloc_large+0x90/0xe0\n ovs_nla_copy_actions+0x1b4/0x2c0 [openvswitch]\n ovs_flow_cmd_new+0x3cd/0xb10 [openvswitch]\n ...\n\nCc: stable@vger.kernel.org\nFixes: f28cd2af22a0 (\"openvswitch: fix flow actions reallocation\")\nSigned-off-by: Paolo Valerio <pvalerio@redhat.com>\nAcked-by: Eelco Chaudron <echaudro@redhat.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "target": 1, "func": "static struct nlattr *reserve_sfa_size(struct sw_flow_actions **sfa,\n\t\t\t\t       int attr_len, bool log)\n{\n\n\tstruct sw_flow_actions *acts;\n\tint new_acts_size;\n\tsize_t req_size = NLA_ALIGN(attr_len);\n\tint next_offset = offsetof(struct sw_flow_actions, actions) +\n\t\t\t\t\t(*sfa)->actions_len;\n\n\tif (req_size <= (ksize(*sfa) - next_offset))\n\t\tgoto out;\n\n\tnew_acts_size = max(next_offset + req_size, ksize(*sfa) * 2);\n\n\tif (new_acts_size > MAX_ACTIONS_BUFSIZE) {\n\t\tif ((MAX_ACTIONS_BUFSIZE - next_offset) < req_size) {\n\t\t\tOVS_NLERR(log, \"Flow action size exceeds max %u\",\n\t\t\t\t  MAX_ACTIONS_BUFSIZE);\n\t\t\treturn ERR_PTR(-EMSGSIZE);\n\t\t}\n\t\tnew_acts_size = MAX_ACTIONS_BUFSIZE;\n\t}\n\n\tacts = nla_alloc_flow_actions(new_acts_size);\n\tif (IS_ERR(acts))\n\t\treturn (void *)acts;\n\n\tmemcpy(acts->actions, (*sfa)->actions, (*sfa)->actions_len);\n\tacts->actions_len = (*sfa)->actions_len;\n\tacts->orig_len = (*sfa)->orig_len;\n\tkfree(*sfa);\n\t*sfa = acts;\n\nout:\n\t(*sfa)->actions_len += req_size;\n\treturn  (struct nlattr *) ((unsigned char *)(*sfa) + next_offset);\n}", "func_hash": 66009891447134933026284929915758254537, "file_name": "flow_netlink.c", "file_hash": 47337588811900760055139247291202023489, "cwe": ["CWE-362"], "cve": "CVE-2022-2639", "cve_desc": "An integer coercion error was found in the openvswitch kernel module. Given a sufficiently large number of actions, while copying and reserving memory for a new action of a new flow, the reserve_sfa_size() function does not return -EMSGSIZE as expected, potentially leading to an out-of-bounds write access. This flaw allows a local user to crash or potentially escalate their privileges on the system.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2639", "file_path": "net/openvswitch/flow_netlink.c"}
{"idx": 430380, "project": "linux", "commit_id": "cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "commit_message": "openvswitch: fix OOB access in reserve_sfa_size()\n\nGiven a sufficiently large number of actions, while copying and\nreserving memory for a new action of a new flow, if next_offset is\ngreater than MAX_ACTIONS_BUFSIZE, the function reserve_sfa_size() does\nnot return -EMSGSIZE as expected, but it allocates MAX_ACTIONS_BUFSIZE\nbytes increasing actions_len by req_size. This can then lead to an OOB\nwrite access, especially when further actions need to be copied.\n\nFix it by rearranging the flow action size check.\n\nKASAN splat below:\n\n==================================================================\nBUG: KASAN: slab-out-of-bounds in reserve_sfa_size+0x1ba/0x380 [openvswitch]\nWrite of size 65360 at addr ffff888147e4001c by task handler15/836\n\nCPU: 1 PID: 836 Comm: handler15 Not tainted 5.18.0-rc1+ #27\n...\nCall Trace:\n <TASK>\n dump_stack_lvl+0x45/0x5a\n print_report.cold+0x5e/0x5db\n ? __lock_text_start+0x8/0x8\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_report+0xb5/0x130\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_check_range+0xf5/0x1d0\n memcpy+0x39/0x60\n reserve_sfa_size+0x1ba/0x380 [openvswitch]\n __add_action+0x24/0x120 [openvswitch]\n ovs_nla_add_action+0xe/0x20 [openvswitch]\n ovs_ct_copy_action+0x29d/0x1130 [openvswitch]\n ? __kernel_text_address+0xe/0x30\n ? unwind_get_return_address+0x56/0xa0\n ? create_prof_cpu_mask+0x20/0x20\n ? ovs_ct_verify+0xf0/0xf0 [openvswitch]\n ? prep_compound_page+0x198/0x2a0\n ? __kasan_check_byte+0x10/0x40\n ? kasan_unpoison+0x40/0x70\n ? ksize+0x44/0x60\n ? reserve_sfa_size+0x75/0x380 [openvswitch]\n __ovs_nla_copy_actions+0xc26/0x2070 [openvswitch]\n ? __zone_watermark_ok+0x420/0x420\n ? validate_set.constprop.0+0xc90/0xc90 [openvswitch]\n ? __alloc_pages+0x1a9/0x3e0\n ? __alloc_pages_slowpath.constprop.0+0x1da0/0x1da0\n ? unwind_next_frame+0x991/0x1e40\n ? __mod_node_page_state+0x99/0x120\n ? __mod_lruvec_page_state+0x2e3/0x470\n ? __kasan_kmalloc_large+0x90/0xe0\n ovs_nla_copy_actions+0x1b4/0x2c0 [openvswitch]\n ovs_flow_cmd_new+0x3cd/0xb10 [openvswitch]\n ...\n\nCc: stable@vger.kernel.org\nFixes: f28cd2af22a0 (\"openvswitch: fix flow actions reallocation\")\nSigned-off-by: Paolo Valerio <pvalerio@redhat.com>\nAcked-by: Eelco Chaudron <echaudro@redhat.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "target": 0, "func": "static struct nlattr *reserve_sfa_size(struct sw_flow_actions **sfa,\n\t\t\t\t       int attr_len, bool log)\n{\n\n\tstruct sw_flow_actions *acts;\n\tint new_acts_size;\n\tsize_t req_size = NLA_ALIGN(attr_len);\n\tint next_offset = offsetof(struct sw_flow_actions, actions) +\n\t\t\t\t\t(*sfa)->actions_len;\n\n\tif (req_size <= (ksize(*sfa) - next_offset))\n\t\tgoto out;\n\n\tnew_acts_size = max(next_offset + req_size, ksize(*sfa) * 2);\n\n\tif (new_acts_size > MAX_ACTIONS_BUFSIZE) {\n\t\tif ((next_offset + req_size) > MAX_ACTIONS_BUFSIZE) {\n\t\t\tOVS_NLERR(log, \"Flow action size exceeds max %u\",\n\t\t\t\t  MAX_ACTIONS_BUFSIZE);\n\t\t\treturn ERR_PTR(-EMSGSIZE);\n\t\t}\n\t\tnew_acts_size = MAX_ACTIONS_BUFSIZE;\n\t}\n\n\tacts = nla_alloc_flow_actions(new_acts_size);\n\tif (IS_ERR(acts))\n\t\treturn (void *)acts;\n\n\tmemcpy(acts->actions, (*sfa)->actions, (*sfa)->actions_len);\n\tacts->actions_len = (*sfa)->actions_len;\n\tacts->orig_len = (*sfa)->orig_len;\n\tkfree(*sfa);\n\t*sfa = acts;\n\nout:\n\t(*sfa)->actions_len += req_size;\n\treturn  (struct nlattr *) ((unsigned char *)(*sfa) + next_offset);\n}", "func_hash": 241955732354437165048790183048012619919, "file_name": "flow_netlink.c", "file_hash": 169733194668607707184956779941409309704, "cwe": ["CWE-362"], "cve": "CVE-2022-2639", "cve_desc": "An integer coercion error was found in the openvswitch kernel module. Given a sufficiently large number of actions, while copying and reserving memory for a new action of a new flow, the reserve_sfa_size() function does not return -EMSGSIZE as expected, potentially leading to an out-of-bounds write access. This flaw allows a local user to crash or potentially escalate their privileges on the system.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2639", "file_path": "net/openvswitch/flow_netlink.c"}
{"idx": 210206, "project": "squid", "commit_id": "780c4ea1b4c9d2fb41f6962aa6ed73ae57f74b2b", "project_url": "https://github.com/squid-cache/squid", "commit_url": "https://github.com/squid-cache/squid/commit/780c4ea1b4c9d2fb41f6962aa6ed73ae57f74b2b", "commit_message": "Improve handling of Gopher responses (#1022)", "target": 1, "func": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    String outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                    outbuf.append(tmpbuf);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n                }\n\n                outbuf.append(tmpbuf);\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    outbuf.append(tmpbuf);\n                    break;\n                }\n\n                }\n            }\n\n            }           /* HTML_CSO_RESULT */\n\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.size() > 0) {\n        entry->append(outbuf.rawBuf(), outbuf.size());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    outbuf.clean();\n    return;\n}", "func_hash": 69907744519047196773632287126924030666, "file_name": "gopher.cc", "file_hash": 274206304991379198598012995880144954128, "cwe": ["CWE-400"], "cve": "CVE-2021-46784", "cve_desc": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46784", "file_path": "src/gopher.cc"}
{"idx": 430470, "project": "squid", "commit_id": "780c4ea1b4c9d2fb41f6962aa6ed73ae57f74b2b", "project_url": "https://github.com/squid-cache/squid", "commit_url": "https://github.com/squid-cache/squid/commit/780c4ea1b4c9d2fb41f6962aa6ed73ae57f74b2b", "commit_message": "Improve handling of Gopher responses (#1022)", "target": 0, "func": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    SBuf outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                           icon_url, escaped_selector, rfc1738_escape_part(host),\n                                           *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                           icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                           port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                           icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                           icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                           icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    outbuf.appendf(\"%s\\n\", html_quote(result));\n                }\n\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    break;\n                }\n\n                }\n            }\n\n            }           /* HTML_CSO_RESULT */\n\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.length() > 0) {\n        entry->append(outbuf.rawContent(), outbuf.length());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    return;\n}", "func_hash": 138686742216343389129906256835749429816, "file_name": "gopher.cc", "file_hash": 39955176817113992488945748005868573997, "cwe": ["CWE-400"], "cve": "CVE-2021-46784", "cve_desc": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-46784", "file_path": "src/gopher.cc"}
{"idx": 210252, "project": "ImageMagick", "commit_id": "ca3654ebf7a439dc736f56f083c9aa98e4464b7f", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/ca3654ebf7a439dc736f56f083c9aa98e4464b7f", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/4988", "target": 1, "func": "static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define MonoColorType  1\n#define RGBColorType  3\n\n  char\n    property[MagickPathExtent];\n\n  CINInfo\n    cin;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  ssize_t\n    i;\n\n  Quantum\n    *q;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    magick[4],\n    *pixels;\n\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    File information.\n  */\n  offset=0;\n  count=ReadBlob(image,4,magick);\n  offset+=count;\n  if ((count != 4) ||\n      ((LocaleNCompare((char *) magick,\"\\200\\052\\137\\327\",4) != 0)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  memset(&cin,0,sizeof(cin));\n  image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n    (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n  cin.file.image_offset=ReadBlobLong(image);\n  offset+=4;\n  cin.file.generic_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.industry_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.user_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.file_size=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.file.version),(unsigned char *)\n    cin.file.version);\n  (void) CopyMagickString(property,cin.file.version,sizeof(cin.file.version));\n  (void) SetImageProperty(image,\"dpx:file.version\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.filename),(unsigned char *)\n    cin.file.filename);\n  (void) CopyMagickString(property,cin.file.filename,sizeof(cin.file.filename));\n  (void) SetImageProperty(image,\"dpx:file.filename\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.create_date),(unsigned char *)\n    cin.file.create_date);\n  (void) CopyMagickString(property,cin.file.create_date,\n    sizeof(cin.file.create_date));\n  (void) SetImageProperty(image,\"dpx:file.create_date\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.create_time),(unsigned char *)\n    cin.file.create_time);\n  (void) CopyMagickString(property,cin.file.create_time,\n    sizeof(cin.file.create_time));\n  (void) SetImageProperty(image,\"dpx:file.create_time\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.reserve),(unsigned char *)\n    cin.file.reserve);\n  /*\n    Image information.\n  */\n  cin.image.orientation=(unsigned char) ReadBlobByte(image);\n  offset++;\n  if (cin.image.orientation != (unsigned char) (~0))\n    (void) FormatImageProperty(image,\"dpx:image.orientation\",\"%d\",\n      cin.image.orientation);\n  switch (cin.image.orientation)\n  {\n    default:\n    case 0: image->orientation=TopLeftOrientation; break;\n    case 1: image->orientation=TopRightOrientation; break;\n    case 2: image->orientation=BottomLeftOrientation; break;\n    case 3: image->orientation=BottomRightOrientation; break;\n    case 4: image->orientation=LeftTopOrientation; break;\n    case 5: image->orientation=RightTopOrientation; break;\n    case 6: image->orientation=LeftBottomOrientation; break;\n    case 7: image->orientation=RightBottomOrientation; break;\n  }\n  cin.image.number_channels=(unsigned char) ReadBlobByte(image);\n  offset++;\n  offset+=ReadBlob(image,sizeof(cin.image.reserve1),(unsigned char *)\n    cin.image.reserve1);\n  for (i=0; i < 8; i++)\n  {\n    cin.image.channel[i].designator[0]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].designator[1]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].bits_per_pixel=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].reserve=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].pixels_per_line=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].lines_per_image=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].min_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].min_quantity=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_quantity=ReadBlobFloat(image);\n    offset+=4;\n  }\n  cin.image.white_point[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[0]) != MagickFalse)\n    image->chromaticity.white_point.x=cin.image.white_point[0];\n  cin.image.white_point[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[1]) != MagickFalse)\n    image->chromaticity.white_point.y=cin.image.white_point[1];\n  cin.image.red_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.red_primary_chromaticity[0];\n  cin.image.red_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.red_primary.y=cin.image.red_primary_chromaticity[1];\n  cin.image.green_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.green_primary_chromaticity[0];\n  cin.image.green_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.green_primary.y=cin.image.green_primary_chromaticity[1];\n  cin.image.blue_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.blue_primary.x=cin.image.blue_primary_chromaticity[0];\n  cin.image.blue_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.blue_primary.y=cin.image.blue_primary_chromaticity[1];\n  offset+=ReadBlob(image,sizeof(cin.image.label),(unsigned char *)\n    cin.image.label);\n  (void) CopyMagickString(property,cin.image.label,sizeof(cin.image.label));\n  (void) SetImageProperty(image,\"dpx:image.label\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.image.reserve),(unsigned char *)\n    cin.image.reserve);\n  /*\n    Image data format information.\n  */\n  cin.data_format.interleave=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.packing=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sign=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sense=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.line_pad=ReadBlobLong(image);\n  offset+=4;\n  cin.data_format.channel_pad=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.data_format.reserve),(unsigned char *)\n    cin.data_format.reserve);\n  /*\n    Image origination information.\n  */\n  cin.origination.x_offset=ReadBlobSignedLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.x_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.x_offset\",\"%.20g\",\n      (double) cin.origination.x_offset);\n  cin.origination.y_offset=(ssize_t) ReadBlobLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.y_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.y_offset\",\"%.20g\",\n      (double) cin.origination.y_offset);\n  offset+=ReadBlob(image,sizeof(cin.origination.filename),(unsigned char *)\n    cin.origination.filename);\n  (void) CopyMagickString(property,cin.origination.filename,\n    sizeof(cin.origination.filename));\n  (void) SetImageProperty(image,\"dpx:origination.filename\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_date),(unsigned char *)\n    cin.origination.create_date);\n  (void) CopyMagickString(property,cin.origination.create_date,\n    sizeof(cin.origination.create_date));\n  (void) SetImageProperty(image,\"dpx:origination.create_date\",property,\n    exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_time),(unsigned char *)\n    cin.origination.create_time);\n  (void) CopyMagickString(property,cin.origination.create_time,\n    sizeof(cin.origination.create_time));\n  (void) SetImageProperty(image,\"dpx:origination.create_time\",property,\n    exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.device),(unsigned char *)\n    cin.origination.device);\n  (void) CopyMagickString(property,cin.origination.device,\n    sizeof(cin.origination.device));\n  (void) SetImageProperty(image,\"dpx:origination.device\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.model),(unsigned char *)\n    cin.origination.model);\n  (void) CopyMagickString(property,cin.origination.model,\n    sizeof(cin.origination.model));\n  (void) SetImageProperty(image,\"dpx:origination.model\",property,exception);\n  (void) memset(cin.origination.serial,0, \n    sizeof(cin.origination.serial));\n  offset+=ReadBlob(image,sizeof(cin.origination.serial),(unsigned char *)\n    cin.origination.serial);\n  (void) CopyMagickString(property,cin.origination.serial,\n    sizeof(cin.origination.serial));\n  (void) SetImageProperty(image,\"dpx:origination.serial\",property,exception);\n  cin.origination.x_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.y_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.gamma=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.origination.gamma) != MagickFalse)\n    image->gamma=cin.origination.gamma;\n  offset+=ReadBlob(image,sizeof(cin.origination.reserve),(unsigned char *)\n    cin.origination.reserve);\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      int\n        c;\n\n      /*\n        Image film information.\n      */\n      cin.film.id=ReadBlobByte(image);\n      offset++;\n      c=cin.film.id;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.id\",\"%d\",cin.film.id);\n      cin.film.type=ReadBlobByte(image);\n      offset++;\n      c=cin.film.type;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.type\",\"%d\",cin.film.type);\n      cin.film.offset=ReadBlobByte(image);\n      offset++;\n      c=cin.film.offset;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.offset\",\"%d\",\n          cin.film.offset);\n      cin.film.reserve1=ReadBlobByte(image);\n      offset++;\n      cin.film.prefix=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.prefix != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.prefix\",\"%.20g\",(double)\n          cin.film.prefix);\n      cin.film.count=ReadBlobLong(image);\n      offset+=4;\n      offset+=ReadBlob(image,sizeof(cin.film.format),(unsigned char *)\n        cin.film.format);\n      (void) CopyMagickString(property,cin.film.format,sizeof(cin.film.format));\n      (void) SetImageProperty(image,\"dpx:film.format\",property,exception);\n      cin.film.frame_position=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.frame_position != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.frame_position\",\"%.20g\",\n          (double) cin.film.frame_position);\n      cin.film.frame_rate=ReadBlobFloat(image);\n      offset+=4;\n      if (IsFloatDefined(cin.film.frame_rate) != MagickFalse)\n        (void) FormatImageProperty(image,\"dpx:film.frame_rate\",\"%g\",\n          cin.film.frame_rate);\n      offset+=ReadBlob(image,sizeof(cin.film.frame_id),(unsigned char *)\n        cin.film.frame_id);\n      (void) CopyMagickString(property,cin.film.frame_id,\n        sizeof(cin.film.frame_id));\n      (void) SetImageProperty(image,\"dpx:film.frame_id\",property,exception);\n      offset+=ReadBlob(image,sizeof(cin.film.slate_info),(unsigned char *)\n        cin.film.slate_info);\n      (void) CopyMagickString(property,cin.film.slate_info,\n        sizeof(cin.film.slate_info));\n      (void) SetImageProperty(image,\"dpx:film.slate_info\",property,exception);\n      offset+=ReadBlob(image,sizeof(cin.film.reserve),(unsigned char *)\n        cin.film.reserve);\n    }\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      StringInfo\n        *profile;\n\n      /*\n        User defined data.\n      */\n      if (cin.file.user_length > GetBlobSize(image))\n        ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n      profile=BlobToStringInfo((const unsigned char *) NULL,\n        cin.file.user_length);\n      if (profile == (StringInfo *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      offset+=ReadBlob(image,GetStringInfoLength(profile),\n        GetStringInfoDatum(profile));\n      (void) SetImageProfile(image,\"dpx:user.data\",profile,exception);\n      profile=DestroyStringInfo(profile);\n    }\n  image->depth=cin.image.channel[0].bits_per_pixel;\n  image->columns=cin.image.channel[0].pixels_per_line;\n  image->rows=cin.image.channel[0].lines_per_image;\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(image);\n    }\n  if (((MagickSizeType) image->columns*image->rows/8) > GetBlobSize(image))\n    ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n  for ( ; offset < (MagickOffsetType) cin.file.image_offset; offset++)\n  {\n    int\n      c;\n\n    c=ReadBlobByte(image);\n    if (c == EOF)\n      break;\n  }\n  if (offset < (MagickOffsetType) cin.file.image_offset)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  (void) SetImageBackgroundColor(image,exception);\n  /*\n    Convert CIN raster image to pixel packets.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  SetQuantumQuantum(quantum_info,32);\n  SetQuantumPack(quantum_info,MagickFalse);\n  quantum_type=RGBQuantum;\n  length=GetBytesPerRow(image->columns,3,image->depth,MagickTrue);\n  if (cin.image.number_channels == 1)\n    {\n      quantum_type=GrayQuantum;\n      length=GetBytesPerRow(image->columns,1,image->depth,MagickTrue);\n    }\n  status=SetQuantumPad(image,quantum_info,0);\n  pixels=GetQuantumPixels(quantum_info);\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const void\n      *stream;\n\n    q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n    if (q == (Quantum *) NULL)\n      break;\n    stream=ReadBlobStream(image,length,pixels,&count);\n    if ((size_t) count != length)\n      break;\n    (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n      quantum_type,(unsigned char *) stream,exception);\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n    if (image->previous == (Image *) NULL)\n      {\n        status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n          image->rows);\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  SetQuantumImageType(image,quantum_type);\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  SetImageColorspace(image,LogColorspace,exception);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_hash": 84114525283902179205757998475769488689, "file_name": "cin.c", "file_hash": 147300579133514318841291345997162565785, "cwe": ["CWE-787"], "cve": "CVE-2022-28463", "cve_desc": "ImageMagick 7.1.0-27 is vulnerable to Buffer Overflow.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-28463", "file_path": "coders/cin.c"}
{"idx": 431633, "project": "ImageMagick", "commit_id": "ca3654ebf7a439dc736f56f083c9aa98e4464b7f", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/ca3654ebf7a439dc736f56f083c9aa98e4464b7f", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/4988", "target": 0, "func": "static Image *ReadCINImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define MonoColorType  1\n#define RGBColorType  3\n\n  char\n    property[MagickPathExtent];\n\n  CINInfo\n    cin;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    offset;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumType\n    quantum_type;\n\n  ssize_t\n    i;\n\n  Quantum\n    *q;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    magick[4],\n    *pixels;\n\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    File information.\n  */\n  offset=0;\n  count=ReadBlob(image,4,magick);\n  offset+=count;\n  if ((count != 4) ||\n      ((LocaleNCompare((char *) magick,\"\\200\\052\\137\\327\",4) != 0)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  memset(&cin,0,sizeof(cin));\n  image->endian=(magick[0] == 0x80) && (magick[1] == 0x2a) &&\n    (magick[2] == 0x5f) && (magick[3] == 0xd7) ? MSBEndian : LSBEndian;\n  cin.file.image_offset=ReadBlobLong(image);\n  if (cin.file.image_offset < 712)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  offset+=4;\n  cin.file.generic_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.industry_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.user_length=ReadBlobLong(image);\n  offset+=4;\n  cin.file.file_size=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.file.version),(unsigned char *)\n    cin.file.version);\n  (void) CopyMagickString(property,cin.file.version,sizeof(cin.file.version));\n  (void) SetImageProperty(image,\"dpx:file.version\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.filename),(unsigned char *)\n    cin.file.filename);\n  (void) CopyMagickString(property,cin.file.filename,sizeof(cin.file.filename));\n  (void) SetImageProperty(image,\"dpx:file.filename\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.create_date),(unsigned char *)\n    cin.file.create_date);\n  (void) CopyMagickString(property,cin.file.create_date,\n    sizeof(cin.file.create_date));\n  (void) SetImageProperty(image,\"dpx:file.create_date\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.create_time),(unsigned char *)\n    cin.file.create_time);\n  (void) CopyMagickString(property,cin.file.create_time,\n    sizeof(cin.file.create_time));\n  (void) SetImageProperty(image,\"dpx:file.create_time\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.file.reserve),(unsigned char *)\n    cin.file.reserve);\n  /*\n    Image information.\n  */\n  cin.image.orientation=(unsigned char) ReadBlobByte(image);\n  offset++;\n  if (cin.image.orientation != (unsigned char) (~0))\n    (void) FormatImageProperty(image,\"dpx:image.orientation\",\"%d\",\n      cin.image.orientation);\n  switch (cin.image.orientation)\n  {\n    default:\n    case 0: image->orientation=TopLeftOrientation; break;\n    case 1: image->orientation=TopRightOrientation; break;\n    case 2: image->orientation=BottomLeftOrientation; break;\n    case 3: image->orientation=BottomRightOrientation; break;\n    case 4: image->orientation=LeftTopOrientation; break;\n    case 5: image->orientation=RightTopOrientation; break;\n    case 6: image->orientation=LeftBottomOrientation; break;\n    case 7: image->orientation=RightBottomOrientation; break;\n  }\n  cin.image.number_channels=(unsigned char) ReadBlobByte(image);\n  offset++;\n  offset+=ReadBlob(image,sizeof(cin.image.reserve1),(unsigned char *)\n    cin.image.reserve1);\n  for (i=0; i < 8; i++)\n  {\n    cin.image.channel[i].designator[0]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].designator[1]=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].bits_per_pixel=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].reserve=(unsigned char) ReadBlobByte(image);\n    offset++;\n    cin.image.channel[i].pixels_per_line=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].lines_per_image=ReadBlobLong(image);\n    offset+=4;\n    cin.image.channel[i].min_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].min_quantity=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_data=ReadBlobFloat(image);\n    offset+=4;\n    cin.image.channel[i].max_quantity=ReadBlobFloat(image);\n    offset+=4;\n  }\n  cin.image.white_point[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[0]) != MagickFalse)\n    image->chromaticity.white_point.x=cin.image.white_point[0];\n  cin.image.white_point[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.white_point[1]) != MagickFalse)\n    image->chromaticity.white_point.y=cin.image.white_point[1];\n  cin.image.red_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.red_primary_chromaticity[0];\n  cin.image.red_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.red_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.red_primary.y=cin.image.red_primary_chromaticity[1];\n  cin.image.green_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.red_primary.x=cin.image.green_primary_chromaticity[0];\n  cin.image.green_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.green_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.green_primary.y=cin.image.green_primary_chromaticity[1];\n  cin.image.blue_primary_chromaticity[0]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[0]) != MagickFalse)\n    image->chromaticity.blue_primary.x=cin.image.blue_primary_chromaticity[0];\n  cin.image.blue_primary_chromaticity[1]=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.image.blue_primary_chromaticity[1]) != MagickFalse)\n    image->chromaticity.blue_primary.y=cin.image.blue_primary_chromaticity[1];\n  offset+=ReadBlob(image,sizeof(cin.image.label),(unsigned char *)\n    cin.image.label);\n  (void) CopyMagickString(property,cin.image.label,sizeof(cin.image.label));\n  (void) SetImageProperty(image,\"dpx:image.label\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.image.reserve),(unsigned char *)\n    cin.image.reserve);\n  /*\n    Image data format information.\n  */\n  cin.data_format.interleave=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.packing=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sign=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.sense=(unsigned char) ReadBlobByte(image);\n  offset++;\n  cin.data_format.line_pad=ReadBlobLong(image);\n  offset+=4;\n  cin.data_format.channel_pad=ReadBlobLong(image);\n  offset+=4;\n  offset+=ReadBlob(image,sizeof(cin.data_format.reserve),(unsigned char *)\n    cin.data_format.reserve);\n  /*\n    Image origination information.\n  */\n  cin.origination.x_offset=ReadBlobSignedLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.x_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.x_offset\",\"%.20g\",\n      (double) cin.origination.x_offset);\n  cin.origination.y_offset=(ssize_t) ReadBlobLong(image);\n  offset+=4;\n  if ((size_t) cin.origination.y_offset != ~0UL)\n    (void) FormatImageProperty(image,\"dpx:origination.y_offset\",\"%.20g\",\n      (double) cin.origination.y_offset);\n  offset+=ReadBlob(image,sizeof(cin.origination.filename),(unsigned char *)\n    cin.origination.filename);\n  (void) CopyMagickString(property,cin.origination.filename,\n    sizeof(cin.origination.filename));\n  (void) SetImageProperty(image,\"dpx:origination.filename\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_date),(unsigned char *)\n    cin.origination.create_date);\n  (void) CopyMagickString(property,cin.origination.create_date,\n    sizeof(cin.origination.create_date));\n  (void) SetImageProperty(image,\"dpx:origination.create_date\",property,\n    exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.create_time),(unsigned char *)\n    cin.origination.create_time);\n  (void) CopyMagickString(property,cin.origination.create_time,\n    sizeof(cin.origination.create_time));\n  (void) SetImageProperty(image,\"dpx:origination.create_time\",property,\n    exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.device),(unsigned char *)\n    cin.origination.device);\n  (void) CopyMagickString(property,cin.origination.device,\n    sizeof(cin.origination.device));\n  (void) SetImageProperty(image,\"dpx:origination.device\",property,exception);\n  offset+=ReadBlob(image,sizeof(cin.origination.model),(unsigned char *)\n    cin.origination.model);\n  (void) CopyMagickString(property,cin.origination.model,\n    sizeof(cin.origination.model));\n  (void) SetImageProperty(image,\"dpx:origination.model\",property,exception);\n  (void) memset(cin.origination.serial,0, \n    sizeof(cin.origination.serial));\n  offset+=ReadBlob(image,sizeof(cin.origination.serial),(unsigned char *)\n    cin.origination.serial);\n  (void) CopyMagickString(property,cin.origination.serial,\n    sizeof(cin.origination.serial));\n  (void) SetImageProperty(image,\"dpx:origination.serial\",property,exception);\n  cin.origination.x_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.y_pitch=ReadBlobFloat(image);\n  offset+=4;\n  cin.origination.gamma=ReadBlobFloat(image);\n  offset+=4;\n  if (IsFloatDefined(cin.origination.gamma) != MagickFalse)\n    image->gamma=cin.origination.gamma;\n  offset+=ReadBlob(image,sizeof(cin.origination.reserve),(unsigned char *)\n    cin.origination.reserve);\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      int\n        c;\n\n      /*\n        Image film information.\n      */\n      cin.film.id=ReadBlobByte(image);\n      offset++;\n      c=cin.film.id;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.id\",\"%d\",cin.film.id);\n      cin.film.type=ReadBlobByte(image);\n      offset++;\n      c=cin.film.type;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.type\",\"%d\",cin.film.type);\n      cin.film.offset=ReadBlobByte(image);\n      offset++;\n      c=cin.film.offset;\n      if (c != ~0)\n        (void) FormatImageProperty(image,\"dpx:film.offset\",\"%d\",\n          cin.film.offset);\n      cin.film.reserve1=ReadBlobByte(image);\n      offset++;\n      cin.film.prefix=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.prefix != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.prefix\",\"%.20g\",(double)\n          cin.film.prefix);\n      cin.film.count=ReadBlobLong(image);\n      offset+=4;\n      offset+=ReadBlob(image,sizeof(cin.film.format),(unsigned char *)\n        cin.film.format);\n      (void) CopyMagickString(property,cin.film.format,sizeof(cin.film.format));\n      (void) SetImageProperty(image,\"dpx:film.format\",property,exception);\n      cin.film.frame_position=ReadBlobLong(image);\n      offset+=4;\n      if (cin.film.frame_position != ~0UL)\n        (void) FormatImageProperty(image,\"dpx:film.frame_position\",\"%.20g\",\n          (double) cin.film.frame_position);\n      cin.film.frame_rate=ReadBlobFloat(image);\n      offset+=4;\n      if (IsFloatDefined(cin.film.frame_rate) != MagickFalse)\n        (void) FormatImageProperty(image,\"dpx:film.frame_rate\",\"%g\",\n          cin.film.frame_rate);\n      offset+=ReadBlob(image,sizeof(cin.film.frame_id),(unsigned char *)\n        cin.film.frame_id);\n      (void) CopyMagickString(property,cin.film.frame_id,\n        sizeof(cin.film.frame_id));\n      (void) SetImageProperty(image,\"dpx:film.frame_id\",property,exception);\n      offset+=ReadBlob(image,sizeof(cin.film.slate_info),(unsigned char *)\n        cin.film.slate_info);\n      (void) CopyMagickString(property,cin.film.slate_info,\n        sizeof(cin.film.slate_info));\n      (void) SetImageProperty(image,\"dpx:film.slate_info\",property,exception);\n      offset+=ReadBlob(image,sizeof(cin.film.reserve),(unsigned char *)\n        cin.film.reserve);\n    }\n  if ((cin.file.image_offset > 2048) && (cin.file.user_length != 0))\n    {\n      StringInfo\n        *profile;\n\n      /*\n        User defined data.\n      */\n      if (cin.file.user_length > GetBlobSize(image))\n        ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n      profile=BlobToStringInfo((const unsigned char *) NULL,\n        cin.file.user_length);\n      if (profile == (StringInfo *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      offset+=ReadBlob(image,GetStringInfoLength(profile),\n        GetStringInfoDatum(profile));\n      (void) SetImageProfile(image,\"dpx:user.data\",profile,exception);\n      profile=DestroyStringInfo(profile);\n    }\n  image->depth=cin.image.channel[0].bits_per_pixel;\n  image->columns=cin.image.channel[0].pixels_per_line;\n  image->rows=cin.image.channel[0].lines_per_image;\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(image);\n    }\n  if (((MagickSizeType) image->columns*image->rows/8) > GetBlobSize(image))\n    ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n  for ( ; offset < (MagickOffsetType) cin.file.image_offset; offset++)\n  {\n    int\n      c;\n\n    c=ReadBlobByte(image);\n    if (c == EOF)\n      break;\n  }\n  if (offset < (MagickOffsetType) cin.file.image_offset)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  (void) SetImageBackgroundColor(image,exception);\n  /*\n    Convert CIN raster image to pixel packets.\n  */\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  SetQuantumQuantum(quantum_info,32);\n  SetQuantumPack(quantum_info,MagickFalse);\n  quantum_type=RGBQuantum;\n  length=GetBytesPerRow(image->columns,3,image->depth,MagickTrue);\n  if (cin.image.number_channels == 1)\n    {\n      quantum_type=GrayQuantum;\n      length=GetBytesPerRow(image->columns,1,image->depth,MagickTrue);\n    }\n  status=SetQuantumPad(image,quantum_info,0);\n  pixels=GetQuantumPixels(quantum_info);\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const void\n      *stream;\n\n    q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n    if (q == (Quantum *) NULL)\n      break;\n    stream=ReadBlobStream(image,length,pixels,&count);\n    if ((size_t) count != length)\n      break;\n    (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n      quantum_type,(unsigned char *) stream,exception);\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n    if (image->previous == (Image *) NULL)\n      {\n        status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n          image->rows);\n        if (status == MagickFalse)\n          break;\n      }\n  }\n  SetQuantumImageType(image,quantum_type);\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  SetImageColorspace(image,LogColorspace,exception);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_hash": 125130615977204070333523361327116450874, "file_name": "cin.c", "file_hash": 296697563604173271604352885758570763809, "cwe": ["CWE-787"], "cve": "CVE-2022-28463", "cve_desc": "ImageMagick 7.1.0-27 is vulnerable to Buffer Overflow.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-28463", "file_path": "coders/cin.c"}
{"idx": 210271, "project": "vim", "commit_id": "6669de1b235843968e88844ca6d3c8dec4b01a9e", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/6669de1b235843968e88844ca6d3c8dec4b01a9e", "commit_message": "patch 9.0.0240: crash when using \":mkspell\" with an empty .dic file\n\nProblem:    Crash when using \":mkspell\" with an empty .dic file.\nSolution:   Check for an empty word tree.", "target": 1, "func": "sug_filltree(spellinfo_T *spin, slang_T *slang)\n{\n    char_u\t*byts;\n    idx_T\t*idxs;\n    int\t\tdepth;\n    idx_T\tarridx[MAXWLEN];\n    int\t\tcuri[MAXWLEN];\n    char_u\ttword[MAXWLEN];\n    char_u\ttsalword[MAXWLEN];\n    int\t\tc;\n    idx_T\tn;\n    unsigned\twords_done = 0;\n    int\t\twordcount[MAXWLEN];\n\n    // We use si_foldroot for the soundfolded trie.\n    spin->si_foldroot = wordtree_alloc(spin);\n    if (spin->si_foldroot == NULL)\n\treturn FAIL;\n\n    // let tree_add_word() know we're adding to the soundfolded tree\n    spin->si_sugtree = TRUE;\n\n    /*\n     * Go through the whole case-folded tree, soundfold each word and put it\n     * in the trie.\n     */\n    byts = slang->sl_fbyts;\n    idxs = slang->sl_fidxs;\n\n    arridx[0] = 0;\n    curi[0] = 1;\n    wordcount[0] = 0;\n\n    depth = 0;\n    while (depth >= 0 && !got_int)\n    {\n\tif (curi[depth] > byts[arridx[depth]])\n\t{\n\t    // Done all bytes at this node, go up one level.\n\t    idxs[arridx[depth]] = wordcount[depth];\n\t    if (depth > 0)\n\t\twordcount[depth - 1] += wordcount[depth];\n\n\t    --depth;\n\t    line_breakcheck();\n\t}\n\telse\n\t{\n\n\t    // Do one more byte at this node.\n\t    n = arridx[depth] + curi[depth];\n\t    ++curi[depth];\n\n\t    c = byts[n];\n\t    if (c == 0)\n\t    {\n\t\t// Sound-fold the word.\n\t\ttword[depth] = NUL;\n\t\tspell_soundfold(slang, tword, TRUE, tsalword);\n\n\t\t// We use the \"flags\" field for the MSB of the wordnr,\n\t\t// \"region\" for the LSB of the wordnr.\n\t\tif (tree_add_word(spin, tsalword, spin->si_foldroot,\n\t\t\t\twords_done >> 16, words_done & 0xffff,\n\t\t\t\t\t\t\t   0) == FAIL)\n\t\t    return FAIL;\n\n\t\t++words_done;\n\t\t++wordcount[depth];\n\n\t\t// Reset the block count each time to avoid compression\n\t\t// kicking in.\n\t\tspin->si_blocks_cnt = 0;\n\n\t\t// Skip over any other NUL bytes (same word with different\n\t\t// flags).  But don't go over the end.\n\t\twhile (n + 1 < slang->sl_fbyts_len && byts[n + 1] == 0)\n\t\t{\n\t\t    ++n;\n\t\t    ++curi[depth];\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t// Normal char, go one level deeper.\n\t\ttword[depth++] = c;\n\t\tarridx[depth] = idxs[n];\n\t\tcuri[depth] = 1;\n\t\twordcount[depth] = 0;\n\t    }\n\t}\n    }\n\n    smsg(_(\"Total number of words: %d\"), words_done);\n\n    return OK;\n}", "func_hash": 207388436213910008407743050781298909937, "file_name": "spellfile.c", "file_hash": 273224760850620955394187294241739462394, "cwe": ["CWE-787"], "cve": "CVE-2022-2923", "cve_desc": "NULL Pointer Dereference in GitHub repository vim/vim prior to 9.0.0240.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2923", "file_path": "src/spellfile.c"}
{"idx": 432093, "project": "vim", "commit_id": "6669de1b235843968e88844ca6d3c8dec4b01a9e", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/6669de1b235843968e88844ca6d3c8dec4b01a9e", "commit_message": "patch 9.0.0240: crash when using \":mkspell\" with an empty .dic file\n\nProblem:    Crash when using \":mkspell\" with an empty .dic file.\nSolution:   Check for an empty word tree.", "target": 0, "func": "sug_filltree(spellinfo_T *spin, slang_T *slang)\n{\n    char_u\t*byts;\n    idx_T\t*idxs;\n    int\t\tdepth;\n    idx_T\tarridx[MAXWLEN];\n    int\t\tcuri[MAXWLEN];\n    char_u\ttword[MAXWLEN];\n    char_u\ttsalword[MAXWLEN];\n    int\t\tc;\n    idx_T\tn;\n    unsigned\twords_done = 0;\n    int\t\twordcount[MAXWLEN];\n\n    // We use si_foldroot for the soundfolded trie.\n    spin->si_foldroot = wordtree_alloc(spin);\n    if (spin->si_foldroot == NULL)\n\treturn FAIL;\n\n    // let tree_add_word() know we're adding to the soundfolded tree\n    spin->si_sugtree = TRUE;\n\n    /*\n     * Go through the whole case-folded tree, soundfold each word and put it\n     * in the trie.  Bail out if the tree is empty.\n     */\n    byts = slang->sl_fbyts;\n    idxs = slang->sl_fidxs;\n    if (byts == NULL || idxs == NULL)\n\treturn FAIL;\n\n    arridx[0] = 0;\n    curi[0] = 1;\n    wordcount[0] = 0;\n\n    depth = 0;\n    while (depth >= 0 && !got_int)\n    {\n\tif (curi[depth] > byts[arridx[depth]])\n\t{\n\t    // Done all bytes at this node, go up one level.\n\t    idxs[arridx[depth]] = wordcount[depth];\n\t    if (depth > 0)\n\t\twordcount[depth - 1] += wordcount[depth];\n\n\t    --depth;\n\t    line_breakcheck();\n\t}\n\telse\n\t{\n\n\t    // Do one more byte at this node.\n\t    n = arridx[depth] + curi[depth];\n\t    ++curi[depth];\n\n\t    c = byts[n];\n\t    if (c == 0)\n\t    {\n\t\t// Sound-fold the word.\n\t\ttword[depth] = NUL;\n\t\tspell_soundfold(slang, tword, TRUE, tsalword);\n\n\t\t// We use the \"flags\" field for the MSB of the wordnr,\n\t\t// \"region\" for the LSB of the wordnr.\n\t\tif (tree_add_word(spin, tsalword, spin->si_foldroot,\n\t\t\t\twords_done >> 16, words_done & 0xffff,\n\t\t\t\t\t\t\t   0) == FAIL)\n\t\t    return FAIL;\n\n\t\t++words_done;\n\t\t++wordcount[depth];\n\n\t\t// Reset the block count each time to avoid compression\n\t\t// kicking in.\n\t\tspin->si_blocks_cnt = 0;\n\n\t\t// Skip over any other NUL bytes (same word with different\n\t\t// flags).  But don't go over the end.\n\t\twhile (n + 1 < slang->sl_fbyts_len && byts[n + 1] == 0)\n\t\t{\n\t\t    ++n;\n\t\t    ++curi[depth];\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t// Normal char, go one level deeper.\n\t\ttword[depth++] = c;\n\t\tarridx[depth] = idxs[n];\n\t\tcuri[depth] = 1;\n\t\twordcount[depth] = 0;\n\t    }\n\t}\n    }\n\n    smsg(_(\"Total number of words: %d\"), words_done);\n\n    return OK;\n}", "func_hash": 208510972034693515698183125739179180871, "file_name": "spellfile.c", "file_hash": 159233725116993104212150761027929059833, "cwe": ["CWE-787"], "cve": "CVE-2022-2923", "cve_desc": "NULL Pointer Dereference in GitHub repository vim/vim prior to 9.0.0240.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2923", "file_path": "src/spellfile.c"}
{"idx": 210273, "project": "mongo", "commit_id": "f3604b901d688c194de5e430c7fbab060c9dc8e0", "project_url": "https://github.com/mongodb/mongo", "commit_url": "https://github.com/mongodb/mongo/commit/f3604b901d688c194de5e430c7fbab060c9dc8e0", "commit_message": "SERVER-59071 Treat '$sample' as unsharded when connecting directly to shards", "target": 1, "func": "createRandomCursorExecutor(const CollectionPtr& coll,\n                           const boost::intrusive_ptr<ExpressionContext>& expCtx,\n                           long long sampleSize,\n                           long long numRecords,\n                           boost::optional<BucketUnpacker> bucketUnpacker) {\n    OperationContext* opCtx = expCtx->opCtx;\n\n    // Verify that we are already under a collection lock. We avoid taking locks ourselves in this\n    // function because double-locking forces any PlanExecutor we create to adopt a NO_YIELD policy.\n    invariant(opCtx->lockState()->isCollectionLockedForMode(coll->ns(), MODE_IS));\n\n    static const double kMaxSampleRatioForRandCursor = 0.05;\n    if (!expCtx->ns.isTimeseriesBucketsCollection()) {\n        if (sampleSize > numRecords * kMaxSampleRatioForRandCursor || numRecords <= 100) {\n            return std::pair{nullptr, false};\n        }\n    } else {\n        // Suppose that a time-series bucket collection is observed to contain 200 buckets, and the\n        // 'gTimeseriesBucketMaxCount' parameter is set to 1000. If all buckets are full, then the\n        // maximum possible measurment count would be 200 * 1000 = 200,000. While the\n        // 'SampleFromTimeseriesBucket' plan is more efficient when the sample size is small\n        // relative to the total number of measurements in the time-series collection, for larger\n        // sample sizes the top-k sort based sample is faster. Experiments have approximated that\n        // the tipping point is roughly when the requested sample size is greater than 1% of the\n        // maximum possible number of measurements in the collection (i.e. numBuckets *\n        // maxMeasurementsPerBucket).\n        static const double kCoefficient = 0.01;\n        if (sampleSize > kCoefficient * numRecords * gTimeseriesBucketMaxCount) {\n            return std::pair{nullptr, false};\n        }\n    }\n\n    // Attempt to get a random cursor from the RecordStore.\n    auto rsRandCursor = coll->getRecordStore()->getRandomCursor(opCtx);\n    if (!rsRandCursor) {\n        // The storage engine has no random cursor support.\n        return std::pair{nullptr, false};\n    }\n\n    // Build a MultiIteratorStage and pass it the random-sampling RecordCursor.\n    auto ws = std::make_unique<WorkingSet>();\n    std::unique_ptr<PlanStage> root =\n        std::make_unique<MultiIteratorStage>(expCtx.get(), ws.get(), coll);\n    static_cast<MultiIteratorStage*>(root.get())->addIterator(std::move(rsRandCursor));\n\n    // If the incoming operation is sharded, use the CSS to infer the filtering metadata for the\n    // collection, otherwise treat it as unsharded\n    auto collectionFilter =\n        CollectionShardingState::get(opCtx, coll->ns())\n            ->getOwnershipFilter(\n                opCtx, CollectionShardingState::OrphanCleanupPolicy::kDisallowOrphanCleanup);\n\n    TrialStage* trialStage = nullptr;\n\n    // Because 'numRecords' includes orphan documents, our initial decision to optimize the $sample\n    // cursor may have been mistaken. For sharded collections, build a TRIAL plan that will switch\n    // to a collection scan if the ratio of orphaned to owned documents encountered over the first\n    // 100 works() is such that we would have chosen not to optimize.\n    static const size_t kMaxPresampleSize = 100;\n    if (collectionFilter.isSharded() && !expCtx->ns.isTimeseriesBucketsCollection()) {\n        // The ratio of owned to orphaned documents must be at least equal to the ratio between the\n        // requested sampleSize and the maximum permitted sampleSize for the original constraints to\n        // be satisfied. For instance, if there are 200 documents and the sampleSize is 5, then at\n        // least (5 / (200*0.05)) = (5/10) = 50% of those documents must be owned. If less than 5%\n        // of the documents in the collection are owned, we default to the backup plan.\n        const auto minAdvancedToWorkRatio = std::max(\n            sampleSize / (numRecords * kMaxSampleRatioForRandCursor), kMaxSampleRatioForRandCursor);\n        // The trial plan is SHARDING_FILTER-MULTI_ITERATOR.\n        auto randomCursorPlan = std::make_unique<ShardFilterStage>(\n            expCtx.get(), collectionFilter, ws.get(), std::move(root));\n        // The backup plan is SHARDING_FILTER-COLLSCAN.\n        std::unique_ptr<PlanStage> collScanPlan = std::make_unique<CollectionScan>(\n            expCtx.get(), coll, CollectionScanParams{}, ws.get(), nullptr);\n        collScanPlan = std::make_unique<ShardFilterStage>(\n            expCtx.get(), collectionFilter, ws.get(), std::move(collScanPlan));\n        // Place a TRIAL stage at the root of the plan tree, and pass it the trial and backup plans.\n        root = std::make_unique<TrialStage>(expCtx.get(),\n                                            ws.get(),\n                                            std::move(randomCursorPlan),\n                                            std::move(collScanPlan),\n                                            kMaxPresampleSize,\n                                            minAdvancedToWorkRatio);\n        trialStage = static_cast<TrialStage*>(root.get());\n    } else if (expCtx->ns.isTimeseriesBucketsCollection()) {\n        // We can't take ARHASH optimization path for a direct $sample on the system.buckets\n        // collection because data is in compressed form. If we did have a direct $sample on the\n        // system.buckets collection, then the 'bucketUnpacker' would not be set up properly. We\n        // also should bail out early if a $sample is made against a time series collection that is\n        // empty. If we don't the 'minAdvancedToWorkRatio' can be nan/-nan depending on the\n        // architecture.\n        if (!(bucketUnpacker && numRecords)) {\n            return std::pair{nullptr, false};\n        }\n\n        // Use a 'TrialStage' to run a trial between 'SampleFromTimeseriesBucket' and\n        // 'UnpackTimeseriesBucket' with $sample left in the pipeline in-place. If the buckets are\n        // not sufficiently full, or the 'SampleFromTimeseriesBucket' plan draws too many\n        // duplicates, then we will fall back to the 'TrialStage' backup plan. This backup plan uses\n        // the top-k sort sampling approach.\n        //\n        // Suppose the 'gTimeseriesBucketMaxCount' is 1000, but each bucket only contains 500\n        // documents on average. The observed trial advanced/work ratio approximates the average\n        // bucket fullness, noted here as \"abf\". In this example, abf = 500 / 1000 = 0.5.\n        // Experiments have shown that the optimized 'SampleFromTimeseriesBucket' algorithm performs\n        // better than backup plan when\n        //\n        //     sampleSize < 0.02 * abf * numRecords * gTimeseriesBucketMaxCount\n        //\n        //  This inequality can be rewritten as\n        //\n        //     abf > sampleSize / (0.02 * numRecords * gTimeseriesBucketMaxCount)\n        //\n        // Therefore, if the advanced/work ratio exceeds this threshold, we will use the\n        // 'SampleFromTimeseriesBucket' plan. Note that as the sample size requested by the user\n        // becomes larger with respect to the number of buckets, we require a higher advanced/work\n        // ratio in order to justify using 'SampleFromTimeseriesBucket'.\n        //\n        // Additionally, we require the 'TrialStage' to approximate the abf as at least 0.25. When\n        // buckets are mostly empty, the 'SampleFromTimeseriesBucket' will be inefficient due to a\n        // lot of sampling \"misses\".\n        static const auto kCoefficient = 0.02;\n        static const auto kMinBucketFullness = 0.25;\n        const auto minAdvancedToWorkRatio = std::max(\n            std::min(sampleSize / (kCoefficient * numRecords * gTimeseriesBucketMaxCount), 1.0),\n            kMinBucketFullness);\n\n        auto arhashPlan = std::make_unique<SampleFromTimeseriesBucket>(\n            expCtx.get(),\n            ws.get(),\n            std::move(root),\n            *bucketUnpacker,\n            // By using a quantity slightly higher than 'kMaxPresampleSize', we ensure that the\n            // 'SampleFromTimeseriesBucket' stage won't fail due to too many consecutive sampling\n            // attempts during the 'TrialStage's trial period.\n            kMaxPresampleSize + 5,\n            sampleSize,\n            gTimeseriesBucketMaxCount);\n\n        std::unique_ptr<PlanStage> collScanPlan = std::make_unique<CollectionScan>(\n            expCtx.get(), coll, CollectionScanParams{}, ws.get(), nullptr);\n\n        auto topkSortPlan = std::make_unique<UnpackTimeseriesBucket>(\n            expCtx.get(), ws.get(), std::move(collScanPlan), *bucketUnpacker);\n\n        root = std::make_unique<TrialStage>(expCtx.get(),\n                                            ws.get(),\n                                            std::move(arhashPlan),\n                                            std::move(topkSortPlan),\n                                            kMaxPresampleSize,\n                                            minAdvancedToWorkRatio);\n        trialStage = static_cast<TrialStage*>(root.get());\n    }\n\n    auto execStatus = plan_executor_factory::make(expCtx,\n                                                  std::move(ws),\n                                                  std::move(root),\n                                                  &coll,\n                                                  opCtx->inMultiDocumentTransaction()\n                                                      ? PlanYieldPolicy::YieldPolicy::INTERRUPT_ONLY\n                                                      : PlanYieldPolicy::YieldPolicy::YIELD_AUTO,\n                                                  QueryPlannerParams::RETURN_OWNED_DATA);\n    if (!execStatus.isOK()) {\n        return execStatus.getStatus();\n    }\n\n    // For sharded collections, the root of the plan tree is a TrialStage that may have chosen\n    // either a random-sampling cursor trial plan or a COLLSCAN backup plan. We can only optimize\n    // the $sample aggregation stage if the trial plan was chosen.\n    return std::pair{std::move(execStatus.getValue()),\n                     !trialStage || !trialStage->pickedBackupPlan()};\n}", "func_hash": 239583334467362355681176105432769486304, "file_name": "pipeline_d.cpp", "file_hash": 58061396446339864036845237439152201402, "cwe": ["CWE-617"], "cve": "CVE-2021-32037", "cve_desc": "An authorized user may trigger an invariant which may result in denial of service or server exit if a relevant aggregation request is sent to a shard. Usually, the requests are sent via mongos and special privileges are required in order to know the address of the shards and to log in to the shards of an auth enabled environment.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-32037", "file_path": "src/mongo/db/pipeline/pipeline_d.cpp"}
{"idx": 432152, "project": "mongo", "commit_id": "f3604b901d688c194de5e430c7fbab060c9dc8e0", "project_url": "https://github.com/mongodb/mongo", "commit_url": "https://github.com/mongodb/mongo/commit/f3604b901d688c194de5e430c7fbab060c9dc8e0", "commit_message": "SERVER-59071 Treat '$sample' as unsharded when connecting directly to shards", "target": 0, "func": "createRandomCursorExecutor(const CollectionPtr& coll,\n                           const boost::intrusive_ptr<ExpressionContext>& expCtx,\n                           long long sampleSize,\n                           long long numRecords,\n                           boost::optional<BucketUnpacker> bucketUnpacker) {\n    OperationContext* opCtx = expCtx->opCtx;\n\n    // Verify that we are already under a collection lock. We avoid taking locks ourselves in this\n    // function because double-locking forces any PlanExecutor we create to adopt a NO_YIELD policy.\n    invariant(opCtx->lockState()->isCollectionLockedForMode(coll->ns(), MODE_IS));\n\n    static const double kMaxSampleRatioForRandCursor = 0.05;\n    if (!expCtx->ns.isTimeseriesBucketsCollection()) {\n        if (sampleSize > numRecords * kMaxSampleRatioForRandCursor || numRecords <= 100) {\n            return std::pair{nullptr, false};\n        }\n    } else {\n        // Suppose that a time-series bucket collection is observed to contain 200 buckets, and the\n        // 'gTimeseriesBucketMaxCount' parameter is set to 1000. If all buckets are full, then the\n        // maximum possible measurment count would be 200 * 1000 = 200,000. While the\n        // 'SampleFromTimeseriesBucket' plan is more efficient when the sample size is small\n        // relative to the total number of measurements in the time-series collection, for larger\n        // sample sizes the top-k sort based sample is faster. Experiments have approximated that\n        // the tipping point is roughly when the requested sample size is greater than 1% of the\n        // maximum possible number of measurements in the collection (i.e. numBuckets *\n        // maxMeasurementsPerBucket).\n        static const double kCoefficient = 0.01;\n        if (sampleSize > kCoefficient * numRecords * gTimeseriesBucketMaxCount) {\n            return std::pair{nullptr, false};\n        }\n    }\n\n    // Attempt to get a random cursor from the RecordStore.\n    auto rsRandCursor = coll->getRecordStore()->getRandomCursor(opCtx);\n    if (!rsRandCursor) {\n        // The storage engine has no random cursor support.\n        return std::pair{nullptr, false};\n    }\n\n    // Build a MultiIteratorStage and pass it the random-sampling RecordCursor.\n    auto ws = std::make_unique<WorkingSet>();\n    std::unique_ptr<PlanStage> root =\n        std::make_unique<MultiIteratorStage>(expCtx.get(), ws.get(), coll);\n    static_cast<MultiIteratorStage*>(root.get())->addIterator(std::move(rsRandCursor));\n\n    TrialStage* trialStage = nullptr;\n\n    // Because 'numRecords' includes orphan documents, our initial decision to optimize the $sample\n    // cursor may have been mistaken. For sharded collections, build a TRIAL plan that will switch\n    // to a collection scan if the ratio of orphaned to owned documents encountered over the first\n    // 100 works() is such that we would have chosen not to optimize.\n    static const size_t kMaxPresampleSize = 100;\n    if (auto css = CollectionShardingState::get(opCtx, coll->ns());\n        css->getCollectionDescription(opCtx).isSharded() &&\n        !expCtx->ns.isTimeseriesBucketsCollection()) {\n        // The ratio of owned to orphaned documents must be at least equal to the ratio between the\n        // requested sampleSize and the maximum permitted sampleSize for the original constraints to\n        // be satisfied. For instance, if there are 200 documents and the sampleSize is 5, then at\n        // least (5 / (200*0.05)) = (5/10) = 50% of those documents must be owned. If less than 5%\n        // of the documents in the collection are owned, we default to the backup plan.\n        const auto minAdvancedToWorkRatio = std::max(\n            sampleSize / (numRecords * kMaxSampleRatioForRandCursor), kMaxSampleRatioForRandCursor);\n        // Since the incoming operation is sharded, use the CSS to infer the filtering metadata for\n        // the collection. We get the shard ownership filter after checking to see if the collection\n        // is sharded to avoid an invariant from being fired in this call.\n        auto collectionFilter = css->getOwnershipFilter(\n            opCtx, CollectionShardingState::OrphanCleanupPolicy::kDisallowOrphanCleanup);\n        // The trial plan is SHARDING_FILTER-MULTI_ITERATOR.\n        auto randomCursorPlan = std::make_unique<ShardFilterStage>(\n            expCtx.get(), collectionFilter, ws.get(), std::move(root));\n        // The backup plan is SHARDING_FILTER-COLLSCAN.\n        std::unique_ptr<PlanStage> collScanPlan = std::make_unique<CollectionScan>(\n            expCtx.get(), coll, CollectionScanParams{}, ws.get(), nullptr);\n        collScanPlan = std::make_unique<ShardFilterStage>(\n            expCtx.get(), collectionFilter, ws.get(), std::move(collScanPlan));\n        // Place a TRIAL stage at the root of the plan tree, and pass it the trial and backup plans.\n        root = std::make_unique<TrialStage>(expCtx.get(),\n                                            ws.get(),\n                                            std::move(randomCursorPlan),\n                                            std::move(collScanPlan),\n                                            kMaxPresampleSize,\n                                            minAdvancedToWorkRatio);\n        trialStage = static_cast<TrialStage*>(root.get());\n    } else if (expCtx->ns.isTimeseriesBucketsCollection()) {\n        // We can't take ARHASH optimization path for a direct $sample on the system.buckets\n        // collection because data is in compressed form. If we did have a direct $sample on the\n        // system.buckets collection, then the 'bucketUnpacker' would not be set up properly. We\n        // also should bail out early if a $sample is made against a time series collection that is\n        // empty. If we don't the 'minAdvancedToWorkRatio' can be nan/-nan depending on the\n        // architecture.\n        if (!(bucketUnpacker && numRecords)) {\n            return std::pair{nullptr, false};\n        }\n\n        // Use a 'TrialStage' to run a trial between 'SampleFromTimeseriesBucket' and\n        // 'UnpackTimeseriesBucket' with $sample left in the pipeline in-place. If the buckets are\n        // not sufficiently full, or the 'SampleFromTimeseriesBucket' plan draws too many\n        // duplicates, then we will fall back to the 'TrialStage' backup plan. This backup plan uses\n        // the top-k sort sampling approach.\n        //\n        // Suppose the 'gTimeseriesBucketMaxCount' is 1000, but each bucket only contains 500\n        // documents on average. The observed trial advanced/work ratio approximates the average\n        // bucket fullness, noted here as \"abf\". In this example, abf = 500 / 1000 = 0.5.\n        // Experiments have shown that the optimized 'SampleFromTimeseriesBucket' algorithm performs\n        // better than backup plan when\n        //\n        //     sampleSize < 0.02 * abf * numRecords * gTimeseriesBucketMaxCount\n        //\n        //  This inequality can be rewritten as\n        //\n        //     abf > sampleSize / (0.02 * numRecords * gTimeseriesBucketMaxCount)\n        //\n        // Therefore, if the advanced/work ratio exceeds this threshold, we will use the\n        // 'SampleFromTimeseriesBucket' plan. Note that as the sample size requested by the user\n        // becomes larger with respect to the number of buckets, we require a higher advanced/work\n        // ratio in order to justify using 'SampleFromTimeseriesBucket'.\n        //\n        // Additionally, we require the 'TrialStage' to approximate the abf as at least 0.25. When\n        // buckets are mostly empty, the 'SampleFromTimeseriesBucket' will be inefficient due to a\n        // lot of sampling \"misses\".\n        static const auto kCoefficient = 0.02;\n        static const auto kMinBucketFullness = 0.25;\n        const auto minAdvancedToWorkRatio = std::max(\n            std::min(sampleSize / (kCoefficient * numRecords * gTimeseriesBucketMaxCount), 1.0),\n            kMinBucketFullness);\n\n        auto arhashPlan = std::make_unique<SampleFromTimeseriesBucket>(\n            expCtx.get(),\n            ws.get(),\n            std::move(root),\n            *bucketUnpacker,\n            // By using a quantity slightly higher than 'kMaxPresampleSize', we ensure that the\n            // 'SampleFromTimeseriesBucket' stage won't fail due to too many consecutive sampling\n            // attempts during the 'TrialStage's trial period.\n            kMaxPresampleSize + 5,\n            sampleSize,\n            gTimeseriesBucketMaxCount);\n\n        std::unique_ptr<PlanStage> collScanPlan = std::make_unique<CollectionScan>(\n            expCtx.get(), coll, CollectionScanParams{}, ws.get(), nullptr);\n\n        auto topkSortPlan = std::make_unique<UnpackTimeseriesBucket>(\n            expCtx.get(), ws.get(), std::move(collScanPlan), *bucketUnpacker);\n\n        root = std::make_unique<TrialStage>(expCtx.get(),\n                                            ws.get(),\n                                            std::move(arhashPlan),\n                                            std::move(topkSortPlan),\n                                            kMaxPresampleSize,\n                                            minAdvancedToWorkRatio);\n        trialStage = static_cast<TrialStage*>(root.get());\n    }\n\n    auto execStatus = plan_executor_factory::make(expCtx,\n                                                  std::move(ws),\n                                                  std::move(root),\n                                                  &coll,\n                                                  opCtx->inMultiDocumentTransaction()\n                                                      ? PlanYieldPolicy::YieldPolicy::INTERRUPT_ONLY\n                                                      : PlanYieldPolicy::YieldPolicy::YIELD_AUTO,\n                                                  QueryPlannerParams::RETURN_OWNED_DATA);\n    if (!execStatus.isOK()) {\n        return execStatus.getStatus();\n    }\n\n    // For sharded collections, the root of the plan tree is a TrialStage that may have chosen\n    // either a random-sampling cursor trial plan or a COLLSCAN backup plan. We can only optimize\n    // the $sample aggregation stage if the trial plan was chosen.\n    return std::pair{std::move(execStatus.getValue()),\n                     !trialStage || !trialStage->pickedBackupPlan()};\n}", "func_hash": 248936200771856096728172359306392383142, "file_name": "pipeline_d.cpp", "file_hash": 250256559163646850106921369320994189676, "cwe": ["CWE-617"], "cve": "CVE-2021-32037", "cve_desc": "An authorized user may trigger an invariant which may result in denial of service or server exit if a relevant aggregation request is sent to a shard. Usually, the requests are sent via mongos and special privileges are required in order to know the address of the shards and to log in to the shards of an auth enabled environment.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-32037", "file_path": "src/mongo/db/pipeline/pipeline_d.cpp"}
{"idx": 210278, "project": "unicorn", "commit_id": "3d3deac5e6d38602b689c4fef5dac004f07a2e63", "project_url": "https://github.com/unicorn-engine/unicorn", "commit_url": "https://github.com/unicorn-engine/unicorn/commit/3d3deac5e6d38602b689c4fef5dac004f07a2e63", "commit_message": "Fix crash when mapping a big memory and calling uc_close", "target": 1, "func": "void qemu_ram_free(struct uc_struct *uc, RAMBlock *block)\n{\n    if (!block) {\n        return;\n    }\n\n    //if (block->host) {\n    //    ram_block_notify_remove(block->host, block->max_length);\n    //}\n\n    QLIST_REMOVE(block, next);\n    uc->ram_list.mru_block = NULL;\n    /* Write list before version */\n    //smp_wmb();\n    // call_rcu(block, reclaim_ramblock, rcu);\n    reclaim_ramblock(uc, block);\n}", "func_hash": 157575120486623399749960791680175069672, "file_name": "exec.c", "file_hash": 310161744044250278013604508128366354672, "cwe": ["CWE-476"], "cve": "CVE-2022-29694", "cve_desc": "Unicorn Engine v2.0.0-rc7 and below was discovered to contain a NULL pointer dereference via qemu_ram_free.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29694", "file_path": "qemu/exec.c"}
{"idx": 432247, "project": "unicorn", "commit_id": "3d3deac5e6d38602b689c4fef5dac004f07a2e63", "project_url": "https://github.com/unicorn-engine/unicorn", "commit_url": "https://github.com/unicorn-engine/unicorn/commit/3d3deac5e6d38602b689c4fef5dac004f07a2e63", "commit_message": "Fix crash when mapping a big memory and calling uc_close", "target": 0, "func": "void qemu_ram_free(struct uc_struct *uc, RAMBlock *block)\n{\n    if (!block) {\n        return;\n    }\n\n    //if (block->host) {\n    //    ram_block_notify_remove(block->host, block->max_length);\n    //}\n\n    QLIST_REMOVE_RCU(block, next);\n    uc->ram_list.mru_block = NULL;\n    /* Write list before version */\n    //smp_wmb();\n    // call_rcu(block, reclaim_ramblock, rcu);\n    reclaim_ramblock(uc, block);\n}", "func_hash": 139151486807095402727767671215311097684, "file_name": "exec.c", "file_hash": 120586418967583212379316417474927455385, "cwe": ["CWE-476"], "cve": "CVE-2022-29694", "cve_desc": "Unicorn Engine v2.0.0-rc7 and below was discovered to contain a NULL pointer dereference via qemu_ram_free.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29694", "file_path": "qemu/exec.c"}
{"idx": 210282, "project": "qemu", "commit_id": "b05b267840515730dbf6753495d5b7bd8b04ad1c", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://github.com/qemu/qemu/commit/b05b267840515730dbf6753495d5b7bd8b04ad1c", "commit_message": "i2c-ddc: fix oob read\n\nSuggested-by: Michael Hanselmann <public@hansmi.ch>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>\nReviewed-by: Michael Hanselmann <public@hansmi.ch>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <philmd@redhat.com>\nMessage-id: 20190108102301.1957-1-kraxel@redhat.com", "target": 1, "func": "static int i2c_ddc_rx(I2CSlave *i2c)\n{\n    I2CDDCState *s = I2CDDC(i2c);\n\n    int value;\n    value = s->edid_blob[s->reg];\n    s->reg++;\n    return value;\n}", "func_hash": 231715994309117248387350691536475330701, "file_name": "i2c-ddc.c", "file_hash": 48804313309392962475337802621299781910, "cwe": ["CWE-125"], "cve": "CVE-2019-3812", "cve_desc": "QEMU, through version 2.10 and through version 3.1.0, is vulnerable to an out-of-bounds read of up to 128 bytes in the hw/i2c/i2c-ddc.c:i2c_ddc() function. A local attacker with permission to execute i2c commands could exploit this to read stack memory of the qemu process on the host.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-3812", "file_path": "hw/i2c/i2c-ddc.c"}
{"idx": 432346, "project": "qemu", "commit_id": "b05b267840515730dbf6753495d5b7bd8b04ad1c", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://github.com/qemu/qemu/commit/b05b267840515730dbf6753495d5b7bd8b04ad1c", "commit_message": "i2c-ddc: fix oob read\n\nSuggested-by: Michael Hanselmann <public@hansmi.ch>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>\nReviewed-by: Michael Hanselmann <public@hansmi.ch>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <philmd@redhat.com>\nMessage-id: 20190108102301.1957-1-kraxel@redhat.com", "target": 0, "func": "static int i2c_ddc_rx(I2CSlave *i2c)\n{\n    I2CDDCState *s = I2CDDC(i2c);\n\n    int value;\n    value = s->edid_blob[s->reg % sizeof(s->edid_blob)];\n    s->reg++;\n    return value;\n}", "func_hash": 197849623050732713088444316780408422340, "file_name": "i2c-ddc.c", "file_hash": 241703496436230749148573739318246335373, "cwe": ["CWE-125"], "cve": "CVE-2019-3812", "cve_desc": "QEMU, through version 2.10 and through version 3.1.0, is vulnerable to an out-of-bounds read of up to 128 bytes in the hw/i2c/i2c-ddc.c:i2c_ddc() function. A local attacker with permission to execute i2c commands could exploit this to read stack memory of the qemu process on the host.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2019-3812", "file_path": "hw/i2c/i2c-ddc.c"}
{"idx": 210283, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "target": 1, "func": "vhost_user_set_inflight_fd(struct virtio_net **pdev,\n\t\t\t   struct vhu_msg_context *ctx,\n\t\t\t   int main_fd __rte_unused)\n{\n\tuint64_t mmap_size, mmap_offset;\n\tuint16_t num_queues, queue_size;\n\tstruct virtio_net *dev = *pdev;\n\tuint32_t pervq_inflight_size;\n\tstruct vhost_virtqueue *vq;\n\tvoid *addr;\n\tint fd, i;\n\tint numa_node = SOCKET_ID_ANY;\n\n\tfd = ctx->fds[0];\n\tif (ctx->msg.size != sizeof(ctx->msg.payload.inflight) || fd < 0) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) invalid set_inflight_fd message size is %d,fd is %d\\n\",\n\t\t\tdev->ifname, ctx->msg.size, fd);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\tmmap_size = ctx->msg.payload.inflight.mmap_size;\n\tmmap_offset = ctx->msg.payload.inflight.mmap_offset;\n\tnum_queues = ctx->msg.payload.inflight.num_queues;\n\tqueue_size = ctx->msg.payload.inflight.queue_size;\n\n\tif (vq_is_packed(dev))\n\t\tpervq_inflight_size = get_pervq_shm_size_packed(queue_size);\n\telse\n\t\tpervq_inflight_size = get_pervq_shm_size_split(queue_size);\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd mmap_size: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, mmap_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd mmap_offset: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, mmap_offset);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd num_queues: %u\\n\", dev->ifname, num_queues);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd queue_size: %u\\n\", dev->ifname, queue_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd fd: %d\\n\", dev->ifname, fd);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd pervq_inflight_size: %d\\n\",\n\t\t\tdev->ifname, pervq_inflight_size);\n\n\t/*\n\t * If VQ 0 has already been allocated, try to allocate on the same\n\t * NUMA node. It can be reallocated later in numa_realloc().\n\t */\n\tif (dev->nr_vring > 0)\n\t\tnuma_node = dev->virtqueue[0]->numa_node;\n\n\tif (!dev->inflight_info) {\n\t\tdev->inflight_info = rte_zmalloc_socket(\"inflight_info\",\n\t\t\t\tsizeof(struct inflight_mem_info), 0, numa_node);\n\t\tif (dev->inflight_info == NULL) {\n\t\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc dev inflight area\\n\",\n\t\t\t\t\tdev->ifname);\n\t\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t\t}\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tif (dev->inflight_info->addr) {\n\t\tmunmap(dev->inflight_info->addr, dev->inflight_info->size);\n\t\tdev->inflight_info->addr = NULL;\n\t}\n\n\taddr = mmap(0, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t    fd, mmap_offset);\n\tif (addr == MAP_FAILED) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to mmap share memory.\\n\", dev->ifname);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\tif (dev->inflight_info->fd >= 0) {\n\t\tclose(dev->inflight_info->fd);\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tdev->inflight_info->fd = fd;\n\tdev->inflight_info->addr = addr;\n\tdev->inflight_info->size = mmap_size;\n\n\tfor (i = 0; i < num_queues; i++) {\n\t\tvq = dev->virtqueue[i];\n\t\tif (!vq)\n\t\t\tcontinue;\n\n\t\tif (vq_is_packed(dev)) {\n\t\t\tvq->inflight_packed = addr;\n\t\t\tvq->inflight_packed->desc_num = queue_size;\n\t\t} else {\n\t\t\tvq->inflight_split = addr;\n\t\t\tvq->inflight_split->desc_num = queue_size;\n\t\t}\n\t\taddr = (void *)((char *)addr + pervq_inflight_size);\n\t}\n\n\treturn RTE_VHOST_MSG_RESULT_OK;\n}", "func_hash": 13095885723937845585670342074688916492, "file_name": "vhost_user.c", "file_hash": 63503821127437927181843920110423384686, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0669", "file_path": "lib/vhost/vhost_user.c"}
{"idx": 432351, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "target": 0, "func": "vhost_user_set_inflight_fd(struct virtio_net **pdev,\n\t\t\t   struct vhu_msg_context *ctx,\n\t\t\t   int main_fd __rte_unused)\n{\n\tuint64_t mmap_size, mmap_offset;\n\tuint16_t num_queues, queue_size;\n\tstruct virtio_net *dev = *pdev;\n\tuint32_t pervq_inflight_size;\n\tstruct vhost_virtqueue *vq;\n\tvoid *addr;\n\tint fd, i;\n\tint numa_node = SOCKET_ID_ANY;\n\n\tif (validate_msg_fds(dev, ctx, 1) != 0)\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\n\tfd = ctx->fds[0];\n\tif (ctx->msg.size != sizeof(ctx->msg.payload.inflight) || fd < 0) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) invalid set_inflight_fd message size is %d,fd is %d\\n\",\n\t\t\tdev->ifname, ctx->msg.size, fd);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\tmmap_size = ctx->msg.payload.inflight.mmap_size;\n\tmmap_offset = ctx->msg.payload.inflight.mmap_offset;\n\tnum_queues = ctx->msg.payload.inflight.num_queues;\n\tqueue_size = ctx->msg.payload.inflight.queue_size;\n\n\tif (vq_is_packed(dev))\n\t\tpervq_inflight_size = get_pervq_shm_size_packed(queue_size);\n\telse\n\t\tpervq_inflight_size = get_pervq_shm_size_split(queue_size);\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd mmap_size: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, mmap_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd mmap_offset: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, mmap_offset);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd num_queues: %u\\n\", dev->ifname, num_queues);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd queue_size: %u\\n\", dev->ifname, queue_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd fd: %d\\n\", dev->ifname, fd);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) set_inflight_fd pervq_inflight_size: %d\\n\",\n\t\t\tdev->ifname, pervq_inflight_size);\n\n\t/*\n\t * If VQ 0 has already been allocated, try to allocate on the same\n\t * NUMA node. It can be reallocated later in numa_realloc().\n\t */\n\tif (dev->nr_vring > 0)\n\t\tnuma_node = dev->virtqueue[0]->numa_node;\n\n\tif (!dev->inflight_info) {\n\t\tdev->inflight_info = rte_zmalloc_socket(\"inflight_info\",\n\t\t\t\tsizeof(struct inflight_mem_info), 0, numa_node);\n\t\tif (dev->inflight_info == NULL) {\n\t\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc dev inflight area\\n\",\n\t\t\t\t\tdev->ifname);\n\t\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t\t}\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tif (dev->inflight_info->addr) {\n\t\tmunmap(dev->inflight_info->addr, dev->inflight_info->size);\n\t\tdev->inflight_info->addr = NULL;\n\t}\n\n\taddr = mmap(0, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t    fd, mmap_offset);\n\tif (addr == MAP_FAILED) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to mmap share memory.\\n\", dev->ifname);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\tif (dev->inflight_info->fd >= 0) {\n\t\tclose(dev->inflight_info->fd);\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tdev->inflight_info->fd = fd;\n\tdev->inflight_info->addr = addr;\n\tdev->inflight_info->size = mmap_size;\n\n\tfor (i = 0; i < num_queues; i++) {\n\t\tvq = dev->virtqueue[i];\n\t\tif (!vq)\n\t\t\tcontinue;\n\n\t\tif (vq_is_packed(dev)) {\n\t\t\tvq->inflight_packed = addr;\n\t\t\tvq->inflight_packed->desc_num = queue_size;\n\t\t} else {\n\t\t\tvq->inflight_split = addr;\n\t\t\tvq->inflight_split->desc_num = queue_size;\n\t\t}\n\t\taddr = (void *)((char *)addr + pervq_inflight_size);\n\t}\n\n\treturn RTE_VHOST_MSG_RESULT_OK;\n}", "func_hash": 175493676655646817389391031814281109414, "file_name": "vhost_user.c", "file_hash": 99784894649346629896685974573557095486, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0669", "file_path": "lib/vhost/vhost_user.c"}
{"idx": 210284, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "target": 1, "func": "vhost_user_get_inflight_fd(struct virtio_net **pdev,\n\t\t\t   struct vhu_msg_context *ctx,\n\t\t\t   int main_fd __rte_unused)\n{\n\tstruct rte_vhost_inflight_info_packed *inflight_packed;\n\tuint64_t pervq_inflight_size, mmap_size;\n\tuint16_t num_queues, queue_size;\n\tstruct virtio_net *dev = *pdev;\n\tint fd, i, j;\n\tint numa_node = SOCKET_ID_ANY;\n\tvoid *addr;\n\n\tif (ctx->msg.size != sizeof(ctx->msg.payload.inflight)) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) invalid get_inflight_fd message size is %d\\n\",\n\t\t\tdev->ifname, ctx->msg.size);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\t/*\n\t * If VQ 0 has already been allocated, try to allocate on the same\n\t * NUMA node. It can be reallocated later in numa_realloc().\n\t */\n\tif (dev->nr_vring > 0)\n\t\tnuma_node = dev->virtqueue[0]->numa_node;\n\n\tif (dev->inflight_info == NULL) {\n\t\tdev->inflight_info = rte_zmalloc_socket(\"inflight_info\",\n\t\t\t\tsizeof(struct inflight_mem_info), 0, numa_node);\n\t\tif (!dev->inflight_info) {\n\t\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc dev inflight area\\n\",\n\t\t\t\t\tdev->ifname);\n\t\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t\t}\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tnum_queues = ctx->msg.payload.inflight.num_queues;\n\tqueue_size = ctx->msg.payload.inflight.queue_size;\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) get_inflight_fd num_queues: %u\\n\",\n\t\tdev->ifname, ctx->msg.payload.inflight.num_queues);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) get_inflight_fd queue_size: %u\\n\",\n\t\tdev->ifname, ctx->msg.payload.inflight.queue_size);\n\n\tif (vq_is_packed(dev))\n\t\tpervq_inflight_size = get_pervq_shm_size_packed(queue_size);\n\telse\n\t\tpervq_inflight_size = get_pervq_shm_size_split(queue_size);\n\n\tmmap_size = num_queues * pervq_inflight_size;\n\taddr = inflight_mem_alloc(dev, \"vhost-inflight\", mmap_size, &fd);\n\tif (!addr) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc vhost inflight area\\n\", dev->ifname);\n\t\t\tctx->msg.payload.inflight.mmap_size = 0;\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\tmemset(addr, 0, mmap_size);\n\n\tif (dev->inflight_info->addr) {\n\t\tmunmap(dev->inflight_info->addr, dev->inflight_info->size);\n\t\tdev->inflight_info->addr = NULL;\n\t}\n\n\tif (dev->inflight_info->fd >= 0) {\n\t\tclose(dev->inflight_info->fd);\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tdev->inflight_info->addr = addr;\n\tdev->inflight_info->size = ctx->msg.payload.inflight.mmap_size = mmap_size;\n\tdev->inflight_info->fd = ctx->fds[0] = fd;\n\tctx->msg.payload.inflight.mmap_offset = 0;\n\tctx->fd_num = 1;\n\n\tif (vq_is_packed(dev)) {\n\t\tfor (i = 0; i < num_queues; i++) {\n\t\t\tinflight_packed =\n\t\t\t\t(struct rte_vhost_inflight_info_packed *)addr;\n\t\t\tinflight_packed->used_wrap_counter = 1;\n\t\t\tinflight_packed->old_used_wrap_counter = 1;\n\t\t\tfor (j = 0; j < queue_size; j++)\n\t\t\t\tinflight_packed->desc[j].next = j + 1;\n\t\t\taddr = (void *)((char *)addr + pervq_inflight_size);\n\t\t}\n\t}\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight mmap_size: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, ctx->msg.payload.inflight.mmap_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight mmap_offset: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, ctx->msg.payload.inflight.mmap_offset);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight fd: %d\\n\", dev->ifname, ctx->fds[0]);\n\n\treturn RTE_VHOST_MSG_RESULT_REPLY;\n}", "func_hash": 188145158919819292025512968399906201688, "file_name": "vhost_user.c", "file_hash": 63503821127437927181843920110423384686, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0669", "file_path": "lib/vhost/vhost_user.c"}
{"idx": 432352, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "target": 0, "func": "vhost_user_get_inflight_fd(struct virtio_net **pdev,\n\t\t\t   struct vhu_msg_context *ctx,\n\t\t\t   int main_fd __rte_unused)\n{\n\tstruct rte_vhost_inflight_info_packed *inflight_packed;\n\tuint64_t pervq_inflight_size, mmap_size;\n\tuint16_t num_queues, queue_size;\n\tstruct virtio_net *dev = *pdev;\n\tint fd, i, j;\n\tint numa_node = SOCKET_ID_ANY;\n\tvoid *addr;\n\n\tif (validate_msg_fds(dev, ctx, 0) != 0)\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\n\tif (ctx->msg.size != sizeof(ctx->msg.payload.inflight)) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) invalid get_inflight_fd message size is %d\\n\",\n\t\t\tdev->ifname, ctx->msg.size);\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\n\t/*\n\t * If VQ 0 has already been allocated, try to allocate on the same\n\t * NUMA node. It can be reallocated later in numa_realloc().\n\t */\n\tif (dev->nr_vring > 0)\n\t\tnuma_node = dev->virtqueue[0]->numa_node;\n\n\tif (dev->inflight_info == NULL) {\n\t\tdev->inflight_info = rte_zmalloc_socket(\"inflight_info\",\n\t\t\t\tsizeof(struct inflight_mem_info), 0, numa_node);\n\t\tif (!dev->inflight_info) {\n\t\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc dev inflight area\\n\",\n\t\t\t\t\tdev->ifname);\n\t\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t\t}\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tnum_queues = ctx->msg.payload.inflight.num_queues;\n\tqueue_size = ctx->msg.payload.inflight.queue_size;\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) get_inflight_fd num_queues: %u\\n\",\n\t\tdev->ifname, ctx->msg.payload.inflight.num_queues);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) get_inflight_fd queue_size: %u\\n\",\n\t\tdev->ifname, ctx->msg.payload.inflight.queue_size);\n\n\tif (vq_is_packed(dev))\n\t\tpervq_inflight_size = get_pervq_shm_size_packed(queue_size);\n\telse\n\t\tpervq_inflight_size = get_pervq_shm_size_split(queue_size);\n\n\tmmap_size = num_queues * pervq_inflight_size;\n\taddr = inflight_mem_alloc(dev, \"vhost-inflight\", mmap_size, &fd);\n\tif (!addr) {\n\t\tVHOST_LOG_CONFIG(ERR, \"(%s) failed to alloc vhost inflight area\\n\", dev->ifname);\n\t\t\tctx->msg.payload.inflight.mmap_size = 0;\n\t\treturn RTE_VHOST_MSG_RESULT_ERR;\n\t}\n\tmemset(addr, 0, mmap_size);\n\n\tif (dev->inflight_info->addr) {\n\t\tmunmap(dev->inflight_info->addr, dev->inflight_info->size);\n\t\tdev->inflight_info->addr = NULL;\n\t}\n\n\tif (dev->inflight_info->fd >= 0) {\n\t\tclose(dev->inflight_info->fd);\n\t\tdev->inflight_info->fd = -1;\n\t}\n\n\tdev->inflight_info->addr = addr;\n\tdev->inflight_info->size = ctx->msg.payload.inflight.mmap_size = mmap_size;\n\tdev->inflight_info->fd = ctx->fds[0] = fd;\n\tctx->msg.payload.inflight.mmap_offset = 0;\n\tctx->fd_num = 1;\n\n\tif (vq_is_packed(dev)) {\n\t\tfor (i = 0; i < num_queues; i++) {\n\t\t\tinflight_packed =\n\t\t\t\t(struct rte_vhost_inflight_info_packed *)addr;\n\t\t\tinflight_packed->used_wrap_counter = 1;\n\t\t\tinflight_packed->old_used_wrap_counter = 1;\n\t\t\tfor (j = 0; j < queue_size; j++)\n\t\t\t\tinflight_packed->desc[j].next = j + 1;\n\t\t\taddr = (void *)((char *)addr + pervq_inflight_size);\n\t\t}\n\t}\n\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight mmap_size: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, ctx->msg.payload.inflight.mmap_size);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight mmap_offset: %\"PRIu64\"\\n\",\n\t\t\tdev->ifname, ctx->msg.payload.inflight.mmap_offset);\n\tVHOST_LOG_CONFIG(INFO, \"(%s) send inflight fd: %d\\n\", dev->ifname, ctx->fds[0]);\n\n\treturn RTE_VHOST_MSG_RESULT_REPLY;\n}", "func_hash": 77090797647717556170769908563421841237, "file_name": "vhost_user.c", "file_hash": 99784894649346629896685974573557095486, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0669", "file_path": "lib/vhost/vhost_user.c"}
{"idx": 210393, "project": "vim", "commit_id": "6f98371532fcff911b462d51bc64f2ce8a6ae682", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/6f98371532fcff911b462d51bc64f2ce8a6ae682", "commit_message": "patch 8.2.3884: crash when clearing the argument list while using it\n\nProblem:    Crash when clearing the argument list while using it.\nSolution:   Lock the argument list for \":all\".", "target": 1, "func": "do_arg_all(\n    int\tcount,\n    int\tforceit,\t\t// hide buffers in current windows\n    int keep_tabs)\t\t// keep current tabs, for \":tab drop file\"\n{\n    int\t\ti;\n    win_T\t*wp, *wpnext;\n    char_u\t*opened;\t// Array of weight for which args are open:\n\t\t\t\t//  0: not opened\n\t\t\t\t//  1: opened in other tab\n\t\t\t\t//  2: opened in curtab\n\t\t\t\t//  3: opened in curtab and curwin\n\t\t\t\t//\n    int\t\topened_len;\t// length of opened[]\n    int\t\tuse_firstwin = FALSE;\t// use first window for arglist\n    int\t\ttab_drop_empty_window = FALSE;\n    int\t\tsplit_ret = OK;\n    int\t\tp_ea_save;\n    alist_T\t*alist;\t\t// argument list to be used\n    buf_T\t*buf;\n    tabpage_T\t*tpnext;\n    int\t\thad_tab = cmdmod.cmod_tab;\n    win_T\t*old_curwin, *last_curwin;\n    tabpage_T\t*old_curtab, *last_curtab;\n    win_T\t*new_curwin = NULL;\n    tabpage_T\t*new_curtab = NULL;\n\n#ifdef FEAT_CMDWIN\n    if (cmdwin_type != 0)\n    {\n\temsg(_(e_invalid_in_cmdline_window));\n\treturn;\n    }\n#endif\n    if (ARGCOUNT <= 0)\n    {\n\t// Don't give an error message.  We don't want it when the \":all\"\n\t// command is in the .vimrc.\n\treturn;\n    }\n    setpcmark();\n\n    opened_len = ARGCOUNT;\n    opened = alloc_clear(opened_len);\n    if (opened == NULL)\n\treturn;\n\n    // Autocommands may do anything to the argument list.  Make sure it's not\n    // freed while we are working here by \"locking\" it.  We still have to\n    // watch out for its size to be changed.\n    alist = curwin->w_alist;\n    ++alist->al_refcount;\n\n    old_curwin = curwin;\n    old_curtab = curtab;\n\n# ifdef FEAT_GUI\n    need_mouse_correct = TRUE;\n# endif\n\n    // Try closing all windows that are not in the argument list.\n    // Also close windows that are not full width;\n    // When 'hidden' or \"forceit\" set the buffer becomes hidden.\n    // Windows that have a changed buffer and can't be hidden won't be closed.\n    // When the \":tab\" modifier was used do this for all tab pages.\n    if (had_tab > 0)\n\tgoto_tabpage_tp(first_tabpage, TRUE, TRUE);\n    for (;;)\n    {\n\ttpnext = curtab->tp_next;\n\tfor (wp = firstwin; wp != NULL; wp = wpnext)\n\t{\n\t    wpnext = wp->w_next;\n\t    buf = wp->w_buffer;\n\t    if (buf->b_ffname == NULL\n\t\t    || (!keep_tabs && (buf->b_nwindows > 1\n\t\t\t    || wp->w_width != Columns)))\n\t\ti = opened_len;\n\t    else\n\t    {\n\t\t// check if the buffer in this window is in the arglist\n\t\tfor (i = 0; i < opened_len; ++i)\n\t\t{\n\t\t    if (i < alist->al_ga.ga_len\n\t\t\t    && (AARGLIST(alist)[i].ae_fnum == buf->b_fnum\n\t\t\t\t|| fullpathcmp(alist_name(&AARGLIST(alist)[i]),\n\t\t\t\t\tbuf->b_ffname, TRUE, TRUE) & FPC_SAME))\n\t\t    {\n\t\t\tint weight = 1;\n\n\t\t\tif (old_curtab == curtab)\n\t\t\t{\n\t\t\t    ++weight;\n\t\t\t    if (old_curwin == wp)\n\t\t\t\t++weight;\n\t\t\t}\n\n\t\t\tif (weight > (int)opened[i])\n\t\t\t{\n\t\t\t    opened[i] = (char_u)weight;\n\t\t\t    if (i == 0)\n\t\t\t    {\n\t\t\t\tif (new_curwin != NULL)\n\t\t\t\t    new_curwin->w_arg_idx = opened_len;\n\t\t\t\tnew_curwin = wp;\n\t\t\t\tnew_curtab = curtab;\n\t\t\t    }\n\t\t\t}\n\t\t\telse if (keep_tabs)\n\t\t\t    i = opened_len;\n\n\t\t\tif (wp->w_alist != alist)\n\t\t\t{\n\t\t\t    // Use the current argument list for all windows\n\t\t\t    // containing a file from it.\n\t\t\t    alist_unlink(wp->w_alist);\n\t\t\t    wp->w_alist = alist;\n\t\t\t    ++wp->w_alist->al_refcount;\n\t\t\t}\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\t    wp->w_arg_idx = i;\n\n\t    if (i == opened_len && !keep_tabs)// close this window\n\t    {\n\t\tif (buf_hide(buf) || forceit || buf->b_nwindows > 1\n\t\t\t\t\t\t\t|| !bufIsChanged(buf))\n\t\t{\n\t\t    // If the buffer was changed, and we would like to hide it,\n\t\t    // try autowriting.\n\t\t    if (!buf_hide(buf) && buf->b_nwindows <= 1\n\t\t\t\t\t\t\t && bufIsChanged(buf))\n\t\t    {\n\t\t\tbufref_T    bufref;\n\n\t\t\tset_bufref(&bufref, buf);\n\n\t\t\t(void)autowrite(buf, FALSE);\n\n\t\t\t// check if autocommands removed the window\n\t\t\tif (!win_valid(wp) || !bufref_valid(&bufref))\n\t\t\t{\n\t\t\t    wpnext = firstwin;\t// start all over...\n\t\t\t    continue;\n\t\t\t}\n\t\t    }\n\t\t    // don't close last window\n\t\t    if (ONE_WINDOW\n\t\t\t    && (first_tabpage->tp_next == NULL || !had_tab))\n\t\t\tuse_firstwin = TRUE;\n\t\t    else\n\t\t    {\n\t\t\twin_close(wp, !buf_hide(buf) && !bufIsChanged(buf));\n\n\t\t\t// check if autocommands removed the next window\n\t\t\tif (!win_valid(wpnext))\n\t\t\t    wpnext = firstwin;\t// start all over...\n\t\t    }\n\t\t}\n\t    }\n\t}\n\n\t// Without the \":tab\" modifier only do the current tab page.\n\tif (had_tab == 0 || tpnext == NULL)\n\t    break;\n\n\t// check if autocommands removed the next tab page\n\tif (!valid_tabpage(tpnext))\n\t    tpnext = first_tabpage;\t// start all over...\n\n\tgoto_tabpage_tp(tpnext, TRUE, TRUE);\n    }\n\n    // Open a window for files in the argument list that don't have one.\n    // ARGCOUNT may change while doing this, because of autocommands.\n    if (count > opened_len || count <= 0)\n\tcount = opened_len;\n\n    // Don't execute Win/Buf Enter/Leave autocommands here.\n    ++autocmd_no_enter;\n    ++autocmd_no_leave;\n    last_curwin = curwin;\n    last_curtab = curtab;\n    win_enter(lastwin, FALSE);\n    // \":tab drop file\" should re-use an empty window to avoid \"--remote-tab\"\n    // leaving an empty tab page when executed locally.\n    if (keep_tabs && BUFEMPTY() && curbuf->b_nwindows == 1\n\t\t\t    && curbuf->b_ffname == NULL && !curbuf->b_changed)\n    {\n\tuse_firstwin = TRUE;\n\ttab_drop_empty_window = TRUE;\n    }\n\n    for (i = 0; i < count && !got_int; ++i)\n    {\n\tif (alist == &global_alist && i == global_alist.al_ga.ga_len - 1)\n\t    arg_had_last = TRUE;\n\tif (opened[i] > 0)\n\t{\n\t    // Move the already present window to below the current window\n\t    if (curwin->w_arg_idx != i)\n\t    {\n\t\tFOR_ALL_WINDOWS(wpnext)\n\t\t{\n\t\t    if (wpnext->w_arg_idx == i)\n\t\t    {\n\t\t\tif (keep_tabs)\n\t\t\t{\n\t\t\t    new_curwin = wpnext;\n\t\t\t    new_curtab = curtab;\n\t\t\t}\n\t\t\telse if (wpnext->w_frame->fr_parent\n\t\t\t\t\t\t != curwin->w_frame->fr_parent)\n\t\t\t{\n\t\t\t    emsg(_(\"E249: window layout changed unexpectedly\"));\n\t\t\t    i = count;\n\t\t\t    break;\n\t\t\t}\n\t\t\telse\n\t\t\t    win_move_after(wpnext, curwin);\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\t}\n\telse if (split_ret == OK)\n\t{\n\t    // trigger events for tab drop\n\t    if (tab_drop_empty_window && i == count - 1)\n\t\t--autocmd_no_enter;\n\t    if (!use_firstwin)\t\t// split current window\n\t    {\n\t\tp_ea_save = p_ea;\n\t\tp_ea = TRUE;\t\t// use space from all windows\n\t\tsplit_ret = win_split(0, WSP_ROOM | WSP_BELOW);\n\t\tp_ea = p_ea_save;\n\t\tif (split_ret == FAIL)\n\t\t    continue;\n\t    }\n\t    else    // first window: do autocmd for leaving this buffer\n\t\t--autocmd_no_leave;\n\n\t    // edit file \"i\"\n\t    curwin->w_arg_idx = i;\n\t    if (i == 0)\n\t    {\n\t\tnew_curwin = curwin;\n\t\tnew_curtab = curtab;\n\t    }\n\t    (void)do_ecmd(0, alist_name(&AARGLIST(alist)[i]), NULL, NULL,\n\t\t      ECMD_ONE,\n\t\t      ((buf_hide(curwin->w_buffer)\n\t\t\t   || bufIsChanged(curwin->w_buffer)) ? ECMD_HIDE : 0)\n\t\t\t\t\t\t       + ECMD_OLDBUF, curwin);\n\t    if (tab_drop_empty_window && i == count - 1)\n\t\t++autocmd_no_enter;\n\t    if (use_firstwin)\n\t\t++autocmd_no_leave;\n\t    use_firstwin = FALSE;\n\t}\n\tui_breakcheck();\n\n\t// When \":tab\" was used open a new tab for a new window repeatedly.\n\tif (had_tab > 0 && tabpage_index(NULL) <= p_tpm)\n\t    cmdmod.cmod_tab = 9999;\n    }\n\n    // Remove the \"lock\" on the argument list.\n    alist_unlink(alist);\n\n    --autocmd_no_enter;\n\n    // restore last referenced tabpage's curwin\n    if (last_curtab != new_curtab)\n    {\n\tif (valid_tabpage(last_curtab))\n\t    goto_tabpage_tp(last_curtab, TRUE, TRUE);\n\tif (win_valid(last_curwin))\n\t    win_enter(last_curwin, FALSE);\n    }\n    // to window with first arg\n    if (valid_tabpage(new_curtab))\n\tgoto_tabpage_tp(new_curtab, TRUE, TRUE);\n    if (win_valid(new_curwin))\n\twin_enter(new_curwin, FALSE);\n\n    --autocmd_no_leave;\n    vim_free(opened);\n}", "func_hash": 231413303097445020226238674413950257364, "file_name": "arglist.c", "file_hash": 299441320904377920044719346235855663984, "cwe": ["CWE-416"], "cve": "CVE-2021-4166", "cve_desc": "vim is vulnerable to Out-of-bounds Read", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4166", "file_path": "src/arglist.c"}
{"idx": 434093, "project": "vim", "commit_id": "6f98371532fcff911b462d51bc64f2ce8a6ae682", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/6f98371532fcff911b462d51bc64f2ce8a6ae682", "commit_message": "patch 8.2.3884: crash when clearing the argument list while using it\n\nProblem:    Crash when clearing the argument list while using it.\nSolution:   Lock the argument list for \":all\".", "target": 0, "func": "do_arg_all(\n    int\tcount,\n    int\tforceit,\t\t// hide buffers in current windows\n    int keep_tabs)\t\t// keep current tabs, for \":tab drop file\"\n{\n    int\t\ti;\n    win_T\t*wp, *wpnext;\n    char_u\t*opened;\t// Array of weight for which args are open:\n\t\t\t\t//  0: not opened\n\t\t\t\t//  1: opened in other tab\n\t\t\t\t//  2: opened in curtab\n\t\t\t\t//  3: opened in curtab and curwin\n\t\t\t\t//\n    int\t\topened_len;\t// length of opened[]\n    int\t\tuse_firstwin = FALSE;\t// use first window for arglist\n    int\t\ttab_drop_empty_window = FALSE;\n    int\t\tsplit_ret = OK;\n    int\t\tp_ea_save;\n    alist_T\t*alist;\t\t// argument list to be used\n    buf_T\t*buf;\n    tabpage_T\t*tpnext;\n    int\t\thad_tab = cmdmod.cmod_tab;\n    win_T\t*old_curwin, *last_curwin;\n    tabpage_T\t*old_curtab, *last_curtab;\n    win_T\t*new_curwin = NULL;\n    tabpage_T\t*new_curtab = NULL;\n    int\t\tprev_arglist_locked = arglist_locked;\n\n#ifdef FEAT_CMDWIN\n    if (cmdwin_type != 0)\n    {\n\temsg(_(e_invalid_in_cmdline_window));\n\treturn;\n    }\n#endif\n    if (ARGCOUNT <= 0)\n    {\n\t// Don't give an error message.  We don't want it when the \":all\"\n\t// command is in the .vimrc.\n\treturn;\n    }\n    setpcmark();\n\n    opened_len = ARGCOUNT;\n    opened = alloc_clear(opened_len);\n    if (opened == NULL)\n\treturn;\n\n    // Autocommands may do anything to the argument list.  Make sure it's not\n    // freed while we are working here by \"locking\" it.  We still have to\n    // watch out for its size to be changed.\n    alist = curwin->w_alist;\n    ++alist->al_refcount;\n    arglist_locked = TRUE;\n\n    old_curwin = curwin;\n    old_curtab = curtab;\n\n# ifdef FEAT_GUI\n    need_mouse_correct = TRUE;\n# endif\n\n    // Try closing all windows that are not in the argument list.\n    // Also close windows that are not full width;\n    // When 'hidden' or \"forceit\" set the buffer becomes hidden.\n    // Windows that have a changed buffer and can't be hidden won't be closed.\n    // When the \":tab\" modifier was used do this for all tab pages.\n    if (had_tab > 0)\n\tgoto_tabpage_tp(first_tabpage, TRUE, TRUE);\n    for (;;)\n    {\n\ttpnext = curtab->tp_next;\n\tfor (wp = firstwin; wp != NULL; wp = wpnext)\n\t{\n\t    wpnext = wp->w_next;\n\t    buf = wp->w_buffer;\n\t    if (buf->b_ffname == NULL\n\t\t    || (!keep_tabs && (buf->b_nwindows > 1\n\t\t\t    || wp->w_width != Columns)))\n\t\ti = opened_len;\n\t    else\n\t    {\n\t\t// check if the buffer in this window is in the arglist\n\t\tfor (i = 0; i < opened_len; ++i)\n\t\t{\n\t\t    if (i < alist->al_ga.ga_len\n\t\t\t    && (AARGLIST(alist)[i].ae_fnum == buf->b_fnum\n\t\t\t\t|| fullpathcmp(alist_name(&AARGLIST(alist)[i]),\n\t\t\t\t\tbuf->b_ffname, TRUE, TRUE) & FPC_SAME))\n\t\t    {\n\t\t\tint weight = 1;\n\n\t\t\tif (old_curtab == curtab)\n\t\t\t{\n\t\t\t    ++weight;\n\t\t\t    if (old_curwin == wp)\n\t\t\t\t++weight;\n\t\t\t}\n\n\t\t\tif (weight > (int)opened[i])\n\t\t\t{\n\t\t\t    opened[i] = (char_u)weight;\n\t\t\t    if (i == 0)\n\t\t\t    {\n\t\t\t\tif (new_curwin != NULL)\n\t\t\t\t    new_curwin->w_arg_idx = opened_len;\n\t\t\t\tnew_curwin = wp;\n\t\t\t\tnew_curtab = curtab;\n\t\t\t    }\n\t\t\t}\n\t\t\telse if (keep_tabs)\n\t\t\t    i = opened_len;\n\n\t\t\tif (wp->w_alist != alist)\n\t\t\t{\n\t\t\t    // Use the current argument list for all windows\n\t\t\t    // containing a file from it.\n\t\t\t    alist_unlink(wp->w_alist);\n\t\t\t    wp->w_alist = alist;\n\t\t\t    ++wp->w_alist->al_refcount;\n\t\t\t}\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\t    wp->w_arg_idx = i;\n\n\t    if (i == opened_len && !keep_tabs)// close this window\n\t    {\n\t\tif (buf_hide(buf) || forceit || buf->b_nwindows > 1\n\t\t\t\t\t\t\t|| !bufIsChanged(buf))\n\t\t{\n\t\t    // If the buffer was changed, and we would like to hide it,\n\t\t    // try autowriting.\n\t\t    if (!buf_hide(buf) && buf->b_nwindows <= 1\n\t\t\t\t\t\t\t && bufIsChanged(buf))\n\t\t    {\n\t\t\tbufref_T    bufref;\n\n\t\t\tset_bufref(&bufref, buf);\n\n\t\t\t(void)autowrite(buf, FALSE);\n\n\t\t\t// check if autocommands removed the window\n\t\t\tif (!win_valid(wp) || !bufref_valid(&bufref))\n\t\t\t{\n\t\t\t    wpnext = firstwin;\t// start all over...\n\t\t\t    continue;\n\t\t\t}\n\t\t    }\n\t\t    // don't close last window\n\t\t    if (ONE_WINDOW\n\t\t\t    && (first_tabpage->tp_next == NULL || !had_tab))\n\t\t\tuse_firstwin = TRUE;\n\t\t    else\n\t\t    {\n\t\t\twin_close(wp, !buf_hide(buf) && !bufIsChanged(buf));\n\n\t\t\t// check if autocommands removed the next window\n\t\t\tif (!win_valid(wpnext))\n\t\t\t    wpnext = firstwin;\t// start all over...\n\t\t    }\n\t\t}\n\t    }\n\t}\n\n\t// Without the \":tab\" modifier only do the current tab page.\n\tif (had_tab == 0 || tpnext == NULL)\n\t    break;\n\n\t// check if autocommands removed the next tab page\n\tif (!valid_tabpage(tpnext))\n\t    tpnext = first_tabpage;\t// start all over...\n\n\tgoto_tabpage_tp(tpnext, TRUE, TRUE);\n    }\n\n    // Open a window for files in the argument list that don't have one.\n    // ARGCOUNT may change while doing this, because of autocommands.\n    if (count > opened_len || count <= 0)\n\tcount = opened_len;\n\n    // Don't execute Win/Buf Enter/Leave autocommands here.\n    ++autocmd_no_enter;\n    ++autocmd_no_leave;\n    last_curwin = curwin;\n    last_curtab = curtab;\n    win_enter(lastwin, FALSE);\n    // \":tab drop file\" should re-use an empty window to avoid \"--remote-tab\"\n    // leaving an empty tab page when executed locally.\n    if (keep_tabs && BUFEMPTY() && curbuf->b_nwindows == 1\n\t\t\t    && curbuf->b_ffname == NULL && !curbuf->b_changed)\n    {\n\tuse_firstwin = TRUE;\n\ttab_drop_empty_window = TRUE;\n    }\n\n    for (i = 0; i < count && !got_int; ++i)\n    {\n\tif (alist == &global_alist && i == global_alist.al_ga.ga_len - 1)\n\t    arg_had_last = TRUE;\n\tif (opened[i] > 0)\n\t{\n\t    // Move the already present window to below the current window\n\t    if (curwin->w_arg_idx != i)\n\t    {\n\t\tFOR_ALL_WINDOWS(wpnext)\n\t\t{\n\t\t    if (wpnext->w_arg_idx == i)\n\t\t    {\n\t\t\tif (keep_tabs)\n\t\t\t{\n\t\t\t    new_curwin = wpnext;\n\t\t\t    new_curtab = curtab;\n\t\t\t}\n\t\t\telse if (wpnext->w_frame->fr_parent\n\t\t\t\t\t\t != curwin->w_frame->fr_parent)\n\t\t\t{\n\t\t\t    emsg(_(\"E249: window layout changed unexpectedly\"));\n\t\t\t    i = count;\n\t\t\t    break;\n\t\t\t}\n\t\t\telse\n\t\t\t    win_move_after(wpnext, curwin);\n\t\t\tbreak;\n\t\t    }\n\t\t}\n\t    }\n\t}\n\telse if (split_ret == OK)\n\t{\n\t    // trigger events for tab drop\n\t    if (tab_drop_empty_window && i == count - 1)\n\t\t--autocmd_no_enter;\n\t    if (!use_firstwin)\t\t// split current window\n\t    {\n\t\tp_ea_save = p_ea;\n\t\tp_ea = TRUE;\t\t// use space from all windows\n\t\tsplit_ret = win_split(0, WSP_ROOM | WSP_BELOW);\n\t\tp_ea = p_ea_save;\n\t\tif (split_ret == FAIL)\n\t\t    continue;\n\t    }\n\t    else    // first window: do autocmd for leaving this buffer\n\t\t--autocmd_no_leave;\n\n\t    // edit file \"i\"\n\t    curwin->w_arg_idx = i;\n\t    if (i == 0)\n\t    {\n\t\tnew_curwin = curwin;\n\t\tnew_curtab = curtab;\n\t    }\n\t    (void)do_ecmd(0, alist_name(&AARGLIST(alist)[i]), NULL, NULL,\n\t\t      ECMD_ONE,\n\t\t      ((buf_hide(curwin->w_buffer)\n\t\t\t   || bufIsChanged(curwin->w_buffer)) ? ECMD_HIDE : 0)\n\t\t\t\t\t\t       + ECMD_OLDBUF, curwin);\n\t    if (tab_drop_empty_window && i == count - 1)\n\t\t++autocmd_no_enter;\n\t    if (use_firstwin)\n\t\t++autocmd_no_leave;\n\t    use_firstwin = FALSE;\n\t}\n\tui_breakcheck();\n\n\t// When \":tab\" was used open a new tab for a new window repeatedly.\n\tif (had_tab > 0 && tabpage_index(NULL) <= p_tpm)\n\t    cmdmod.cmod_tab = 9999;\n    }\n\n    // Remove the \"lock\" on the argument list.\n    alist_unlink(alist);\n    arglist_locked = prev_arglist_locked;\n\n    --autocmd_no_enter;\n\n    // restore last referenced tabpage's curwin\n    if (last_curtab != new_curtab)\n    {\n\tif (valid_tabpage(last_curtab))\n\t    goto_tabpage_tp(last_curtab, TRUE, TRUE);\n\tif (win_valid(last_curwin))\n\t    win_enter(last_curwin, FALSE);\n    }\n    // to window with first arg\n    if (valid_tabpage(new_curtab))\n\tgoto_tabpage_tp(new_curtab, TRUE, TRUE);\n    if (win_valid(new_curwin))\n\twin_enter(new_curwin, FALSE);\n\n    --autocmd_no_leave;\n    vim_free(opened);\n}", "func_hash": 267745419662130579869831756599776775733, "file_name": "arglist.c", "file_hash": 117785855197438392738154857809118603392, "cwe": ["CWE-416"], "cve": "CVE-2021-4166", "cve_desc": "vim is vulnerable to Out-of-bounds Read", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4166", "file_path": "src/arglist.c"}
