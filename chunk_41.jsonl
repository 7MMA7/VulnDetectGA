{"idx": 259515, "project": "gpac", "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "commit_message": "fixed #2212", "target": 0, "func": "GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node, GF_FieldInfo *field, Bool is_mem_com)\n{\n\tGF_Err e;\n\tu32 NbBits, nbFields;\n\tu32 i;\n\tGF_ChildNodeItem *last;\n\tu8 qp_local, qp_on, initial_qp;\n\tGF_FieldInfo sffield;\n\n\tmemset(&sffield, 0, sizeof(GF_FieldInfo));\n\tsffield.fieldIndex = field->fieldIndex;\n\tsffield.fieldType = gf_sg_vrml_get_sf_type(field->fieldType);\n\tsffield.NDTtype = field->NDTtype;\n\tsffield.name = field->name;\n\n\tinitial_qp = qp_local = qp_on = 0;\n\n\t//vector description - alloc the MF size before\n\tNbBits = gf_bs_read_int(bs, 5);\n\tnbFields = gf_bs_read_int(bs, NbBits);\n\n\tif (codec->ActiveQP) {\n\t\tinitial_qp = 1;\n\t\t/*this is for QP 14*/\n\t\tgf_bifs_dec_qp14_set_length(codec, nbFields);\n\t}\n\n\tif (field->fieldType != GF_SG_VRML_MFNODE) {\n\t\te = gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields);\n\t\tif (e) return e;\n\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\te = gf_sg_vrml_mf_get_item(field->far_ptr, field->fieldType, & sffield.far_ptr, i);\n\t\t\tif (e) return e;\n\t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n\t\t\tif (e) return e;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\te = GF_OK;\n\tlast = NULL;\n\tfor (i=0; i<nbFields; i++) {\n\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n\t\tif (new_node) {\n\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n\t\t\tif (e) goto exit;\n\n\t\t\tif (node) {\n\t\t\t\t/*special case for QP, register as the current QP*/\n\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n\t\t\t\t\t/*we have a QP in the same scope, remove previous\n\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n\t\t\t\t\twhether QP is cumulative or not*/\n\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n\n\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n\t\t\t\t\tif (e) goto exit;\n\t\t\t\t\tqp_on = 1;\n\t\t\t\t\tif (qp_local) qp_local = 2;\n\t\t\t\t\tif (codec->force_keep_qp) {\n\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\tif (e) goto exit;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tgf_node_register(new_node, NULL);\n\t\t\t\t\t\tgf_node_unregister(new_node, node);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\tif (e) goto exit;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*proto coding*/\n\t\t\telse if (codec->pCurrentProto) {\n\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n\t\t\t\tif (e)goto exit;\n\t\t\t}\n\t\t} else {\n\t\t\te = codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\nexit:\n\n\t/*according to the spec, the QP applies to the current node itself, not just children.\n\tIf IsLocal is TRUE remove the node*/\n\tif (qp_on && qp_local) {\n\t\tif (qp_local == 2) {\n//\t\t\t\tqp_local = 1;\n\t\t} else {\n\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n//\t\t\t\tqp_local = 0;\n\t\t}\n\t}\n\n\t/*finally delete the QP if any (local or not) as we get out of this node*/\n\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n\treturn e;\n}", "func_hash": 87913328330334973477048870942232615519, "file_name": "field_decode.c", "file_hash": 151388572550638562891846673305217274829, "cwe": ["CWE-416"], "cve": "CVE-2022-2453", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2453", "file_path": "src/bifs/field_decode.c"}
{"idx": 197511, "project": "libjpeg", "commit_id": "187035b9726710b4fe11d565c7808975c930895d", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d", "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.", "target": 1, "func": "void HierarchicalBitmapRequester::PrepareForDecoding(void)\n{\n#if ACCUSOFT_CODE\n\n  UBYTE i;\n\n  BuildCommon();\n\n  if (m_ppDecodingMCU == NULL) {\n    m_ppDecodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount*8);\n    memset(m_ppDecodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n\n  if (m_ppUpsampler == NULL) {\n    m_ppUpsampler = (class UpsamplerBase **)m_pEnviron->AllocMem(sizeof(class UpsamplerBase *) * m_ucCount);\n    memset(m_ppUpsampler,0,sizeof(class Upsampler *) * m_ucCount);\n\n    for(i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                          m_ulPixelWidth,m_ulPixelHeight,\n                                                          m_pFrame->TablesOf()->isChromaCentered());\n        m_bSubsampling   = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForDecoding();\n#endif\n}", "func_hash": 63468052144489012470048601021040613418, "file_name": "hierarchicalbitmaprequester.cpp", "file_hash": 34345221108539770458549868924228630502, "cwe": ["CWE-787"], "cve": "CVE-2022-31796", "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796", "file_path": "control/hierarchicalbitmaprequester.cpp"}
{"idx": 259619, "project": "libjpeg", "commit_id": "187035b9726710b4fe11d565c7808975c930895d", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d", "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.", "target": 0, "func": "void HierarchicalBitmapRequester::PrepareForEncoding(void)\n{\n#if ACCUSOFT_CODE\n  \n  BuildCommon();\n\n  if (m_ppEncodingMCU == NULL) {\n    m_ppEncodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount *8);\n    memset(m_ppEncodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n  \n  if (m_ppDownsampler == NULL) {\n    m_ppDownsampler = (class DownsamplerBase **)m_pEnviron->AllocMem(sizeof(class DownsamplerBase *) * m_ucCount);\n    memset(m_ppDownsampler,0,sizeof(class DownsamplerBase *) * m_ucCount);\n    \n    for(UBYTE i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppDownsampler[i] = DownsamplerBase::CreateDownsampler(m_pEnviron,sx,sy,\n                                                                m_ulPixelWidth,m_ulPixelHeight,\n                                                                m_pFrame->TablesOf()->\n                                                                isDownsamplingInterpolated());\n        m_bSubsampling     = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForEncoding();\n#endif\n}", "func_hash": 163837755851062573337491873573690435408, "file_name": "hierarchicalbitmaprequester.cpp", "file_hash": 103246407112165898630439185486735063817, "cwe": ["CWE-787"], "cve": "CVE-2022-31796", "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796", "file_path": "control/hierarchicalbitmaprequester.cpp"}
{"idx": 197518, "project": "tensorflow", "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58", "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }", "func_hash": 234673676615434385684756936171703208879, "file_name": "quantize_and_dequantize_op.cc", "file_hash": 339380707229520344979853528458088260159, "cwe": ["CWE-703"], "cve": "CVE-2022-29192", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192", "file_path": "tensorflow/core/kernels/quantize_and_dequantize_op.cc"}
{"idx": 259732, "project": "tensorflow", "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58", "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 0 or 1. Received \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 0 or 1. Received \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n                  errors::InvalidArgument(\n                      \"input_min must be a scalar if axis is unspecified\"));\n      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n                  errors::InvalidArgument(\n                      \"input_max must be a scalar if axis is unspecified\"));\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }", "func_hash": 287418587934128745776529470108188021327, "file_name": "quantize_and_dequantize_op.cc", "file_hash": 149077864405379849027595796830913818555, "cwe": ["CWE-703"], "cve": "CVE-2022-29192", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192", "file_path": "tensorflow/core/kernels/quantize_and_dequantize_op.cc"}
