{"idx": 196578, "project": "vim", "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/44db8213d38c39877d2148eff6a72f4beccfb94e", "commit_message": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.", "target": 1, "func": "yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n{\n    char_u\t*pnew;\n\n    if (exclude_trailing_space)\n\tbd->endspaces = 0;\n    if ((pnew = alloc(bd->startspaces + bd->endspaces + bd->textlen + 1))\n\t\t\t\t\t\t\t\t      == NULL)\n\treturn FAIL;\n    y_current->y_array[y_idx] = pnew;\n    vim_memset(pnew, ' ', (size_t)bd->startspaces);\n    pnew += bd->startspaces;\n    mch_memmove(pnew, bd->textstart, (size_t)bd->textlen);\n    pnew += bd->textlen;\n    vim_memset(pnew, ' ', (size_t)bd->endspaces);\n    pnew += bd->endspaces;\n    if (exclude_trailing_space)\n    {\n\tint s = bd->textlen + bd->endspaces;\n\n\twhile (VIM_ISWHITE(*(bd->textstart + s - 1)) && s > 0)\n\t{\n\t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n\t    pnew--;\n\t}\n    }\n    *pnew = NUL;\n    return OK;\n}", "func_hash": 329046653104270093704788517563971777510, "file_name": "register.c", "file_hash": 197045442768005159362544298682780980387, "cwe": ["CWE-787"], "cve": "CVE-2022-0407", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0407", "file_path": "src/register.c"}
{"idx": 240276, "project": "vim", "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/44db8213d38c39877d2148eff6a72f4beccfb94e", "commit_message": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.", "target": 0, "func": "yank_copy_line(struct block_def *bd, long y_idx, int exclude_trailing_space)\n{\n    char_u\t*pnew;\n\n    if (exclude_trailing_space)\n\tbd->endspaces = 0;\n    if ((pnew = alloc(bd->startspaces + bd->endspaces + bd->textlen + 1))\n\t\t\t\t\t\t\t\t      == NULL)\n\treturn FAIL;\n    y_current->y_array[y_idx] = pnew;\n    vim_memset(pnew, ' ', (size_t)bd->startspaces);\n    pnew += bd->startspaces;\n    mch_memmove(pnew, bd->textstart, (size_t)bd->textlen);\n    pnew += bd->textlen;\n    vim_memset(pnew, ' ', (size_t)bd->endspaces);\n    pnew += bd->endspaces;\n    if (exclude_trailing_space)\n    {\n\tint s = bd->textlen + bd->endspaces;\n\n\twhile (s > 0 && VIM_ISWHITE(*(bd->textstart + s - 1)))\n\t{\n\t    s = s - (*mb_head_off)(bd->textstart, bd->textstart + s - 1) - 1;\n\t    pnew--;\n\t}\n    }\n    *pnew = NUL;\n    return OK;\n}", "func_hash": 215111577434116975174543951046273639484, "file_name": "register.c", "file_hash": 303069020104340496076924952267660178460, "cwe": ["CWE-787"], "cve": "CVE-2022-0407", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-0407", "file_path": "src/register.c"}
{"idx": 196587, "project": "tensorflow", "commit_id": "4aacb30888638da75023e6601149415b39763d76", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76", "commit_message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c", "target": 1, "func": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }", "func_hash": 322924980951140877428129021875471736973, "file_name": "resource_variable_ops.cc", "file_hash": 290989719174845979221072798512679804902, "cwe": ["CWE-369"], "cve": "CVE-2021-37642", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37642", "file_path": "tensorflow/core/ops/resource_variable_ops.cc"}
{"idx": 240595, "project": "tensorflow", "commit_id": "4aacb30888638da75023e6601149415b39763d76", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76", "commit_message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c", "target": 0, "func": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    // Prevent division by 0\n    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n      OP_REQUIRES(c, ValidateInput<T>(updates),\n                  errors::InvalidArgument(\"updates must not contain 0\"));\n    }\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }", "func_hash": 249042864160254570036396062378524137135, "file_name": "resource_variable_ops.cc", "file_hash": 303304073982532975843126024441239469279, "cwe": ["CWE-369"], "cve": "CVE-2021-37642", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37642", "file_path": "tensorflow/core/ops/resource_variable_ops.cc"}
{"idx": 196611, "project": "booth", "commit_id": "35bf0b7b048d715f671eb68974fb6b4af6528c67", "project_url": "https://github.com/ClusterLabs/booth", "commit_url": "https://github.com/ClusterLabs/booth/commit/35bf0b7b048d715f671eb68974fb6b4af6528c67", "commit_message": "Revert \"Refactor: main: substitute is_auth_req macro\"\n\nThis reverts commit da79b8ba28ad4837a0fee13e5f8fb6f89fe0e24c.\n\nauthfile != authkey\n\nSigned-off-by: Jan Friesse <jfriesse@redhat.com>", "target": 1, "func": "static int setup_config(int type)\n{\n\tint rv;\n\n\trv = read_config(cl.configfile, type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\tif (is_auth_req()) {\n\t\trv = read_authkey();\n\t\tif (rv < 0)\n\t\t\tgoto out;\n#if HAVE_LIBGCRYPT\n\t\tif (!gcry_check_version(NULL)) {\n\t\t\tlog_error(\"gcry_check_version\");\n\t\t\trv = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tgcry_control(GCRYCTL_DISABLE_SECMEM, 0);\n\t\tgcry_control(GCRYCTL_INITIALIZATION_FINISHED, 0);\n#endif\n\t}\n\n\t/* Set \"local\" pointer, ignoring errors. */\n\tif (cl.type == DAEMON && cl.site[0]) {\n\t\tif (!find_site_by_name(cl.site, &local, 1)) {\n\t\t\tlog_error(\"Cannot find \\\"%s\\\" in the configuration.\",\n\t\t\t\t\tcl.site);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlocal->local = 1;\n\t} else\n\t\tfind_myself(NULL, type == CLIENT || type == GEOSTORE);\n\n\n\trv = check_config(type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\n\t/* Per default the PID file name is derived from the\n\t * configuration name. */\n\tif (!cl.lockfile[0]) {\n\t\tsnprintf(cl.lockfile, sizeof(cl.lockfile)-1,\n\t\t\t\t\"%s/%s.pid\", BOOTH_RUN_DIR, booth_conf->name);\n\t}\n\nout:\n\treturn rv;\n}", "func_hash": 170997267947585139967201027163993257008, "file_name": "main.c", "file_hash": 4814718832295442874488153140310945385, "cwe": ["CWE-284"], "cve": "CVE-2022-2553", "cve_desc": "The authfile directive in the booth config file is ignored, preventing use of authentication in communications from node to node. As a result, nodes that do not have the correct authentication key are not prevented from communicating with other nodes in the cluster.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2553", "file_path": "src/main.c"}
{"idx": 241040, "project": "booth", "commit_id": "35bf0b7b048d715f671eb68974fb6b4af6528c67", "project_url": "https://github.com/ClusterLabs/booth", "commit_url": "https://github.com/ClusterLabs/booth/commit/35bf0b7b048d715f671eb68974fb6b4af6528c67", "commit_message": "Revert \"Refactor: main: substitute is_auth_req macro\"\n\nThis reverts commit da79b8ba28ad4837a0fee13e5f8fb6f89fe0e24c.\n\nauthfile != authkey\n\nSigned-off-by: Jan Friesse <jfriesse@redhat.com>", "target": 0, "func": "static int setup_config(int type)\n{\n\tint rv;\n\n\trv = read_config(cl.configfile, type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\tif (booth_conf->authfile[0] != '\\0') {\n\t\trv = read_authkey();\n\t\tif (rv < 0)\n\t\t\tgoto out;\n#if HAVE_LIBGCRYPT\n\t\tif (!gcry_check_version(NULL)) {\n\t\t\tlog_error(\"gcry_check_version\");\n\t\t\trv = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tgcry_control(GCRYCTL_DISABLE_SECMEM, 0);\n\t\tgcry_control(GCRYCTL_INITIALIZATION_FINISHED, 0);\n#endif\n\t}\n\n\t/* Set \"local\" pointer, ignoring errors. */\n\tif (cl.type == DAEMON && cl.site[0]) {\n\t\tif (!find_site_by_name(cl.site, &local, 1)) {\n\t\t\tlog_error(\"Cannot find \\\"%s\\\" in the configuration.\",\n\t\t\t\t\tcl.site);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlocal->local = 1;\n\t} else\n\t\tfind_myself(NULL, type == CLIENT || type == GEOSTORE);\n\n\n\trv = check_config(type);\n\tif (rv < 0)\n\t\tgoto out;\n\n\n\t/* Per default the PID file name is derived from the\n\t * configuration name. */\n\tif (!cl.lockfile[0]) {\n\t\tsnprintf(cl.lockfile, sizeof(cl.lockfile)-1,\n\t\t\t\t\"%s/%s.pid\", BOOTH_RUN_DIR, booth_conf->name);\n\t}\n\nout:\n\treturn rv;\n}", "func_hash": 89622919560301199125405967494920550093, "file_name": "main.c", "file_hash": 219733327123326706215521846542751103807, "cwe": ["CWE-284"], "cve": "CVE-2022-2553", "cve_desc": "The authfile directive in the booth config file is ignored, preventing use of authentication in communications from node to node. As a result, nodes that do not have the correct authentication key are not prevented from communicating with other nodes in the cluster.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2553", "file_path": "src/main.c"}
{"idx": 196629, "project": "tensorflow", "commit_id": "579261dcd446385831fe4f7457d802a59685121d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d", "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335", "target": 1, "func": "  void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const Tensor& rhs = context->input(1);\n    const int ndims = input.dims();\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 nrhs = rhs.dim_size(ndims - 1);\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dims() == ndims,\n                      errors::InvalidArgument(\n                          \"Input and right-hand side must have same rank, got \",\n                          ndims, \" != \", rhs.dims()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, input.dim_size(ndims - 2) == n,\n        errors::InvalidArgument(\"Input matrices must be squares, got\",\n                                input.dim_size(ndims - 2), \" != \", n),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                      errors::InvalidArgument(\n                          \"Input matrix and right-hand side must have the \"\n                          \"same number of rows, got\",\n                          n, \" != \", rhs.dim_size(ndims - 2)),\n                      done);\n\n    // Allocate output.\n    Tensor* output;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->forward_input_or_allocate_output({1}, 0, rhs.shape(), &output),\n        done);\n\n    // To be consistent with the MatrixInverse op, we define the solution for\n    // an empty set of equations as the empty matrix.\n    if (input.NumElements() == 0 || rhs.NumElements() == 0) {\n      done();\n      return;\n    }\n\n    // TODO(rmlarsen): Convert to std::make_unique when available.\n    std::unique_ptr<CudaSolver> solver(new CudaSolver(context));\n\n    // Make a copy of the input for the factorization step, or, if adjoint_ is\n    // false, try to reuse the input buffer if this op owns it exclusively.\n    Tensor input_copy;\n    const GPUDevice& device = context->eigen_device<GPUDevice>();\n    if (adjoint_) {\n      // For the adjoint case, it is simpler to always make a transposed copy up\n      // front.\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                         input.shape(), &input_copy),\n          done);\n      OP_REQUIRES_OK_ASYNC(context,\n                           DoMatrixTranspose(device, input, &input_copy), done);\n    } else {\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->forward_input_or_allocate_scoped_tensor(\n              {0}, DataTypeToEnum<Scalar>::value, input.shape(), &input_copy),\n          done);\n      if (!input.SharesBufferWith(input_copy)) {\n        device.memcpy(input_copy.flat<Scalar>().data(),\n                      input.flat<Scalar>().data(),\n                      input.NumElements() * sizeof(Scalar));\n      }\n    }\n    auto input_copy_reshaped = input_copy.template flat_inner_dims<Scalar, 3>();\n    const int64 batch_size = input_copy_reshaped.dimension(0);\n\n    // Allocate pivots on the device.\n    Tensor pivots;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<int>::value,\n                                       TensorShape{batch_size, n}, &pivots),\n        done);\n    auto pivots_mat = pivots.template matrix<int>();\n\n    // 1. Compute the partially pivoted LU factorization(s) of the\n    // matrix/matrices.\n    std::vector<DeviceLapackInfo> dev_info;\n    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copt_ptrs\",\n        /* on_host */ true);\n    const int kMaxMatrixSizeToBatchSizeRatio = 128;\n    const bool use_batched_solver =\n        n <= kMaxMatrixSizeToBatchSizeRatio * batch_size;\n    if (use_batched_solver) {\n      // For small matrices or large batch sizes, we use the batched interface\n      // from cuBlas.\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptrs.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n      }\n      dev_info.push_back(\n          solver->GetDeviceLapackInfo(batch_size, \"getrfBatched\"));\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrfBatched(n, input_copy_ptrs_base, n, pivots_mat.data(),\n                               &dev_info.back(), batch_size),\n          done);\n    } else {\n      // For small batch sizes or large matrices, we use the non-batched\n      // interface from cuSolver, which is much faster for large matrices.\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrf\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrf(n, n, &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0), &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 2. Make a transposed copy of the right-hand sides. This is necessary\n    // because cuBLAS assumes column-major storage while TensorFlow TF uses\n    // row-major.\n    TensorShape transposed_rhs_shape(rhs.shape());\n    transposed_rhs_shape.RemoveLastDims(2);\n    transposed_rhs_shape.AddDim(nrhs);\n    transposed_rhs_shape.AddDim(n);\n    Tensor transposed_rhs;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                       transposed_rhs_shape, &transposed_rhs),\n        done);\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, rhs, &transposed_rhs), done);\n    } else {\n      device.memcpy(transposed_rhs.flat<Scalar>().data(),\n                    rhs.flat<Scalar>().data(),\n                    rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // 3. Solve op(A) X = B (in column major form).\n    // We use a trick here: If adjoint_ is true, we converted A to column major\n    // form above. If adjoint is false then I leave A in row-major form and use\n    // trans_a = CUBLAS_OP_T to effectively transform it to column-major on the\n    // fly. (This means that we actually use the LU-factorization of A^T in that\n    // case, but that is equally good for solving AX=B). This way we save an\n    // explicit transpose in the more common case of adjoint_ == false.\n    auto input_copy_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copy_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"transposed_rhs_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_reshaped =\n        transposed_rhs.template flat_inner_dims<Scalar, 3>();\n    if (use_batched_solver) {\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptr_array.mutable_data());\n      const Scalar** transposed_rhs_ptrs_base =\n          reinterpret_cast<const Scalar**>(\n              transposed_rhs_ptr_array.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n        transposed_rhs_ptrs_base[batch] = &transposed_rhs_reshaped(batch, 0, 0);\n      }\n      int host_info = 0;\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrsBatched(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                               input_copy_ptrs_base, n, pivots_mat.data(),\n                               transposed_rhs_ptrs_base, n, &host_info,\n                               batch_size),\n          done);\n      OP_REQUIRES_ASYNC(\n          context, host_info == 0,\n          errors::InvalidArgument(\"The \", -host_info,\n                                  \"'th argument to cublas*getrsBatched had \"\n                                  \"an illegal value.\"),\n          done);\n    } else {\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrs\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrs(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                          &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0),\n                          &transposed_rhs_reshaped(batch, 0, 0), n,\n                          &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 4. Transpose X to get the final result in row-major form.\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, transposed_rhs, output), done);\n    } else {\n      device.memcpy(output->flat<Scalar>().data(),\n                    transposed_rhs.flat<Scalar>().data(),\n                    transposed_rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // Callback for checking info after kernels finish. Also capture the\n    // temporary Tensors/ScratchSpace so they don't get deallocated before the\n    // kernels run. TODO(rmlarsen): Use move capture once C++14 becomes\n    // available.\n    auto info_checker = [context, done, dev_info](\n                            const Status& status,\n                            const std::vector<HostLapackInfo>& host_infos) {\n      if (!status.ok() && errors::IsInvalidArgument(status) &&\n          !host_infos.empty()) {\n        for (int i = 0; i < host_infos[0].size(); ++i) {\n          // Match the CPU error message for singular matrices. Otherwise\n          // just print the original error message from the status below.\n          OP_REQUIRES_ASYNC(context, host_infos[0].data()[i] <= 0,\n                            errors::InvalidArgument(kErrMsg), done);\n        }\n      }\n      OP_REQUIRES_OK_ASYNC(context, status, done);\n      done();\n    };\n    CudaSolver::CheckLapackInfoAndDeleteSolverAsync(std::move(solver), dev_info,\n                                                    std::move(info_checker));\n  }", "func_hash": 232512673394609281083836207268567643755, "file_name": "matrix_solve_op.cc", "file_hash": 18056043033202767652193305242094140715, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206", "file_path": "tensorflow/core/kernels/linalg/matrix_solve_op.cc"}
{"idx": 241369, "project": "tensorflow", "commit_id": "579261dcd446385831fe4f7457d802a59685121d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d", "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335", "target": 0, "func": "  void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const Tensor& rhs = context->input(1);\n    const int ndims = input.dims();\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 nrhs = rhs.dim_size(ndims - 1);\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dims() == ndims,\n                      errors::InvalidArgument(\n                          \"Input and right-hand side must have same rank, got \",\n                          ndims, \" != \", rhs.dims()),\n                      done);\n    OP_REQUIRES_ASYNC(\n        context, input.dim_size(ndims - 2) == n,\n        errors::InvalidArgument(\"Input matrices must be squares, got \",\n                                input.dim_size(ndims - 2), \" != \", n),\n        done);\n    OP_REQUIRES_ASYNC(context, rhs.dim_size(ndims - 2) == n,\n                      errors::InvalidArgument(\n                          \"Input matrix and right-hand side must have the \"\n                          \"same number of rows, got \",\n                          n, \" != \", rhs.dim_size(ndims - 2)),\n                      done);\n    for (int dim = 0; dim < ndims - 2; dim++) {\n      OP_REQUIRES_ASYNC(\n          context, input.dim_size(dim) == rhs.dim_size(dim),\n          errors::InvalidArgument(\n              \"All input tensors must have the same outer dimensions.\"),\n          done);\n    }\n\n    // Allocate output.\n    Tensor* output;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        context->forward_input_or_allocate_output({1}, 0, rhs.shape(), &output),\n        done);\n\n    // To be consistent with the MatrixInverse op, we define the solution for\n    // an empty set of equations as the empty matrix.\n    if (input.NumElements() == 0 || rhs.NumElements() == 0) {\n      done();\n      return;\n    }\n\n    // TODO(rmlarsen): Convert to std::make_unique when available.\n    std::unique_ptr<CudaSolver> solver(new CudaSolver(context));\n\n    // Make a copy of the input for the factorization step, or, if adjoint_ is\n    // false, try to reuse the input buffer if this op owns it exclusively.\n    Tensor input_copy;\n    const GPUDevice& device = context->eigen_device<GPUDevice>();\n    if (adjoint_) {\n      // For the adjoint case, it is simpler to always make a transposed copy up\n      // front.\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                         input.shape(), &input_copy),\n          done);\n      OP_REQUIRES_OK_ASYNC(context,\n                           DoMatrixTranspose(device, input, &input_copy), done);\n    } else {\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->forward_input_or_allocate_scoped_tensor(\n              {0}, DataTypeToEnum<Scalar>::value, input.shape(), &input_copy),\n          done);\n      if (!input.SharesBufferWith(input_copy)) {\n        device.memcpy(input_copy.flat<Scalar>().data(),\n                      input.flat<Scalar>().data(),\n                      input.NumElements() * sizeof(Scalar));\n      }\n    }\n    auto input_copy_reshaped = input_copy.template flat_inner_dims<Scalar, 3>();\n    const int64 batch_size = input_copy_reshaped.dimension(0);\n\n    // Allocate pivots on the device.\n    Tensor pivots;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<int>::value,\n                                       TensorShape{batch_size, n}, &pivots),\n        done);\n    auto pivots_mat = pivots.template matrix<int>();\n\n    // 1. Compute the partially pivoted LU factorization(s) of the\n    // matrix/matrices.\n    std::vector<DeviceLapackInfo> dev_info;\n    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copt_ptrs\",\n        /* on_host */ true);\n    const int kMaxMatrixSizeToBatchSizeRatio = 128;\n    const bool use_batched_solver =\n        n <= kMaxMatrixSizeToBatchSizeRatio * batch_size;\n    if (use_batched_solver) {\n      // For small matrices or large batch sizes, we use the batched interface\n      // from cuBlas.\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptrs.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n      }\n      dev_info.push_back(\n          solver->GetDeviceLapackInfo(batch_size, \"getrfBatched\"));\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrfBatched(n, input_copy_ptrs_base, n, pivots_mat.data(),\n                               &dev_info.back(), batch_size),\n          done);\n    } else {\n      // For small batch sizes or large matrices, we use the non-batched\n      // interface from cuSolver, which is much faster for large matrices.\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrf\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrf(n, n, &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0), &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 2. Make a transposed copy of the right-hand sides. This is necessary\n    // because cuBLAS assumes column-major storage while TensorFlow TF uses\n    // row-major.\n    TensorShape transposed_rhs_shape(rhs.shape());\n    transposed_rhs_shape.RemoveLastDims(2);\n    transposed_rhs_shape.AddDim(nrhs);\n    transposed_rhs_shape.AddDim(n);\n    Tensor transposed_rhs;\n    OP_REQUIRES_OK_ASYNC(\n        context,\n        solver->allocate_scoped_tensor(DataTypeToEnum<Scalar>::value,\n                                       transposed_rhs_shape, &transposed_rhs),\n        done);\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, rhs, &transposed_rhs), done);\n    } else {\n      device.memcpy(transposed_rhs.flat<Scalar>().data(),\n                    rhs.flat<Scalar>().data(),\n                    rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // 3. Solve op(A) X = B (in column major form).\n    // We use a trick here: If adjoint_ is true, we converted A to column major\n    // form above. If adjoint is false then I leave A in row-major form and use\n    // trans_a = CUBLAS_OP_T to effectively transform it to column-major on the\n    // fly. (This means that we actually use the LU-factorization of A^T in that\n    // case, but that is equally good for solving AX=B). This way we save an\n    // explicit transpose in the more common case of adjoint_ == false.\n    auto input_copy_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"input_copy_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8>(\n        sizeof(Scalar*) * batch_size, \"transposed_rhs_ptr_array\",\n        /* on_host */ true);\n    auto transposed_rhs_reshaped =\n        transposed_rhs.template flat_inner_dims<Scalar, 3>();\n    if (use_batched_solver) {\n      const Scalar** input_copy_ptrs_base =\n          reinterpret_cast<const Scalar**>(input_copy_ptr_array.mutable_data());\n      const Scalar** transposed_rhs_ptrs_base =\n          reinterpret_cast<const Scalar**>(\n              transposed_rhs_ptr_array.mutable_data());\n      for (int batch = 0; batch < batch_size; ++batch) {\n        input_copy_ptrs_base[batch] = &input_copy_reshaped(batch, 0, 0);\n        transposed_rhs_ptrs_base[batch] = &transposed_rhs_reshaped(batch, 0, 0);\n      }\n      int host_info = 0;\n      OP_REQUIRES_OK_ASYNC(\n          context,\n          solver->GetrsBatched(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                               input_copy_ptrs_base, n, pivots_mat.data(),\n                               transposed_rhs_ptrs_base, n, &host_info,\n                               batch_size),\n          done);\n      OP_REQUIRES_ASYNC(\n          context, host_info == 0,\n          errors::InvalidArgument(\"The \", -host_info,\n                                  \"'th argument to cublas*getrsBatched had \"\n                                  \"an illegal value.\"),\n          done);\n    } else {\n      dev_info.push_back(solver->GetDeviceLapackInfo(batch_size, \"getrs\"));\n      for (int batch = 0; batch < batch_size; ++batch) {\n        OP_REQUIRES_OK_ASYNC(\n            context,\n            solver->Getrs(adjoint_ ? CUBLAS_OP_C : CUBLAS_OP_T, n, nrhs,\n                          &input_copy_reshaped(batch, 0, 0), n,\n                          &pivots_mat(batch, 0),\n                          &transposed_rhs_reshaped(batch, 0, 0), n,\n                          &dev_info.back()(batch)),\n            done);\n      }\n    }\n\n    // 4. Transpose X to get the final result in row-major form.\n    if (nrhs > 1) {\n      OP_REQUIRES_OK_ASYNC(\n          context, DoMatrixTranspose(device, transposed_rhs, output), done);\n    } else {\n      device.memcpy(output->flat<Scalar>().data(),\n                    transposed_rhs.flat<Scalar>().data(),\n                    transposed_rhs.NumElements() * sizeof(Scalar));\n    }\n\n    // Callback for checking info after kernels finish. Also capture the\n    // temporary Tensors/ScratchSpace so they don't get deallocated before the\n    // kernels run. TODO(rmlarsen): Use move capture once C++14 becomes\n    // available.\n    auto info_checker = [context, done, dev_info](\n                            const Status& status,\n                            const std::vector<HostLapackInfo>& host_infos) {\n      if (!status.ok() && errors::IsInvalidArgument(status) &&\n          !host_infos.empty()) {\n        for (int i = 0; i < host_infos[0].size(); ++i) {\n          // Match the CPU error message for singular matrices. Otherwise\n          // just print the original error message from the status below.\n          OP_REQUIRES_ASYNC(context, host_infos[0].data()[i] <= 0,\n                            errors::InvalidArgument(kErrMsg), done);\n        }\n      }\n      OP_REQUIRES_OK_ASYNC(context, status, done);\n      done();\n    };\n    CudaSolver::CheckLapackInfoAndDeleteSolverAsync(std::move(solver), dev_info,\n                                                    std::move(info_checker));\n  }", "func_hash": 213027909579375149223707117272594449042, "file_name": "matrix_solve_op.cc", "file_hash": 56729187938743390978402639550963026335, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41206", "file_path": "tensorflow/core/kernels/linalg/matrix_solve_op.cc"}
{"idx": 196689, "project": "tensorflow", "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "commit_message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    Buffer* buf = nullptr;\n    OP_REQUIRES_OK(ctx, GetBuffer(ctx, def(), &buf));\n    core::ScopedUnref scope(buf);\n    Buffer::Tuple tuple;\n\n    std::size_t index = ctx->input(0).scalar<int>()();\n\n    OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));\n\n    OP_REQUIRES(\n        ctx, tuple.size() == (size_t)ctx->num_outputs(),\n        errors::InvalidArgument(\"Mismatch stage/unstage: \", tuple.size(),\n                                \" vs. \", ctx->num_outputs()));\n\n    for (size_t i = 0; i < tuple.size(); ++i) {\n      ctx->set_output(i, tuple[i]);\n    }\n  }", "func_hash": 321476459442808105718031824942985787186, "file_name": "stage_op.cc", "file_hash": 203338145673187111221975146552959312769, "cwe": ["CWE-703"], "cve": "CVE-2022-29195", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29195", "file_path": "tensorflow/core/kernels/stage_op.cc"}
{"idx": 242619, "project": "tensorflow", "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "commit_message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    Buffer* buf = nullptr;\n    OP_REQUIRES_OK(ctx, GetBuffer(ctx, def(), &buf));\n    core::ScopedUnref scope(buf);\n    Buffer::Tuple tuple;\n\n    buf->Get(&tuple);\n\n    OP_REQUIRES(\n        ctx, tuple.size() == (size_t)ctx->num_outputs(),\n        errors::InvalidArgument(\"Mismatch stage/unstage: \", tuple.size(),\n                                \" vs. \", ctx->num_outputs()));\n\n    for (size_t i = 0; i < tuple.size(); ++i) {\n      ctx->set_output(i, tuple[i]);\n    }\n  }", "func_hash": 150871818833070085390431100112319012215, "file_name": "stage_op.cc", "file_hash": 292796960162980121952379513053668377918, "cwe": ["CWE-703"], "cve": "CVE-2022-29195", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29195", "file_path": "tensorflow/core/kernels/stage_op.cc"}
{"idx": 196691, "project": "gpac", "commit_id": "71460d72ec07df766dab0a4d52687529f3efcf0a", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/71460d72ec07df766dab0a4d52687529f3efcf0a", "commit_message": "fixed #1876", "target": 1, "func": "static GF_Err isoffin_process(GF_Filter *filter)\n{\n\tISOMReader *read = gf_filter_get_udta(filter);\n\tu32 i, count = gf_list_count(read->channels);\n\tBool is_active = GF_FALSE;\n\tBool in_is_eos = GF_FALSE;\n\tBool check_forced_end = GF_FALSE;\n\tBool has_new_data = GF_FALSE;\n\tu64 min_offset_plus_one = 0;\n\tu32 nb_forced_end=0;\n\tif (read->in_error)\n\t\treturn read->in_error;\n\n\tif (read->pid) {\n\t\tBool fetch_input = GF_TRUE;\n\n\t\t//we failed at loading the init segment during a dash switch, retry\n\t\tif (!read->is_partial_download && !read->mem_load_mode && (read->moov_not_loaded==2) ) {\n\t\t\tisoffin_configure_pid(filter, read->pid, GF_FALSE);\n\t\t\tif (read->moov_not_loaded) return GF_OK;\n\t\t}\n\t\tif (read->mem_load_mode==2) {\n\t\t\tif (!read->force_fetch && read->mem_blob.size > read->mstore_size) {\n\t\t\t\tfetch_input = GF_FALSE;\n\t\t\t}\n\t\t\tread->force_fetch = GF_FALSE;\n\t\t}\n\t\twhile (fetch_input) {\n\t\t\tGF_FilterPacket *pck = gf_filter_pid_get_packet(read->pid);\n\t\t\tif (!pck) {\n\t\t\t\t//we issued a seek, wait for the first packet to be received before fetching channels\n\t\t\t\t//otherwise we could end up reading from the wrong cache\n\t\t\t\tif (read->wait_for_source) {\n\t\t\t\t\t//something went wrong during the seek request\n\t\t\t\t\tif (gf_filter_pid_is_eos(read->pid))\n\t\t\t\t\t\treturn GF_EOS;\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tread->wait_for_source = GF_FALSE;\n\n\t\t\tif (read->mem_load_mode) {\n\t\t\t\tu32 data_size;\n\t\t\t\tconst u8 *pck_data = gf_filter_pck_get_data(pck, &data_size);\n\t\t\t\tisoffin_push_buffer(filter, read, pck_data, data_size);\n\t\t\t}\n\t\t\t//we just had a switch but init seg is not completely done: input packet is only a part of the init, drop it\n\t\t\telse if (read->moov_not_loaded==2) {\n\t\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\thas_new_data = GF_TRUE;\n\t\t\tif (read->in_error)\n\t\t\t\treturn read->in_error;\n\t\t}\n\t\tif (gf_filter_pid_is_eos(read->pid)) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n\t\tif (read->input_is_stop) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t\tread->input_is_stop = GF_FALSE;\n\t\t}\n\t\tif (!read->frag_type && read->input_loaded) {\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n        //segment is invalid, wait for eos on input an send eos on all channels\n        if (read->invalid_segment) {\n            if (!in_is_eos) return GF_OK;\n            read->invalid_segment = GF_FALSE;\n\n            for (i=0; i<count; i++) {\n                ISOMChannel *ch = gf_list_get(read->channels, i);\n                if (!ch->playing) {\n                    continue;\n                }\n                if (!ch->eos_sent) {\n                    ch->eos_sent = GF_TRUE;\n                    gf_filter_pid_set_eos(ch->pid);\n                }\n            }\n            read->eos_signaled = GF_TRUE;\n            return GF_EOS;\n        }\n\t} else if (read->extern_mov) {\n\t\tin_is_eos = GF_TRUE;\n\t\tread->input_loaded = GF_TRUE;\n\t}\n\tif (read->moov_not_loaded==1) {\n\t\tif (read->mem_load_mode)\n\t\t\treturn GF_OK;\n\t\tread->moov_not_loaded = GF_FALSE;\n\t\treturn isoffin_setup(filter, read);\n\t}\n\n\tif (read->refresh_fragmented) {\n\t\tconst GF_PropertyValue *prop;\n\n\t\tif (in_is_eos) {\n\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t} else {\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILE_CACHED);\n\t\t\tif (prop && prop->value.boolean)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\n\t\tif (has_new_data) {\n\t\t\tu64 bytesMissing=0;\n\t\t\tGF_Err e;\n\t\t\tconst char *new_url = NULL;\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILEPATH);\n\t\t\tif (prop) new_url = prop->value.string;\n\n\t\t\te = gf_isom_refresh_fragmented(read->mov, &bytesMissing, new_url);\n\n\t\t\tif (e && (e!= GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_DASH, (\"[IsoMedia] Failed to refresh current segment: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] Refreshing current segment at UTC \"LLU\" - \"LLU\" bytes still missing - input is EOS %d\\n\", gf_net_get_utc(), bytesMissing, in_is_eos));\n\t\t\t}\n\n\t\t\tif (!read->refresh_fragmented && (e==GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_DASH, (\"[IsoMedia] Incomplete Segment received - \"LLU\" bytes missing but EOF found\\n\", bytesMissing ));\n\t\t\t}\n\n#ifndef GPAC_DISABLE_LOG\n\t\t\tif (gf_log_tool_level_on(GF_LOG_DASH, GF_LOG_DEBUG)) {\n\t\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\t\tISOMChannel *ch = gf_list_get(read->channels, i);\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] refresh track %d fragment - cur sample %d - new sample count %d\\n\", ch->track, ch->sample_num, gf_isom_get_sample_count(ch->owner->mov, ch->track) ));\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tisor_check_producer_ref_time(read);\n\t\t\tif (!read->frag_type)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\t}\n\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 nb_pck=50;\n\t\tISOMChannel *ch;\n\t\tch = gf_list_get(read->channels, i);\n\t\tif (!ch->playing) {\n\t\t\tnb_forced_end++;\n\t\t\tcontinue;\n\t\t}\n\t\t//eos not sent on this channel, we are active\n\t\tif (!ch->eos_sent)\n\t\t\tis_active = GF_TRUE;\n\n\t\twhile (nb_pck) {\n\t\t\tch->sample_data_offset = 0;\n\t\t\tif (!read->full_segment_flush && gf_filter_pid_would_block(ch->pid) )\n\t\t\t\tbreak;\n\n\t\t\tif (ch->item_id) {\n\t\t\t\tisor_reader_get_sample_from_item(ch);\n\t\t\t} else {\n\t\t\t\tisor_reader_get_sample(ch);\n\t\t\t}\n\n\t\t\tif (read->stsd && (ch->last_sample_desc_index != read->stsd) && ch->sample) {\n\t\t\t\tisor_reader_release_sample(ch);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (ch->sample) {\n\t\t\t\tu32 sample_dur;\n\t\t\t\tu8 dep_flags;\n\t\t\t\tu8 *subs_buf;\n\t\t\t\tu32 subs_buf_size;\n\t\t\t\tGF_FilterPacket *pck;\n\t\t\t\tif (ch->needs_pid_reconfig) {\n\t\t\t\t\tisor_update_channel_config(ch);\n\t\t\t\t\tch->needs_pid_reconfig = GF_FALSE;\n\t\t\t\t}\n\n\t\t\t\t//we have at least two samples, update GF_PROP_PID_HAS_SYNC if needed\n\t\t\t\tif (ch->check_has_rap && (gf_isom_get_sample_count(ch->owner->mov, ch->track)>1) && (gf_isom_has_sync_points(ch->owner->mov, ch->track)==1)) {\n\t\t\t\t\tch->check_has_rap = GF_FALSE;\n\t\t\t\t\tch->has_rap = GF_TRUE;\n\t\t\t\t\tgf_filter_pid_set_property(ch->pid, GF_PROP_PID_HAS_SYNC, &PROP_BOOL(ch->has_rap) );\n\t\t\t\t}\n\n\t\t\t\t//strip param sets from payload, trigger reconfig if needed\n\t\t\t\tisor_reader_check_config(ch);\n\n\t\t\t\tif (read->nodata) {\n\t\t\t\t\tpck = gf_filter_pck_new_shared(ch->pid, NULL, ch->sample->dataLength, NULL);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\t\t\t\t} else {\n\t\t\t\t\tpck = gf_filter_pck_new_alloc(ch->pid, ch->sample->dataLength, &data);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tmemcpy(data, ch->sample->data, ch->sample->dataLength);\n\t\t\t\t}\n\t\t\t\tgf_filter_pck_set_dts(pck, ch->dts);\n\t\t\t\tgf_filter_pck_set_cts(pck, ch->cts);\n\t\t\t\tif (ch->sample->IsRAP==-1) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_1);\n\t\t\t\t\tch->redundant = 1;\n\t\t\t\t} else {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (GF_FilterSAPType) ch->sample->IsRAP);\n\t\t\t\t}\n\n\t\t\t\tif (ch->sap_3)\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_3);\n\t\t\t\telse if (ch->sap_4_type) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (ch->sap_4_type==GF_ISOM_SAMPLE_PREROLL) ? GF_FILTER_SAP_4_PROL : GF_FILTER_SAP_4);\n\t\t\t\t\tgf_filter_pck_set_roll_info(pck, ch->roll);\n\t\t\t\t}\n\n\t\t\t\tsample_dur = ch->au_duration;\n\t\t\t\tif (ch->sample->nb_pack)\n\t\t\t\t\tsample_dur *= ch->sample->nb_pack;\n\t\t\t\tgf_filter_pck_set_duration(pck, sample_dur);\n\t\t\t\tgf_filter_pck_set_seek_flag(pck, ch->seek_flag);\n\n\t\t\t\t//for now we only signal xPS mask for non-sap\n\t\t\t\tif (ch->xps_mask && !gf_filter_pck_get_sap(pck) ) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_XPS_MASK, &PROP_UINT(ch->xps_mask) );\n\t\t\t\t}\n\n\t\t\t\tdep_flags = ch->isLeading;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependsOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependedOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->redundant;\n\n\t\t\t\tif (dep_flags)\n\t\t\t\t\tgf_filter_pck_set_dependency_flags(pck, dep_flags);\n\n\t\t\t\tgf_filter_pck_set_crypt_flags(pck, ch->pck_encrypted ? GF_FILTER_PCK_CRYPT : 0);\n\t\t\t\tgf_filter_pck_set_seq_num(pck, ch->sample_num);\n\n\n\t\t\t\tsubs_buf = gf_isom_sample_get_subsamples_buffer(read->mov, ch->track, ch->sample_num, &subs_buf_size);\n\t\t\t\tif (subs_buf) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SUBS, &PROP_DATA_NO_COPY(subs_buf, subs_buf_size) );\n\t\t\t\t}\n\n\t\t\t\tif (ch->sai_buffer && ch->pck_encrypted) {\n\t\t\t\t\tassert(ch->sai_buffer_size);\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CENC_SAI, &PROP_DATA(ch->sai_buffer, ch->sai_buffer_size) );\n\t\t\t\t}\n\n\t\t\t\tif (read->sigfrag) {\n\t\t\t\t\tGF_ISOFragmentBoundaryInfo finfo;\n\t\t\t\t\tif (gf_isom_sample_is_fragment_start(read->mov, ch->track, ch->sample_num, &finfo) ) {\n\t\t\t\t\t\tu64 start=0;\n\t\t\t\t\t\tu32 traf_start = finfo.seg_start_plus_one ? 2 : 1;\n\n\t\t\t\t\t\tif (finfo.seg_start_plus_one)\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CUE_START, &PROP_BOOL(GF_TRUE));\n\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_START, &PROP_UINT(traf_start));\n\n\t\t\t\t\t\tstart = finfo.frag_start;\n\t\t\t\t\t\tif (finfo.seg_start_plus_one) start = finfo.seg_start_plus_one-1;\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_RANGE, &PROP_FRAC64_INT(start, finfo.mdat_end));\n\t\t\t\t\t\tif (finfo.moof_template) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_MOOF_TEMPLATE, &PROP_DATA((u8 *)finfo.moof_template, finfo.moof_template_size));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (finfo.sidx_end) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SIDX_RANGE, &PROP_FRAC64_INT(finfo.sidx_start , finfo.sidx_end));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (read->seg_name_changed) {\n\t\t\t\t\t\t\tconst GF_PropertyValue *p = gf_filter_pid_get_property(read->pid, GF_PROP_PID_URL);\n\t\t\t\t\t\t\tread->seg_name_changed = GF_FALSE;\n\t\t\t\t\t\t\tif (p && p->value.string) {\n\t\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PID_URL, &PROP_STRING(p->value.string));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (ch->sender_ntp) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SENDER_NTP, &PROP_LONGUINT(ch->sender_ntp));\n\t\t\t\t\tif (ch->ntp_at_server_ntp) {\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_RECEIVER_NTP, &PROP_LONGUINT(ch->ntp_at_server_ntp));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tch->eos_sent = GF_FALSE;\n\n\t\t\t\t//this might not be the true end of stream\n\t\t\t\tif ((ch->streamType==GF_STREAM_AUDIO) && (ch->sample_num == gf_isom_get_sample_count(read->mov, ch->track))) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_END_RANGE, &PROP_BOOL(GF_TRUE));\n\t\t\t\t}\n\n\t\t\t\tgf_filter_pck_send(pck);\n\t\t\t\tisor_reader_release_sample(ch);\n\n\t\t\t\tch->last_valid_sample_data_offset = ch->sample_data_offset;\n\t\t\t\tnb_pck--;\n\t\t\t} else if (ch->last_state==GF_EOS) {\n\t\t\t\tif (ch->playing == 2) {\n\t\t\t\t\tif (in_is_eos) {\n\t\t\t\t\t\tch->playing = GF_FALSE;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnb_forced_end++;\n\t\t\t\t\t\tcheck_forced_end = GF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (in_is_eos && !ch->eos_sent) {\n\t\t\t\t\tvoid *tfrf;\n\t\t\t\t\tconst void *gf_isom_get_tfrf(GF_ISOFile *movie, u32 trackNumber);\n\n\t\t\t\t\tch->eos_sent = GF_TRUE;\n\t\t\t\t\tread->eos_signaled = GF_TRUE;\n\n\t\t\t\t\ttfrf = (void *) gf_isom_get_tfrf(read->mov, ch->track);\n\t\t\t\t\tif (tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", &PROP_POINTER(tfrf) );\n\t\t\t\t\t\tch->last_has_tfrf = GF_TRUE;\n\t\t\t\t\t} else if (ch->last_has_tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", NULL);\n\t\t\t\t\t\tch->last_has_tfrf = GF_FALSE;\n\t\t\t\t\t}\n\n\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tread->force_fetch = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!min_offset_plus_one || (min_offset_plus_one - 1 > ch->last_valid_sample_data_offset))\n\t\t\tmin_offset_plus_one = 1 + ch->last_valid_sample_data_offset;\n\t}\n\tif (read->mem_load_mode && min_offset_plus_one) {\n\t\tisoffin_purge_mem(read, min_offset_plus_one-1);\n\t}\n\n\t//we reached end of playback due to play range request, we must send eos - however for safety reason with DASH, we first need to cancel the input\n\tif (read->pid && check_forced_end && (nb_forced_end==count)) {\n\t\t//abort input\n\t\tGF_FilterEvent evt;\n\t\tGF_FEVT_INIT(evt, GF_FEVT_STOP, read->pid);\n\t\tgf_filter_pid_send_event(read->pid, &evt);\n\t}\n\n\n\tif (!is_active) {\n\t\treturn GF_EOS;\n\t}\n\t//if (in_is_eos)\n//\tgf_filter_ask_rt_reschedule(filter, 1);\n\treturn GF_OK;\n\n}", "func_hash": 245491994913846374509516795584789756192, "file_name": "isoffin_read.c", "file_hash": 80320074166992838039801529564251755054, "cwe": ["CWE-703"], "cve": "CVE-2021-40592", "cve_desc": "GPAC version before commit 71460d72ec07df766dab0a4d52687529f3efcf0a (version v1.0.1 onwards) contains loop with unreachable exit condition ('infinite loop') vulnerability in ISOBMFF reader filter, isoffin_read.c. Function isoffin_process() can result in DoS by infinite loop. To exploit, the victim must open a specially crafted mp4 file.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40592", "file_path": "src/filters/isoffin_read.c"}
{"idx": 242637, "project": "gpac", "commit_id": "71460d72ec07df766dab0a4d52687529f3efcf0a", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/71460d72ec07df766dab0a4d52687529f3efcf0a", "commit_message": "fixed #1876", "target": 0, "func": "static GF_Err isoffin_process(GF_Filter *filter)\n{\n\tISOMReader *read = gf_filter_get_udta(filter);\n\tu32 i, count = gf_list_count(read->channels);\n\tBool is_active = GF_FALSE;\n\tBool in_is_eos = GF_FALSE;\n\tBool check_forced_end = GF_FALSE;\n\tBool has_new_data = GF_FALSE;\n\tu64 min_offset_plus_one = 0;\n\tu32 nb_forced_end=0;\n\tif (read->in_error)\n\t\treturn read->in_error;\n\n\tif (read->pid) {\n\t\tBool fetch_input = GF_TRUE;\n\n\t\t//we failed at loading the init segment during a dash switch, retry\n\t\tif (!read->is_partial_download && !read->mem_load_mode && (read->moov_not_loaded==2) ) {\n\t\t\tisoffin_configure_pid(filter, read->pid, GF_FALSE);\n\t\t\tif (read->moov_not_loaded) return GF_OK;\n\t\t}\n\t\tif (read->mem_load_mode==2) {\n\t\t\tif (!read->force_fetch && read->mem_blob.size > read->mstore_size) {\n\t\t\t\tfetch_input = GF_FALSE;\n\t\t\t}\n\t\t\tread->force_fetch = GF_FALSE;\n\t\t}\n\t\twhile (fetch_input) {\n\t\t\tGF_FilterPacket *pck = gf_filter_pid_get_packet(read->pid);\n\t\t\tif (!pck) {\n\t\t\t\t//we issued a seek, wait for the first packet to be received before fetching channels\n\t\t\t\t//otherwise we could end up reading from the wrong cache\n\t\t\t\tif (read->wait_for_source) {\n\t\t\t\t\t//something went wrong during the seek request\n\t\t\t\t\tif (gf_filter_pid_is_eos(read->pid))\n\t\t\t\t\t\treturn GF_EOS;\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tread->wait_for_source = GF_FALSE;\n\n\t\t\tif (read->mem_load_mode) {\n\t\t\t\tu32 data_size;\n\t\t\t\tconst u8 *pck_data = gf_filter_pck_get_data(pck, &data_size);\n\t\t\t\tisoffin_push_buffer(filter, read, pck_data, data_size);\n\t\t\t}\n\t\t\t//we just had a switch but init seg is not completely done: input packet is only a part of the init, drop it\n\t\t\telse if (read->moov_not_loaded==2) {\n\t\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t\tgf_filter_pid_drop_packet(read->pid);\n\t\t\thas_new_data = GF_TRUE;\n\t\t\tif (read->in_error)\n\t\t\t\treturn read->in_error;\n\t\t}\n\t\tif (gf_filter_pid_is_eos(read->pid)) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n\t\tif (read->input_is_stop) {\n\t\t\tread->input_loaded = GF_TRUE;\n\t\t\tin_is_eos = GF_TRUE;\n\t\t\tread->input_is_stop = GF_FALSE;\n\t\t}\n\t\tif (!read->frag_type && read->input_loaded) {\n\t\t\tin_is_eos = GF_TRUE;\n\t\t}\n        //segment is invalid, wait for eos on input an send eos on all channels\n        if (read->invalid_segment) {\n            if (!in_is_eos) return GF_OK;\n            read->invalid_segment = GF_FALSE;\n\n            for (i=0; i<count; i++) {\n                ISOMChannel *ch = gf_list_get(read->channels, i);\n                if (!ch->playing) {\n                    continue;\n                }\n                if (!ch->eos_sent) {\n                    ch->eos_sent = GF_TRUE;\n                    gf_filter_pid_set_eos(ch->pid);\n                }\n            }\n            read->eos_signaled = GF_TRUE;\n            return GF_EOS;\n        }\n\t} else if (read->extern_mov) {\n\t\tin_is_eos = GF_TRUE;\n\t\tread->input_loaded = GF_TRUE;\n\t}\n\tif (read->moov_not_loaded==1) {\n\t\tif (read->mem_load_mode)\n\t\t\treturn GF_OK;\n\t\tread->moov_not_loaded = GF_FALSE;\n\t\treturn isoffin_setup(filter, read);\n\t}\n\n\tif (read->refresh_fragmented) {\n\t\tconst GF_PropertyValue *prop;\n\n\t\tif (in_is_eos) {\n\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t} else {\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILE_CACHED);\n\t\t\tif (prop && prop->value.boolean)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\n\t\tif (has_new_data) {\n\t\t\tu64 bytesMissing=0;\n\t\t\tGF_Err e;\n\t\t\tconst char *new_url = NULL;\n\t\t\tprop = gf_filter_pid_get_property(read->pid, GF_PROP_PID_FILEPATH);\n\t\t\tif (prop) new_url = prop->value.string;\n\n\t\t\te = gf_isom_refresh_fragmented(read->mov, &bytesMissing, new_url);\n\n\t\t\tif (e && (e!= GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_DASH, (\"[IsoMedia] Failed to refresh current segment: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] Refreshing current segment at UTC \"LLU\" - \"LLU\" bytes still missing - input is EOS %d\\n\", gf_net_get_utc(), bytesMissing, in_is_eos));\n\t\t\t}\n\n\t\t\tif (!read->refresh_fragmented && (e==GF_ISOM_INCOMPLETE_FILE)) {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_DASH, (\"[IsoMedia] Incomplete Segment received - \"LLU\" bytes missing but EOF found\\n\", bytesMissing ));\n\t\t\t}\n\n#ifndef GPAC_DISABLE_LOG\n\t\t\tif (gf_log_tool_level_on(GF_LOG_DASH, GF_LOG_DEBUG)) {\n\t\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\t\tISOMChannel *ch = gf_list_get(read->channels, i);\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_DASH, (\"[IsoMedia] refresh track %d fragment - cur sample %d - new sample count %d\\n\", ch->track, ch->sample_num, gf_isom_get_sample_count(ch->owner->mov, ch->track) ));\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tisor_check_producer_ref_time(read);\n\t\t\tif (!read->frag_type)\n\t\t\t\tread->refresh_fragmented = GF_FALSE;\n\t\t}\n\t}\n\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 nb_pck=50;\n\t\tISOMChannel *ch;\n\t\tch = gf_list_get(read->channels, i);\n\t\tif (!ch->playing) {\n\t\t\tnb_forced_end++;\n\t\t\tcontinue;\n\t\t}\n\t\t//eos not sent on this channel, we are active\n\t\tif (!ch->eos_sent)\n\t\t\tis_active = GF_TRUE;\n\n\t\twhile (nb_pck) {\n\t\t\tch->sample_data_offset = 0;\n\t\t\tif (!read->full_segment_flush && gf_filter_pid_would_block(ch->pid) )\n\t\t\t\tbreak;\n\n\t\t\tif (ch->item_id) {\n\t\t\t\tisor_reader_get_sample_from_item(ch);\n\t\t\t} else {\n\t\t\t\tisor_reader_get_sample(ch);\n\t\t\t}\n\n\t\t\tif (read->stsd && (ch->last_sample_desc_index != read->stsd) && ch->sample) {\n\t\t\t\tisor_reader_release_sample(ch);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (ch->sample) {\n\t\t\t\tu32 sample_dur;\n\t\t\t\tu8 dep_flags;\n\t\t\t\tu8 *subs_buf;\n\t\t\t\tu32 subs_buf_size;\n\t\t\t\tGF_FilterPacket *pck;\n\t\t\t\tif (ch->needs_pid_reconfig) {\n\t\t\t\t\tisor_update_channel_config(ch);\n\t\t\t\t\tch->needs_pid_reconfig = GF_FALSE;\n\t\t\t\t}\n\n\t\t\t\t//we have at least two samples, update GF_PROP_PID_HAS_SYNC if needed\n\t\t\t\tif (ch->check_has_rap && (gf_isom_get_sample_count(ch->owner->mov, ch->track)>1) && (gf_isom_has_sync_points(ch->owner->mov, ch->track)==1)) {\n\t\t\t\t\tch->check_has_rap = GF_FALSE;\n\t\t\t\t\tch->has_rap = GF_TRUE;\n\t\t\t\t\tgf_filter_pid_set_property(ch->pid, GF_PROP_PID_HAS_SYNC, &PROP_BOOL(ch->has_rap) );\n\t\t\t\t}\n\n\t\t\t\t//strip param sets from payload, trigger reconfig if needed\n\t\t\t\tisor_reader_check_config(ch);\n\n\t\t\t\tif (read->nodata) {\n\t\t\t\t\tpck = gf_filter_pck_new_shared(ch->pid, NULL, ch->sample->dataLength, NULL);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\t\t\t\t} else {\n\t\t\t\t\tpck = gf_filter_pck_new_alloc(ch->pid, ch->sample->dataLength, &data);\n\t\t\t\t\tif (!pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tmemcpy(data, ch->sample->data, ch->sample->dataLength);\n\t\t\t\t}\n\t\t\t\tgf_filter_pck_set_dts(pck, ch->dts);\n\t\t\t\tgf_filter_pck_set_cts(pck, ch->cts);\n\t\t\t\tif (ch->sample->IsRAP==-1) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_1);\n\t\t\t\t\tch->redundant = 1;\n\t\t\t\t} else {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (GF_FilterSAPType) ch->sample->IsRAP);\n\t\t\t\t}\n\n\t\t\t\tif (ch->sap_3)\n\t\t\t\t\tgf_filter_pck_set_sap(pck, GF_FILTER_SAP_3);\n\t\t\t\telse if (ch->sap_4_type) {\n\t\t\t\t\tgf_filter_pck_set_sap(pck, (ch->sap_4_type==GF_ISOM_SAMPLE_PREROLL) ? GF_FILTER_SAP_4_PROL : GF_FILTER_SAP_4);\n\t\t\t\t\tgf_filter_pck_set_roll_info(pck, ch->roll);\n\t\t\t\t}\n\n\t\t\t\tsample_dur = ch->au_duration;\n\t\t\t\tif (ch->sample->nb_pack)\n\t\t\t\t\tsample_dur *= ch->sample->nb_pack;\n\t\t\t\tgf_filter_pck_set_duration(pck, sample_dur);\n\t\t\t\tgf_filter_pck_set_seek_flag(pck, ch->seek_flag);\n\n\t\t\t\t//for now we only signal xPS mask for non-sap\n\t\t\t\tif (ch->xps_mask && !gf_filter_pck_get_sap(pck) ) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_XPS_MASK, &PROP_UINT(ch->xps_mask) );\n\t\t\t\t}\n\n\t\t\t\tdep_flags = ch->isLeading;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependsOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->dependedOn;\n\t\t\t\tdep_flags <<= 2;\n\t\t\t\tdep_flags |= ch->redundant;\n\n\t\t\t\tif (dep_flags)\n\t\t\t\t\tgf_filter_pck_set_dependency_flags(pck, dep_flags);\n\n\t\t\t\tgf_filter_pck_set_crypt_flags(pck, ch->pck_encrypted ? GF_FILTER_PCK_CRYPT : 0);\n\t\t\t\tgf_filter_pck_set_seq_num(pck, ch->sample_num);\n\n\n\t\t\t\tsubs_buf = gf_isom_sample_get_subsamples_buffer(read->mov, ch->track, ch->sample_num, &subs_buf_size);\n\t\t\t\tif (subs_buf) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SUBS, &PROP_DATA_NO_COPY(subs_buf, subs_buf_size) );\n\t\t\t\t}\n\n\t\t\t\tif (ch->sai_buffer && ch->pck_encrypted) {\n\t\t\t\t\tassert(ch->sai_buffer_size);\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CENC_SAI, &PROP_DATA(ch->sai_buffer, ch->sai_buffer_size) );\n\t\t\t\t}\n\n\t\t\t\tif (read->sigfrag) {\n\t\t\t\t\tGF_ISOFragmentBoundaryInfo finfo;\n\t\t\t\t\tif (gf_isom_sample_is_fragment_start(read->mov, ch->track, ch->sample_num, &finfo) ) {\n\t\t\t\t\t\tu64 start=0;\n\t\t\t\t\t\tu32 traf_start = finfo.seg_start_plus_one ? 2 : 1;\n\n\t\t\t\t\t\tif (finfo.seg_start_plus_one)\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_CUE_START, &PROP_BOOL(GF_TRUE));\n\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_START, &PROP_UINT(traf_start));\n\n\t\t\t\t\t\tstart = finfo.frag_start;\n\t\t\t\t\t\tif (finfo.seg_start_plus_one) start = finfo.seg_start_plus_one-1;\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_FRAG_RANGE, &PROP_FRAC64_INT(start, finfo.mdat_end));\n\t\t\t\t\t\tif (finfo.moof_template) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_MOOF_TEMPLATE, &PROP_DATA((u8 *)finfo.moof_template, finfo.moof_template_size));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (finfo.sidx_end) {\n\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SIDX_RANGE, &PROP_FRAC64_INT(finfo.sidx_start , finfo.sidx_end));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (read->seg_name_changed) {\n\t\t\t\t\t\t\tconst GF_PropertyValue *p = gf_filter_pid_get_property(read->pid, GF_PROP_PID_URL);\n\t\t\t\t\t\t\tread->seg_name_changed = GF_FALSE;\n\t\t\t\t\t\t\tif (p && p->value.string) {\n\t\t\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PID_URL, &PROP_STRING(p->value.string));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (ch->sender_ntp) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_SENDER_NTP, &PROP_LONGUINT(ch->sender_ntp));\n\t\t\t\t\tif (ch->ntp_at_server_ntp) {\n\t\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_RECEIVER_NTP, &PROP_LONGUINT(ch->ntp_at_server_ntp));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tch->eos_sent = GF_FALSE;\n\n\t\t\t\t//this might not be the true end of stream\n\t\t\t\tif ((ch->streamType==GF_STREAM_AUDIO) && (ch->sample_num == gf_isom_get_sample_count(read->mov, ch->track))) {\n\t\t\t\t\tgf_filter_pck_set_property(pck, GF_PROP_PCK_END_RANGE, &PROP_BOOL(GF_TRUE));\n\t\t\t\t}\n\n\t\t\t\tgf_filter_pck_send(pck);\n\t\t\t\tisor_reader_release_sample(ch);\n\n\t\t\t\tch->last_valid_sample_data_offset = ch->sample_data_offset;\n\t\t\t\tnb_pck--;\n\t\t\t} else if (ch->last_state==GF_EOS) {\n\t\t\t\tif (ch->playing == 2) {\n\t\t\t\t\tif (in_is_eos) {\n\t\t\t\t\t\tch->playing = GF_FALSE;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnb_forced_end++;\n\t\t\t\t\t\tcheck_forced_end = GF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (in_is_eos && !ch->eos_sent) {\n\t\t\t\t\tvoid *tfrf;\n\t\t\t\t\tconst void *gf_isom_get_tfrf(GF_ISOFile *movie, u32 trackNumber);\n\n\t\t\t\t\tch->eos_sent = GF_TRUE;\n\t\t\t\t\tread->eos_signaled = GF_TRUE;\n\n\t\t\t\t\ttfrf = (void *) gf_isom_get_tfrf(read->mov, ch->track);\n\t\t\t\t\tif (tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", &PROP_POINTER(tfrf) );\n\t\t\t\t\t\tch->last_has_tfrf = GF_TRUE;\n\t\t\t\t\t} else if (ch->last_has_tfrf) {\n\t\t\t\t\t\tgf_filter_pid_set_info_str(ch->pid, \"smooth_tfrf\", NULL);\n\t\t\t\t\t\tch->last_has_tfrf = GF_FALSE;\n\t\t\t\t\t}\n\n\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t} else if (ch->last_state==GF_ISOM_INVALID_FILE) {\n\t\t\t\tif (!ch->eos_sent) {\n\t\t\t\t\tch->eos_sent = GF_TRUE;\n\t\t\t\t\tread->eos_signaled = GF_TRUE;\n\t\t\t\t\tgf_filter_pid_set_eos(ch->pid);\n\t\t\t\t}\n\t\t\t\treturn ch->last_state;\n\t\t\t} else {\n\t\t\t\tread->force_fetch = GF_TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!min_offset_plus_one || (min_offset_plus_one - 1 > ch->last_valid_sample_data_offset))\n\t\t\tmin_offset_plus_one = 1 + ch->last_valid_sample_data_offset;\n\t}\n\tif (read->mem_load_mode && min_offset_plus_one) {\n\t\tisoffin_purge_mem(read, min_offset_plus_one-1);\n\t}\n\n\t//we reached end of playback due to play range request, we must send eos - however for safety reason with DASH, we first need to cancel the input\n\tif (read->pid && check_forced_end && (nb_forced_end==count)) {\n\t\t//abort input\n\t\tGF_FilterEvent evt;\n\t\tGF_FEVT_INIT(evt, GF_FEVT_STOP, read->pid);\n\t\tgf_filter_pid_send_event(read->pid, &evt);\n\t}\n\n\n\tif (!is_active) {\n\t\treturn GF_EOS;\n\t}\n\t//if (in_is_eos)\n//\tgf_filter_ask_rt_reschedule(filter, 1);\n\treturn GF_OK;\n\n}", "func_hash": 305058451325362998718292493453495076439, "file_name": "isoffin_read.c", "file_hash": 45568496591393007238506246573526523584, "cwe": ["CWE-703"], "cve": "CVE-2021-40592", "cve_desc": "GPAC version before commit 71460d72ec07df766dab0a4d52687529f3efcf0a (version v1.0.1 onwards) contains loop with unreachable exit condition ('infinite loop') vulnerability in ISOBMFF reader filter, isoffin_read.c. Function isoffin_process() can result in DoS by infinite loop. To exploit, the victim must open a specially crafted mp4 file.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40592", "file_path": "src/filters/isoffin_read.c"}
{"idx": 196705, "project": "tensorflow", "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730", "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704", "target": 1, "func": "Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n                      const Tensor *a_shape, const Tensor *b) {\n  if (!TensorShapeUtils::IsMatrix(a_indices->shape())) {\n    return errors::InvalidArgument(\n        \"Input a_indices should be a matrix but received shape: \",\n        a_indices->shape().DebugString());\n  }\n  if (!TensorShapeUtils::IsVector(a_values->shape()) ||\n      !TensorShapeUtils::IsVector(a_shape->shape())) {\n    return errors::InvalidArgument(\n        \"Inputs a_values and a_shape should be vectors \"\n        \"but received shapes: \",\n        a_values->shape().DebugString(), \" and \",\n        a_shape->shape().DebugString());\n  }\n  if (a_shape->NumElements() != b->dims()) {\n    return errors::InvalidArgument(\n        \"Two operands have different ranks; received: \", a_shape->NumElements(),\n        \" and \", b->dims());\n  }\n  const auto a_shape_flat = a_shape->flat<Index>();\n  for (int i = 0; i < b->dims(); ++i) {\n    if (a_shape_flat(i) != b->dim_size(i)) {\n      return errors::InvalidArgument(\n          \"Dimension \", i,\n          \" does not equal (no broadcasting is supported): sparse side \",\n          a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n    }\n  }\n  return Status::OK();\n}", "func_hash": 308425823880781073775676879611190785715, "file_name": "sparse_tensor_dense_add_op.cc", "file_hash": 91198918327439956509177796541242214319, "cwe": ["CWE-20"], "cve": "CVE-2022-29206", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29206", "file_path": "tensorflow/core/kernels/sparse_tensor_dense_add_op.cc"}
{"idx": 242926, "project": "tensorflow", "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730", "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704", "target": 0, "func": "Status ValidateInputs(const Tensor *a_indices, const Tensor *a_values,\n                      const Tensor *a_shape, const Tensor *b) {\n  if (!TensorShapeUtils::IsMatrix(a_indices->shape())) {\n    return errors::InvalidArgument(\n        \"Input a_indices should be a matrix but received shape: \",\n        a_indices->shape().DebugString());\n  }\n  if (!TensorShapeUtils::IsVector(a_values->shape()) ||\n      !TensorShapeUtils::IsVector(a_shape->shape())) {\n    return errors::InvalidArgument(\n        \"Inputs a_values and a_shape should be vectors \"\n        \"but received shapes: \",\n        a_values->shape().DebugString(), \" and \",\n        a_shape->shape().DebugString());\n  }\n  int64_t nnz = a_indices->dim_size(0);\n  int64_t ndims = a_indices->dim_size(1);\n  if (a_values->dim_size(0) != nnz) {\n    return errors::InvalidArgument(\"Dimensions \", nnz, \" and \",\n                                   a_values->dim_size(0),\n                                   \" are not compatible\");\n  }\n  if (a_shape->dim_size(0) != ndims) {\n    return errors::InvalidArgument(\"Dimensions \", ndims, \" and \",\n                                   a_shape->dim_size(0), \" are not compatible\");\n  }\n  if (a_shape->NumElements() != b->dims()) {\n    return errors::InvalidArgument(\n        \"Two operands have different ranks; received: \", a_shape->NumElements(),\n        \" and \", b->dims());\n  }\n  const auto a_shape_flat = a_shape->flat<Index>();\n  for (int i = 0; i < b->dims(); ++i) {\n    if (a_shape_flat(i) != b->dim_size(i)) {\n      return errors::InvalidArgument(\n          \"Dimension \", i,\n          \" does not equal (no broadcasting is supported): sparse side \",\n          a_shape_flat(i), \" vs dense side \", b->dim_size(i));\n    }\n  }\n\n  // Check for invalid indices.\n  const auto a_indices_mat = a_indices->flat_inner_dims<Index>();\n\n  for (int64_t zidx = 0; zidx < nnz; ++zidx) {\n    for (int64_t didx = 0; didx < ndims; ++didx) {\n      const Index idx = a_indices_mat(zidx, didx);\n      if (idx < 0 || idx >= a_shape_flat(didx)) {\n        return errors::InvalidArgument(\n            \"Sparse tensor has an invalid index on dimension \", didx,\n            \": \"\n            \"a_indices(\",\n            zidx, \",\", didx, \") = \", idx,\n            \", dense tensor shape: \", a_shape_flat);\n      }\n    }\n  }\n\n  return Status::OK();\n}", "func_hash": 310798775905628265586866839597720584207, "file_name": "sparse_tensor_dense_add_op.cc", "file_hash": 106434963445193170812694157920438487376, "cwe": ["CWE-20"], "cve": "CVE-2022-29206", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29206", "file_path": "tensorflow/core/kernels/sparse_tensor_dense_add_op.cc"}
{"idx": 196790, "project": "tensorflow", "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a4e138660270e7599793fa438cd7b2fc2ce215a6", "commit_message": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808", "target": 1, "func": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}", "func_hash": 183156860369052380668778554351089179754, "file_name": "sdca_internal.cc", "file_hash": 189786435377355636606855329054946360663, "cwe": ["CWE-703"], "cve": "CVE-2021-37672", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37672", "file_path": "tensorflow/core/kernels/sdca_internal.cc"}
{"idx": 245140, "project": "tensorflow", "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a4e138660270e7599793fa438cd7b2fc2ce215a6", "commit_message": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808", "target": 0, "func": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n  if (example_labels.size() != num_examples) {\n    return errors::InvalidArgument(\"Expected \", num_examples,\n                                   \" example labels but got \",\n                                   example_labels.size());\n  }\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}", "func_hash": 260741602322702772753001144224568198903, "file_name": "sdca_internal.cc", "file_hash": 181960497028529937456505885431082793104, "cwe": ["CWE-703"], "cve": "CVE-2021-37672", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37672", "file_path": "tensorflow/core/kernels/sdca_internal.cc"}
{"idx": 196801, "project": "gpac", "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/f5a038e6893019ee471b6a57490cf7a495673816", "commit_message": "fixed #1885", "target": 1, "func": "GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 bandwidth)\n{\n\tu32 i, sceneT, odT, descIndex, size, size64;\n\tGF_InitialObjectDescriptor *iod;\n\tGF_SLConfig slc;\n\tGF_ISOSample *samp;\n\tBool remove_ocr;\n\tu8 *buffer;\n\tchar buf64[5000], sdpLine[5100];\n\n\n\tgf_isom_sdp_clean(file);\n\n\tif (bandwidth) {\n\t\tsprintf(buf64, \"b=AS:%d\", bandwidth);\n\t\tgf_isom_sdp_add_line(file, buf64);\n\t}\n    //xtended attribute for copyright\n    if (gf_sys_is_test_mode()) {\n        sprintf(buf64, \"a=x-copyright: %s\", \"MP4/3GP File hinted with GPAC - (c) Telecom ParisTech (http://gpac.io)\");\n    } else {\n        sprintf(buf64, \"a=x-copyright: MP4/3GP File hinted with GPAC %s - %s\", gf_gpac_version(), gf_gpac_copyright() );\n    }\n\tgf_isom_sdp_add_line(file, buf64);\n\n\tif (IOD_Profile == GF_SDP_IOD_NONE) return GF_OK;\n\n\todT = sceneT = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tif (!gf_isom_is_track_in_root_od(file, i+1)) continue;\n\t\tswitch (gf_isom_get_media_type(file,i+1)) {\n\t\tcase GF_ISOM_MEDIA_OD:\n\t\t\todT = i+1;\n\t\t\tbreak;\n\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tsceneT = i+1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tremove_ocr = 0;\n\tif (IOD_Profile == GF_SDP_IOD_ISMA_STRICT) {\n\t\tIOD_Profile = GF_SDP_IOD_ISMA;\n\t\tremove_ocr = 1;\n\t}\n\n\t/*if we want ISMA like iods, we need at least BIFS */\n\tif ( (IOD_Profile == GF_SDP_IOD_ISMA) && !sceneT ) return GF_BAD_PARAM;\n\n\t/*do NOT change PLs, we assume they are correct*/\n\tiod = (GF_InitialObjectDescriptor *) gf_isom_get_root_od(file);\n\tif (!iod) return GF_NOT_SUPPORTED;\n\n\t/*rewrite an IOD with good SL config - embbed data if possible*/\n\tif (IOD_Profile == GF_SDP_IOD_ISMA) {\n\t\tGF_ESD *esd;\n\t\tBool is_ok = 1;\n\t\twhile (gf_list_count(iod->ESDescriptors)) {\n\t\t\tesd = (GF_ESD*)gf_list_get(iod->ESDescriptors, 0);\n\t\t\tgf_odf_desc_del((GF_Descriptor *) esd);\n\t\t\tgf_list_rem(iod->ESDescriptors, 0);\n\t\t}\n\n\n\t\t/*get OD esd, and embbed stream data if possible*/\n\t\tif (odT) {\n\t\t\tesd = gf_isom_get_esd(file, odT, 1);\n\t\t\tif (gf_isom_get_sample_count(file, odT)==1) {\n\t\t\t\tsamp = gf_isom_get_sample(file, odT, 1, &descIndex);\n\t\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_OD)) {\n\t\t\t\t\tInitSL_NULL(&slc);\n\t\t\t\t\tslc.predefined = 0;\n\t\t\t\t\tslc.hasRandomAccessUnitsOnlyFlag = 1;\n\t\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, odT);\n\t\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t\t//set the SL for future extraction\n\t\t\t\t\tgf_isom_set_extraction_slc(file, odT, 1, &slc);\n\n\t\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\t\tbuf64[size64] = 0;\n\t\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-od-au;base64,%s\", buf64);\n\n\t\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t\t}\n\t\t\t\t\tsize64 = (u32) strlen(sdpLine)+1;\n\t\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * size64);\n\t\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t\t} else {\n\t\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_RTP, (\"[rtp hinter] OD sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\t\tis_ok = 0;\n\t\t\t\t}\n\t\t\t\tgf_isom_sample_del(&samp);\n\t\t\t}\n\t\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\t\t//OK, add this to our IOD\n\t\t\tgf_list_add(iod->ESDescriptors, esd);\n\t\t}\n\n\t\tesd = gf_isom_get_esd(file, sceneT, 1);\n\t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n\t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n\n\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t//set the SL for future extraction\n\t\t\t\tgf_isom_set_extraction_slc(file, sceneT, 1, &slc);\n\t\t\t\t//encode in Base64 the sample\n\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\tbuf64[size64] = 0;\n\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-bifs-au;base64,%s\", buf64);\n\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t}\n\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * (strlen(sdpLine)+1));\n\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_RTP, (\"[rtp hinter] Scene description sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\tis_ok = 0;\n\t\t\t}\n\t\t\tgf_isom_sample_del(&samp);\n\t\t}\n\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\tgf_list_add(iod->ESDescriptors, esd);\n\n\t\tif (is_ok) {\n\t\t\tu32 has_a, has_v, has_i_a, has_i_v;\n\t\t\thas_a = has_v = has_i_a = has_i_v = 0;\n\t\t\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\t\t\tesd = gf_isom_get_esd(file, i+1, 1);\n\t\t\t\tif (!esd) continue;\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tif (esd->decoderConfig->streamType==GF_STREAM_VISUAL) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_MPEG4_PART2) has_i_v ++;\n\t\t\t\t\t\telse has_v++;\n\t\t\t\t\t} else if (esd->decoderConfig->streamType==GF_STREAM_AUDIO) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_AAC_MPEG4) has_i_a ++;\n\t\t\t\t\t\telse has_a++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_odf_desc_del((GF_Descriptor *)esd);\n\t\t\t}\n\t\t\t/*only 1 MPEG-4 visual max and 1 MPEG-4 audio max for ISMA compliancy*/\n\t\t\tif (!has_v && !has_a && (has_i_v<=1) && (has_i_a<=1)) {\n\t\t\t\tsprintf(sdpLine, \"a=isma-compliance:1,1.0,1\");\n\t\t\t\tgf_isom_sdp_add_line(file, sdpLine);\n\t\t\t}\n\t\t}\n\t}\n\n\t//encode the IOD\n\tbuffer = NULL;\n\tsize = 0;\n\tgf_odf_desc_write((GF_Descriptor *) iod, &buffer, &size);\n\tgf_odf_desc_del((GF_Descriptor *)iod);\n\n\t//encode in Base64 the iod\n\tsize64 = gf_base64_encode(buffer, size, buf64, 2000);\n\tbuf64[size64] = 0;\n\tgf_free(buffer);\n\n\tsprintf(sdpLine, \"a=mpeg4-iod:\\\"data:application/mpeg4-iod;base64,%s\\\"\", buf64);\n\tgf_isom_sdp_add_line(file, sdpLine);\n\n\treturn GF_OK;\n}", "func_hash": 123828913884454942556959015680908121097, "file_name": "isom_hinter.c", "file_hash": 94306079889139284150664165649647698827, "cwe": ["CWE-703"], "cve": "CVE-2021-40567", "cve_desc": "Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40567", "file_path": "src/media_tools/isom_hinter.c"}
{"idx": 245434, "project": "gpac", "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/f5a038e6893019ee471b6a57490cf7a495673816", "commit_message": "fixed #1885", "target": 0, "func": "GF_Err gf_hinter_finalize(GF_ISOFile *file, GF_SDP_IODProfile IOD_Profile, u32 bandwidth)\n{\n\tu32 i, sceneT, odT, descIndex, size, size64;\n\tGF_InitialObjectDescriptor *iod;\n\tGF_SLConfig slc;\n\tGF_ISOSample *samp;\n\tBool remove_ocr;\n\tu8 *buffer;\n\tchar buf64[5000], sdpLine[5100];\n\n\n\tgf_isom_sdp_clean(file);\n\n\tif (bandwidth) {\n\t\tsprintf(buf64, \"b=AS:%d\", bandwidth);\n\t\tgf_isom_sdp_add_line(file, buf64);\n\t}\n    //xtended attribute for copyright\n    if (gf_sys_is_test_mode()) {\n        sprintf(buf64, \"a=x-copyright: %s\", \"MP4/3GP File hinted with GPAC - (c) Telecom ParisTech (http://gpac.io)\");\n    } else {\n        sprintf(buf64, \"a=x-copyright: MP4/3GP File hinted with GPAC %s - %s\", gf_gpac_version(), gf_gpac_copyright() );\n    }\n\tgf_isom_sdp_add_line(file, buf64);\n\n\tif (IOD_Profile == GF_SDP_IOD_NONE) return GF_OK;\n\n\todT = sceneT = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tif (!gf_isom_is_track_in_root_od(file, i+1)) continue;\n\t\tswitch (gf_isom_get_media_type(file,i+1)) {\n\t\tcase GF_ISOM_MEDIA_OD:\n\t\t\todT = i+1;\n\t\t\tbreak;\n\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tsceneT = i+1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tremove_ocr = 0;\n\tif (IOD_Profile == GF_SDP_IOD_ISMA_STRICT) {\n\t\tIOD_Profile = GF_SDP_IOD_ISMA;\n\t\tremove_ocr = 1;\n\t}\n\n\t/*if we want ISMA like iods, we need at least BIFS */\n\tif ( (IOD_Profile == GF_SDP_IOD_ISMA) && !sceneT ) return GF_BAD_PARAM;\n\n\t/*do NOT change PLs, we assume they are correct*/\n\tiod = (GF_InitialObjectDescriptor *) gf_isom_get_root_od(file);\n\tif (!iod) return GF_NOT_SUPPORTED;\n\n\t/*rewrite an IOD with good SL config - embbed data if possible*/\n\tif (IOD_Profile == GF_SDP_IOD_ISMA) {\n\t\tGF_ESD *esd;\n\t\tBool is_ok = 1;\n\t\twhile (gf_list_count(iod->ESDescriptors)) {\n\t\t\tesd = (GF_ESD*)gf_list_get(iod->ESDescriptors, 0);\n\t\t\tgf_odf_desc_del((GF_Descriptor *) esd);\n\t\t\tgf_list_rem(iod->ESDescriptors, 0);\n\t\t}\n\n\n\t\t/*get OD esd, and embbed stream data if possible*/\n\t\tif (odT) {\n\t\t\tesd = gf_isom_get_esd(file, odT, 1);\n\t\t\tif (gf_isom_get_sample_count(file, odT)==1) {\n\t\t\t\tsamp = gf_isom_get_sample(file, odT, 1, &descIndex);\n\t\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_OD)) {\n\t\t\t\t\tInitSL_NULL(&slc);\n\t\t\t\t\tslc.predefined = 0;\n\t\t\t\t\tslc.hasRandomAccessUnitsOnlyFlag = 1;\n\t\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, odT);\n\t\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t\t//set the SL for future extraction\n\t\t\t\t\tgf_isom_set_extraction_slc(file, odT, 1, &slc);\n\n\t\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\t\tbuf64[size64] = 0;\n\t\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-od-au;base64,%s\", buf64);\n\n\t\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t\t}\n\t\t\t\t\tsize64 = (u32) strlen(sdpLine)+1;\n\t\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * size64);\n\t\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t\t} else {\n\t\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_RTP, (\"[rtp hinter] OD sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\t\tis_ok = 0;\n\t\t\t\t}\n\t\t\t\tgf_isom_sample_del(&samp);\n\t\t\t}\n\t\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\t\t//OK, add this to our IOD\n\t\t\tgf_list_add(iod->ESDescriptors, esd);\n\t\t}\n\n\t\tesd = gf_isom_get_esd(file, sceneT, 1);\n\t\tif (gf_isom_get_sample_count(file, sceneT)==1) {\n\t\t\tsamp = gf_isom_get_sample(file, sceneT, 1, &descIndex);\n\t\t\tif (samp && gf_hinter_can_embbed_data(samp->data, samp->dataLength, GF_STREAM_SCENE)) {\n\t\t\t\tInitSL_NULL(&slc);\n\t\t\t\tslc.timeScale = slc.timestampResolution = gf_isom_get_media_timescale(file, sceneT);\n\t\t\t\tslc.OCRResolution = 1000;\n\t\t\t\tslc.startCTS = samp->DTS+samp->CTS_Offset;\n\t\t\t\tslc.startDTS = samp->DTS;\n\t\t\t\t//set the SL for future extraction\n\t\t\t\tgf_isom_set_extraction_slc(file, sceneT, 1, &slc);\n\t\t\t\t//encode in Base64 the sample\n\t\t\t\tsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\n\t\t\t\tbuf64[size64] = 0;\n\t\t\t\tsprintf(sdpLine, \"data:application/mpeg4-bifs-au;base64,%s\", buf64);\n\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tesd->decoderConfig->avgBitrate = 0;\n\t\t\t\t\tesd->decoderConfig->bufferSizeDB = samp->dataLength;\n\t\t\t\t\tesd->decoderConfig->maxBitrate = 0;\n\t\t\t\t}\n\t\t\t\tesd->URLString = (char*)gf_malloc(sizeof(char) * (strlen(sdpLine)+1));\n\t\t\t\tstrcpy(esd->URLString, sdpLine);\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_RTP, (\"[rtp hinter] Scene description sample too large to be embedded in IOD - ISMA disabled\\n\"));\n\t\t\t\tis_ok = 0;\n\t\t\t}\n\t\t\tgf_isom_sample_del(&samp);\n\t\t}\n\t\tif (remove_ocr) esd->OCRESID = 0;\n\t\telse if (esd->OCRESID == esd->ESID) esd->OCRESID = 0;\n\n\t\tgf_list_add(iod->ESDescriptors, esd);\n\n\t\tif (is_ok) {\n\t\t\tu32 has_a, has_v, has_i_a, has_i_v;\n\t\t\thas_a = has_v = has_i_a = has_i_v = 0;\n\t\t\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\t\t\tesd = gf_isom_get_esd(file, i+1, 1);\n\t\t\t\tif (!esd) continue;\n\t\t\t\tif (esd->decoderConfig) {\n\t\t\t\t\tif (esd->decoderConfig->streamType==GF_STREAM_VISUAL) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_MPEG4_PART2) has_i_v ++;\n\t\t\t\t\t\telse has_v++;\n\t\t\t\t\t} else if (esd->decoderConfig->streamType==GF_STREAM_AUDIO) {\n\t\t\t\t\t\tif (esd->decoderConfig->objectTypeIndication==GF_CODECID_AAC_MPEG4) has_i_a ++;\n\t\t\t\t\t\telse has_a++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_odf_desc_del((GF_Descriptor *)esd);\n\t\t\t}\n\t\t\t/*only 1 MPEG-4 visual max and 1 MPEG-4 audio max for ISMA compliancy*/\n\t\t\tif (!has_v && !has_a && (has_i_v<=1) && (has_i_a<=1)) {\n\t\t\t\tsprintf(sdpLine, \"a=isma-compliance:1,1.0,1\");\n\t\t\t\tgf_isom_sdp_add_line(file, sdpLine);\n\t\t\t}\n\t\t}\n\t}\n\n\t//encode the IOD\n\tbuffer = NULL;\n\tsize = 0;\n\tgf_odf_desc_write((GF_Descriptor *) iod, &buffer, &size);\n\tgf_odf_desc_del((GF_Descriptor *)iod);\n\n\t//encode in Base64 the iod\n\tsize64 = gf_base64_encode(buffer, size, buf64, 2000);\n\tbuf64[size64] = 0;\n\tgf_free(buffer);\n\n\tsprintf(sdpLine, \"a=mpeg4-iod:\\\"data:application/mpeg4-iod;base64,%s\\\"\", buf64);\n\tgf_isom_sdp_add_line(file, sdpLine);\n\n\treturn GF_OK;\n}", "func_hash": 303417005627420629887148853980716072397, "file_name": "isom_hinter.c", "file_hash": 42590680344413091509080711519758588742, "cwe": ["CWE-703"], "cve": "CVE-2021-40567", "cve_desc": "Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-40567", "file_path": "src/media_tools/isom_hinter.c"}
{"idx": 196829, "project": "tensorflow", "commit_id": "9a133d73ae4b4664d22bd1aa6d654fec13c52ee1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a133d73ae4b4664d22bd1aa6d654fec13c52ee1", "commit_message": "Prevent segfault in `GetSessionHandle{,V2}`.\n\nIn eager mode, session state is null.\n\nPiperOrigin-RevId: 332548597\nChange-Id: If094812c2e094044220b9ba28f7d7601be042f38", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    int64 id = ctx->session_state()->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }", "func_hash": 265136132776865637405047291994320353020, "file_name": "session_ops.cc", "file_hash": 301236181949638816884177571060128580318, "cwe": ["CWE-476"], "cve": "CVE-2020-15204", "cve_desc": "In eager mode, TensorFlow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1 does not set the session state. Hence, calling `tf.raw_ops.GetSessionHandle` or `tf.raw_ops.GetSessionHandleV2` results in a null pointer dereference In linked snippet, in eager mode, `ctx->session_state()` returns `nullptr`. Since code immediately dereferences this, we get a segmentation fault. The issue is patched in commit 9a133d73ae4b4664d22bd1aa6d654fec13c52ee1, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15204", "file_path": "tensorflow/core/kernels/session_ops.cc"}
{"idx": 245921, "project": "tensorflow", "commit_id": "9a133d73ae4b4664d22bd1aa6d654fec13c52ee1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a133d73ae4b4664d22bd1aa6d654fec13c52ee1", "commit_message": "Prevent segfault in `GetSessionHandle{,V2}`.\n\nIn eager mode, session state is null.\n\nPiperOrigin-RevId: 332548597\nChange-Id: If094812c2e094044220b9ba28f7d7601be042f38", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionHandle called on null session state\"));\n    int64 id = session_state->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }", "func_hash": 297244264653800469833284157710994110214, "file_name": "session_ops.cc", "file_hash": 303341858564051211151362713951438565129, "cwe": ["CWE-476"], "cve": "CVE-2020-15204", "cve_desc": "In eager mode, TensorFlow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1 does not set the session state. Hence, calling `tf.raw_ops.GetSessionHandle` or `tf.raw_ops.GetSessionHandleV2` results in a null pointer dereference In linked snippet, in eager mode, `ctx->session_state()` returns `nullptr`. Since code immediately dereferences this, we get a segmentation fault. The issue is patched in commit 9a133d73ae4b4664d22bd1aa6d654fec13c52ee1, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2020-15204", "file_path": "tensorflow/core/kernels/session_ops.cc"}
