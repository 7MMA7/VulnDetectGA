{"idx": 253970, "project": "tensorflow", "commit_id": "6da6620efad397c85493b8f8667b821403516708", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/6da6620efad397c85493b8f8667b821403516708", "commit_message": "Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const Tensor& input_min_range = ctx->input(1);\n    const Tensor& input_max_range = ctx->input(2);\n\n    int num_slices = 1;\n    if (axis_ > -1) {\n      OP_REQUIRES(\n          ctx, input.dims() > axis_,\n          errors::InvalidArgument(\n              \"Axis is on a zero-based index, so its value must always be less \"\n              \"than number of input's dims, but given axis value was \",\n              axis_, \" and input's dims was \", input.dims()));\n      num_slices = input.dim_size(axis_);\n      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n                  errors::InvalidArgument(\n                      \"If axis is specified, min_range must be a 1-D tensor \"\n                      \"whose size matches the axis dimension of the input and \"\n                      \"output tensors, but min_range dims are \",\n                      input_min_range.dims()));\n      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n                  errors::InvalidArgument(\n                      \"If axis is specified, min_range must be a 1-D tensor \"\n                      \"whose size matches the axis dimension of the input and \"\n                      \"output tensors, but min_range is a 1-D tensor of size \",\n                      input_min_range.dim_size(0),\n                      \" and input's axis dimension is of size \", num_slices));\n      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n                  errors::InvalidArgument(\n                      \"If axis is specified, max_range must be a 1-D tensor \"\n                      \"whose size matches the axis dimension of the input and \"\n                      \"output tensors, but max_range dims are \",\n                      input_max_range.dims()));\n      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n                  errors::InvalidArgument(\n                      \"If axis is specified, max_range must be a 1-D tensor \"\n                      \"whose size matches the axis dimension of the input and \"\n                      \"output tensors, but max_range is a 1-D tensor of size \",\n                      input_max_range.dim_size(0),\n                      \" and input's axis dimension is of size \", num_slices));\n    } else {\n      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n                  errors::InvalidArgument(\n                      \"If axis is not specified, min_range must contain a \"\n                      \"single float element, but it contains \",\n                      input_min_range.NumElements(), \" elements\"));\n      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n                  errors::InvalidArgument(\n                      \"If axis is not specified, max_range must contain a \"\n                      \"single float element, but it contains \",\n                      input_max_range.NumElements(), \" elements\"));\n    }\n\n    const TensorShape& minmax_shape = ctx->input(1).shape();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n\n    Tensor* output_min_tensor = nullptr;\n    Tensor* output_max_tensor = nullptr;\n\n    if (num_slices == 1) {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(1, {}, &output_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(2, {}, &output_max_tensor));\n      const float min_range = input_min_range.template flat<float>()(0);\n      const float max_range = input_max_range.template flat<float>()(0);\n      QuantizeTensor(ctx, input, min_range, max_range, output,\n                     output_min_tensor, output_max_tensor);\n      return;\n    }\n\n    OP_REQUIRES(ctx, mode_ != QUANTIZE_MODE_MIN_FIRST,\n                errors::Unimplemented(\"MIN_FIRST mode is not implemented for \"\n                                      \"Quantize with axis != -1.\"));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, minmax_shape, &output_min_tensor));\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, minmax_shape, &output_max_tensor));\n\n    auto input_tensor =\n        input.template flat_inner_outer_dims<float, 3>(axis_ - 1);\n    int64_t pre_dim = 1, post_dim = 1;\n    for (int i = 0; i < axis_; ++i) {\n      pre_dim *= output->dim_size(i);\n    }\n    for (int i = axis_ + 1; i < output->dims(); ++i) {\n      post_dim *= output->dim_size(i);\n    }\n    auto output_tensor = output->template bit_casted_shaped<T, 3>(\n        {pre_dim, num_slices, post_dim});\n    auto min_ranges = input_min_range.template vec<float>();\n    auto max_ranges = input_max_range.template vec<float>();\n    for (int i = 0; i < num_slices; ++i) {\n      QuantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i),\n                    &output_min_tensor->flat<float>()(i),\n                    &output_max_tensor->flat<float>()(i));\n    }\n  }", "func_hash": 245467204964919391793075021199596127255, "file_name": "quantize_op.cc", "file_hash": 256130062942264695553473842652666995281, "cwe": ["CWE-476"], "cve": "CVE-2021-37663", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor. We have patched the issue in GitHub commit 6da6620efad397c85493b8f8667b821403516708. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37663", "file_path": "tensorflow/core/kernels/quantize_op.cc"}
{"idx": 197223, "project": "njs", "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "commit_message": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).", "target": 1, "func": "njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n{\n    char        *p;\n    size_t      length;\n    njs_bool_t  trail;\n    char        src[NJS_MAX_PATH + 1];\n\n    trail = 0;\n    length = info->name.length;\n\n    if (dir != NULL) {\n        length = dir->length;\n\n        if (length == 0) {\n            return NJS_DECLINED;\n        }\n\n        trail = (dir->start[dir->length - 1] != '/');\n\n        if (trail) {\n            length++;\n        }\n    }\n\n    if (njs_slow_path(length > NJS_MAX_PATH)) {\n        return NJS_ERROR;\n    }\n\n    p = &src[0];\n\n    if (dir != NULL) {\n        p = (char *) njs_cpymem(p, dir->start, dir->length);\n\n        if (trail) {\n            *p++ = '/';\n        }\n    }\n\n    p = (char *) njs_cpymem(p, info->name.start, info->name.length);\n    *p = '\\0';\n\n    p = realpath(&src[0], &info->path[0]);\n    if (p == NULL) {\n        return NJS_DECLINED;\n    }\n\n    info->fd = open(&info->path[0], O_RDONLY);\n    if (info->fd < 0) {\n        return NJS_DECLINED;\n    }\n\n\n    info->file.start = (u_char *) &info->path[0];\n    info->file.length = njs_strlen(info->file.start);\n\n    return NJS_OK;\n}", "func_hash": 236847431367932249474325490160608146650, "file_name": "njs_module.c", "file_hash": 230069477074111336405443824718201036517, "cwe": ["CWE-787"], "cve": "CVE-2022-29379", "cve_desc": "Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29379", "file_path": "src/njs_module.c"}
{"idx": 255574, "project": "njs", "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "commit_message": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).", "target": 0, "func": "njs_module_path(njs_vm_t *vm, const njs_str_t *dir, njs_module_info_t *info)\n{\n    char        *p;\n    size_t      length;\n    njs_bool_t  trail;\n    char        src[NJS_MAX_PATH + 1];\n\n    trail = 0;\n    length = info->name.length;\n\n    if (dir != NULL) {\n        length += dir->length;\n\n        if (length == 0) {\n            return NJS_DECLINED;\n        }\n\n        trail = (dir->start[dir->length - 1] != '/');\n\n        if (trail) {\n            length++;\n        }\n    }\n\n    if (njs_slow_path(length > NJS_MAX_PATH)) {\n        return NJS_ERROR;\n    }\n\n    p = &src[0];\n\n    if (dir != NULL) {\n        p = (char *) njs_cpymem(p, dir->start, dir->length);\n\n        if (trail) {\n            *p++ = '/';\n        }\n    }\n\n    p = (char *) njs_cpymem(p, info->name.start, info->name.length);\n    *p = '\\0';\n\n    p = realpath(&src[0], &info->path[0]);\n    if (p == NULL) {\n        return NJS_DECLINED;\n    }\n\n    info->fd = open(&info->path[0], O_RDONLY);\n    if (info->fd < 0) {\n        return NJS_DECLINED;\n    }\n\n\n    info->file.start = (u_char *) &info->path[0];\n    info->file.length = njs_strlen(info->file.start);\n\n    return NJS_OK;\n}", "func_hash": 78973632734119439539784178182699583703, "file_name": "njs_module.c", "file_hash": 205736021540779021398705962921872486789, "cwe": ["CWE-787"], "cve": "CVE-2022-29379", "cve_desc": "Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29379", "file_path": "src/njs_module.c"}
{"idx": 197239, "project": "tensorflow", "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9", "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.dim_size(0)));\n\n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }", "func_hash": 324241400481110766657474950076141174434, "file_name": "mkl_requantize_per_channel_op.cc", "file_hash": 251676487738280920031977890166955496760, "cwe": ["CWE-20"], "cve": "CVE-2021-37665", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665", "file_path": "tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc"}
{"idx": 255787, "project": "tensorflow", "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9", "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      size_t depth = input_min_vec.NumElements();\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      OP_REQUIRES(\n          ctx, input_max_vec.NumElements() == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.NumElements()));\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      if (out_type_ == DT_QINT8) {\n        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n                    errors::InvalidArgument(\n                        \"If out_type is QINT8, requested_output_max must be \"\n                        \"non negative, got \",\n                        input_requested_min_float));\n      }\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }", "func_hash": 201878661619754288848170161353082339443, "file_name": "mkl_requantize_per_channel_op.cc", "file_hash": 305646743359625407590451757209165637710, "cwe": ["CWE-20"], "cve": "CVE-2021-37665", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665", "file_path": "tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc"}
