{"idx": 195274, "project": "tensorflow", "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1", "commit_message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "target": 1, "func": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}", "func_hash": 134451371039665673916173676790439576039, "file_name": "constant_folding.cc", "file_hash": 221573695858123615640237954647315751120, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589", "file_path": "tensorflow/core/common_runtime/constant_folding.cc"}
{"idx": 223728, "project": "tensorflow", "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1", "commit_message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "target": 0, "func": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  if (mul_left_child == nullptr || mul_right_child == nullptr) {\n    return false;\n  }\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}", "func_hash": 283045777051933437914385494105493059717, "file_name": "constant_folding.cc", "file_hash": 149567017925135188078420823730624272905, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589", "file_path": "tensorflow/core/common_runtime/constant_folding.cc"}
{"idx": 195291, "project": "tensorflow", "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b", "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1", "target": 1, "func": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }", "func_hash": 110563830933859876998490806365273446744, "file_name": "assign_op.h", "file_hash": 69919930869774703131816695670485389180, "cwe": ["CWE-908"], "cve": "CVE-2022-23573", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23573", "file_path": "tensorflow/core/kernels/assign_op.h"}
{"idx": 224153, "project": "tensorflow", "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b", "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1", "target": 0, "func": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // Prevent copying uninitialized data, to solve harder to debug undefined\n    // behaviors that cannot be traced back to the original tensor.\n    OP_REQUIRES(\n        context, rhs.IsInitialized(),\n        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }", "func_hash": 305037740106398797533289727050001288809, "file_name": "assign_op.h", "file_hash": 227740622376075800348272805227748641889, "cwe": ["CWE-908"], "cve": "CVE-2022-23573", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23573", "file_path": "tensorflow/core/kernels/assign_op.h"}
