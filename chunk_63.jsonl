{"idx": 198350, "project": "owntone-server", "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "project_url": "https://github.com/owntone/owntone-server", "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug", "target": 1, "func": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get the port that was assigned\n  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n\n  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}", "func_hash": 32546260713202661418218833633405896143, "file_name": "misc.c", "file_hash": 105075321496416144885475599863207164581, "cwe": ["CWE-416"], "cve": "CVE-2021-38383", "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383", "file_path": "src/misc.c"}
{"idx": 273091, "project": "owntone-server", "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "project_url": "https://github.com/owntone/owntone-server", "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug", "target": 0, "func": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  union net_sockaddr naddr = { 0 };\n  socklen_t naddr_len = sizeof(naddr);\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get our address (as string) and the port that was assigned (necessary when\n  // caller didn't specify a port)\n  ret = getsockname(fd, &naddr.sa, &naddr_len);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Error finding address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n  else if (naddr_len > sizeof(naddr))\n    {\n      DPRINTF(E_LOG, L_MISC, \"Unexpected address length of service '%s'\\n\", log_service_name);\n      goto error;\n    }\n\n  net_port_get(port, &naddr);\n  net_address_get(addr, sizeof(addr), &naddr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}", "func_hash": 222091533748174549495589798239680166393, "file_name": "misc.c", "file_hash": 109030313181388769357445523159421396120, "cwe": ["CWE-416"], "cve": "CVE-2021-38383", "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383", "file_path": "src/misc.c"}
{"idx": 198374, "project": "tensorflow", "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a", "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* x_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));\n\n    const Tensor* cs_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n\n    const Tensor* h_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n\n    const Tensor* w_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n\n    const Tensor* wci_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n\n    const Tensor* wcf_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n\n    const Tensor* wco_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n\n    const Tensor* b_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n    const int64_t cell_size = cs_prev_tensor->dim_size(1);\n\n    // Sanity checks for our input shapes.\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"cs_prev.dims(0) != batch_size: \",\n                                        cs_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\"cs_prev.dims(1) != cell_size: \",\n                                        cs_prev_tensor->dim_size(1), \" vs. \",\n                                        cell_size));\n\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",\n                                        h_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\n                    \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),\n                    \" vs. \", cell_size));\n\n    OP_REQUIRES(ctx, w_tensor->dim_size(0) == input_size + cell_size,\n                errors::InvalidArgument(\n                    \"w.dim_size(0) != input_size + cell_size: \",\n                    w_tensor->dim_size(0), \" vs. \", input_size + cell_size));\n    OP_REQUIRES(ctx, w_tensor->dim_size(1) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"w.dim_size(1) != cell_size * 4: \", w_tensor->dim_size(1),\n                    \" vs. \", cell_size * 4));\n\n    OP_REQUIRES(ctx, b_tensor->dim_size(0) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"b.dim_size(0) != cell_size * 4: \", b_tensor->dim_size(0),\n                    \" vs. \", cell_size * 4));\n\n    // Allocate our output tensors.\n    Tensor* i_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"h_prev\"}, \"i\",\n                            TensorShape({batch_size, cell_size}), &i_tensor));\n\n    Tensor* cs_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"cs\", TensorShape({batch_size, cell_size}),\n                                  &cs_tensor));\n\n    Tensor* f_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"f\", TensorShape({batch_size, cell_size}),\n                                  &f_tensor));\n\n    Tensor* o_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"cs_prev\"}, \"o\",\n                            TensorShape({batch_size, cell_size}), &o_tensor));\n\n    Tensor* ci_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"ci\", TensorShape({batch_size, cell_size}),\n                                  &ci_tensor));\n\n    Tensor* co_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"co\", TensorShape({batch_size, cell_size}),\n                                  &co_tensor));\n\n    Tensor* h_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"h\", TensorShape({batch_size, cell_size}),\n                                  &h_tensor));\n\n    // Allocate our temp tensors.\n    Tensor xh_tensor;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(\n                            DataTypeToEnum<T>::v(),\n                            TensorShape({batch_size, input_size + cell_size}),\n                            &xh_tensor));\n\n    Tensor gates_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<T>::v(),\n                                      TensorShape({batch_size, cell_size * 4}),\n                                      &gates_tensor));\n\n    const Device& device = ctx->eigen_device<Device>();\n\n    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n        batch_size, input_size, cell_size)(\n        ctx, device, forget_bias_, cell_clip_, use_peephole_,\n        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),\n        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),\n        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),\n        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),\n        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),\n        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),\n        h_tensor->matrix<T>());\n  }", "func_hash": 332787893197526379241591780916041422587, "file_name": "lstm_ops.cc", "file_hash": 94555141575162353468670590418949369497, "cwe": ["CWE-703"], "cve": "CVE-2022-29200", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29200", "file_path": "tensorflow/core/kernels/rnn/lstm_ops.cc"}
{"idx": 273407, "project": "tensorflow", "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a", "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* x_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));\n\n    const Tensor* cs_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n\n    const Tensor* h_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n\n    const Tensor* w_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n\n    const Tensor* wci_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n\n    const Tensor* wcf_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n\n    const Tensor* wco_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n\n    const Tensor* b_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n    const int64_t cell_size = cs_prev_tensor->dim_size(1);\n\n    // Sanity checks for our input shapes.\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"cs_prev.dims(0) != batch_size: \",\n                                        cs_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\"cs_prev.dims(1) != cell_size: \",\n                                        cs_prev_tensor->dim_size(1), \" vs. \",\n                                        cell_size));\n\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",\n                                        h_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\n                    \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),\n                    \" vs. \", cell_size));\n\n    OP_REQUIRES(ctx, w_tensor->dim_size(0) == input_size + cell_size,\n                errors::InvalidArgument(\n                    \"w.dim_size(0) != input_size + cell_size: \",\n                    w_tensor->dim_size(0), \" vs. \", input_size + cell_size));\n    OP_REQUIRES(ctx, w_tensor->dim_size(1) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"w.dim_size(1) != cell_size * 4: \", w_tensor->dim_size(1),\n                    \" vs. \", cell_size * 4));\n\n    OP_REQUIRES(ctx, b_tensor->dim_size(0) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"b.dim_size(0) != cell_size * 4: \", b_tensor->dim_size(0),\n                    \" vs. \", cell_size * 4));\n\n    // Allocate our output tensors.\n    Tensor* i_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"h_prev\"}, \"i\",\n                            TensorShape({batch_size, cell_size}), &i_tensor));\n\n    Tensor* cs_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"cs\", TensorShape({batch_size, cell_size}),\n                                  &cs_tensor));\n\n    Tensor* f_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"f\", TensorShape({batch_size, cell_size}),\n                                  &f_tensor));\n\n    Tensor* o_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"cs_prev\"}, \"o\",\n                            TensorShape({batch_size, cell_size}), &o_tensor));\n\n    Tensor* ci_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"ci\", TensorShape({batch_size, cell_size}),\n                                  &ci_tensor));\n\n    Tensor* co_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"co\", TensorShape({batch_size, cell_size}),\n                                  &co_tensor));\n\n    Tensor* h_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"h\", TensorShape({batch_size, cell_size}),\n                                  &h_tensor));\n\n    // Allocate our temp tensors.\n    Tensor xh_tensor;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(\n                            DataTypeToEnum<T>::v(),\n                            TensorShape({batch_size, input_size + cell_size}),\n                            &xh_tensor));\n\n    Tensor gates_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<T>::v(),\n                                      TensorShape({batch_size, cell_size * 4}),\n                                      &gates_tensor));\n\n    const Device& device = ctx->eigen_device<Device>();\n\n    // Sanity check that each of the tensors have the required NDIMS.\n    OP_REQUIRES(ctx, x_tensor->dims() == 2,\n                errors::InvalidArgument(\"x_tensor must be rank 2 but is rank \",\n                                        x_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, cs_prev_tensor->dims() == 2,\n        errors::InvalidArgument(\"cs_prev_tensor must be rank 2 but is rank \",\n                                cs_prev_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, h_prev_tensor->dims() == 2,\n        errors::InvalidArgument(\"h_prev_tensor must be rank 2 but is rank \",\n                                h_prev_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, w_tensor->dims() == 2,\n                errors::InvalidArgument(\"w_tensor must be rank 2 but is rank \",\n                                        w_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, wci_tensor->dims() == 1,\n        errors::InvalidArgument(\"wci_tensor must be rank 1 but is rank \",\n                                wci_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, wcf_tensor->dims() == 1,\n        errors::InvalidArgument(\"wcf_tensor must be rank 1 but is rank \",\n                                wci_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, wco_tensor->dims() == 1,\n        errors::InvalidArgument(\"wco_tensor must be rank 1 but is rank \",\n                                wco_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, b_tensor->dims() == 1,\n                errors::InvalidArgument(\"b_tensor must be rank 1 but is rank \",\n                                        b_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, xh_tensor.dims() == 2,\n                errors::InvalidArgument(\"xh_tensor must be rank 2 but is rank \",\n                                        xh_tensor.dims(), \".\"));\n    OP_REQUIRES(ctx, i_tensor->dims() == 2,\n                errors::InvalidArgument(\"i_tensor must be rank 2 but is rank \",\n                                        i_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, cs_tensor->dims() == 2,\n                errors::InvalidArgument(\"cs_tensor must be rank 2 but is rank \",\n                                        cs_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, f_tensor->dims() == 2,\n                errors::InvalidArgument(\"f_tensor must be rank 2 but is rank \",\n                                        f_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, o_tensor->dims() == 2,\n                errors::InvalidArgument(\"o_tensor must be rank 2 but is rank \",\n                                        o_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, ci_tensor->dims() == 2,\n                errors::InvalidArgument(\"ci_tensor must be rank 2 but is rank \",\n                                        ci_tensor->dims(), \".\"));\n    OP_REQUIRES(ctx, co_tensor->dims() == 2,\n                errors::InvalidArgument(\"co_tensor must be rank 2 but is rank \",\n                                        co_tensor->dims(), \".\"));\n    OP_REQUIRES(\n        ctx, gates_tensor.dims() == 2,\n        errors::InvalidArgument(\"gates_tensor must be rank 2 but is rank \",\n                                gates_tensor.dims(), \".\"));\n    OP_REQUIRES(ctx, h_tensor->dims() == 2,\n                errors::InvalidArgument(\"h_tensor must be rank 2 but is rank \",\n                                        h_tensor->dims(), \".\"));\n\n    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n        batch_size, input_size, cell_size)(\n        ctx, device, forget_bias_, cell_clip_, use_peephole_,\n        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),\n        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),\n        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),\n        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),\n        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),\n        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),\n        h_tensor->matrix<T>());\n  }", "func_hash": 258695141881627595709406834872901892471, "file_name": "lstm_ops.cc", "file_hash": 177796578902754451713518476941050283987, "cwe": ["CWE-703"], "cve": "CVE-2022-29200", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29200", "file_path": "tensorflow/core/kernels/rnn/lstm_ops.cc"}
