{"idx": 195954, "project": "pjproject", "commit_id": "9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a", "commit_message": "Merge pull request from GHSA-p6g5-v97c-w5q4\n\n* Prevent heap buffer overflow when parsing DNS packets\n\n* Make sure packet parsing doesn't advance beyond max/end\n\n* Update checks\n\n* Remove  check\n\nCo-authored-by: sauwming <ming@teluu.com>", "target": 1, "func": "static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n\t\t\t       const pj_uint8_t *pkt, const pj_uint8_t *start,\n\t\t\t       const pj_uint8_t *max, int *parsed_len)\n{\n    const pj_uint8_t *p = start;\n    int name_len, name_part_len;\n    pj_status_t status;\n\n    /* Get the length of the name */\n    status = get_name_len(0, pkt, start, max, &name_part_len, &name_len);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    /* Allocate memory for the name */\n    q->name.ptr = (char*) pj_pool_alloc(pool, name_len+4);\n    q->name.slen = 0;\n\n    /* Get the name */\n    status = get_name(0, pkt, start, max, &q->name);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    p = (start + name_part_len);\n\n    /* Get the type */\n    pj_memcpy(&q->type, p, 2);\n    q->type = pj_ntohs(q->type);\n    p += 2;\n\n    /* Get the class */\n    pj_memcpy(&q->dnsclass, p, 2);\n    q->dnsclass = pj_ntohs(q->dnsclass);\n    p += 2;\n\n    *parsed_len = (int)(p - start);\n\n    return PJ_SUCCESS;\n}", "func_hash": 135450072303259419822933820270333517166, "file_name": "dns.c", "file_hash": 253652259492393007596255371845847130395, "cwe": ["CWE-787"], "cve": "CVE-2022-24793", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. A buffer overflow vulnerability in versions 2.12 and prior affects applications that use PJSIP DNS resolution. It doesn't affect PJSIP users who utilize an external resolver. This vulnerability is related to CVE-2023-27585. The difference is that this issue is in parsing the query record `parse_rr()`, while the issue in CVE-2023-27585 is in `parse_query()`. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. A workaround is to disable DNS resolution in PJSIP config (by setting `nameserver_count` to zero) or use an external resolver instead.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24793", "file_path": "pjlib-util/src/pjlib-util/dns.c"}
{"idx": 235642, "project": "pjproject", "commit_id": "9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/9fae8f43accef8ea65d4a8ae9cdf297c46cfe29a", "commit_message": "Merge pull request from GHSA-p6g5-v97c-w5q4\n\n* Prevent heap buffer overflow when parsing DNS packets\n\n* Make sure packet parsing doesn't advance beyond max/end\n\n* Update checks\n\n* Remove  check\n\nCo-authored-by: sauwming <ming@teluu.com>", "target": 0, "func": "static pj_status_t parse_query(pj_dns_parsed_query *q, pj_pool_t *pool,\n\t\t\t       const pj_uint8_t *pkt, const pj_uint8_t *start,\n\t\t\t       const pj_uint8_t *max, int *parsed_len)\n{\n    const pj_uint8_t *p = start;\n    int name_len, name_part_len;\n    pj_status_t status;\n\n    /* Get the length of the name */\n    status = get_name_len(0, pkt, start, max, &name_part_len, &name_len);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    /* Allocate memory for the name */\n    q->name.ptr = (char*) pj_pool_alloc(pool, name_len+4);\n    q->name.slen = 0;\n\n    /* Get the name */\n    status = get_name(0, pkt, start, max, &q->name);\n    if (status != PJ_SUCCESS)\n\treturn status;\n\n    p = (start + name_part_len);\n\n    /* Check the size can accomodate next few fields. */\n    if (p + 4 > max)\n    \treturn PJLIB_UTIL_EDNSINSIZE;\n\n    /* Get the type */\n    pj_memcpy(&q->type, p, 2);\n    q->type = pj_ntohs(q->type);\n    p += 2;\n\n    /* Get the class */\n    pj_memcpy(&q->dnsclass, p, 2);\n    q->dnsclass = pj_ntohs(q->dnsclass);\n    p += 2;\n\n    *parsed_len = (int)(p - start);\n\n    return PJ_SUCCESS;\n}", "func_hash": 182542196466721409447058148432122336027, "file_name": "dns.c", "file_hash": 267684295944312304672181273486771812087, "cwe": ["CWE-787"], "cve": "CVE-2022-24793", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. A buffer overflow vulnerability in versions 2.12 and prior affects applications that use PJSIP DNS resolution. It doesn't affect PJSIP users who utilize an external resolver. This vulnerability is related to CVE-2023-27585. The difference is that this issue is in parsing the query record `parse_rr()`, while the issue in CVE-2023-27585 is in `parse_query()`. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. A workaround is to disable DNS resolution in PJSIP config (by setting `nameserver_count` to zero) or use an external resolver instead.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-24793", "file_path": "pjlib-util/src/pjlib-util/dns.c"}
{"idx": 195965, "project": "tensorflow", "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/30721cf564cb029d34535446d6a5a6357bebc8e7", "commit_message": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* hypothesis_indices;\n    const Tensor* hypothesis_values;\n    const Tensor* hypothesis_shape;\n    const Tensor* truth_indices;\n    const Tensor* truth_values;\n    const Tensor* truth_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_indices\", &hypothesis_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_values\", &hypothesis_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_shape\", &hypothesis_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_indices\", &truth_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_values\", &truth_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_shape\", &truth_shape));\n\n    OP_REQUIRES_OK(\n        ctx, ValidateShapes(ctx, *hypothesis_indices, *hypothesis_values,\n                            *hypothesis_shape, *truth_indices, *truth_values,\n                            *truth_shape));\n\n    TensorShape hypothesis_st_shape;\n    OP_REQUIRES_OK(ctx,\n                   TensorShapeUtils::MakeShape(\n                       hypothesis_shape->vec<int64_t>().data(),\n                       hypothesis_shape->NumElements(), &hypothesis_st_shape));\n    TensorShape truth_st_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n                            truth_shape->vec<int64_t>().data(),\n                            truth_shape->NumElements(), &truth_st_shape));\n\n    // Assume indices are sorted in row-major order.\n    std::vector<int64_t> sorted_order(truth_st_shape.dims());\n    std::iota(sorted_order.begin(), sorted_order.end(), 0);\n\n    sparse::SparseTensor hypothesis;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *hypothesis_indices, *hypothesis_values,\n                            hypothesis_st_shape, sorted_order, &hypothesis));\n\n    sparse::SparseTensor truth;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *truth_indices, *truth_values, truth_st_shape,\n                            sorted_order, &truth));\n\n    // Group dims 0, 1, ..., RANK - 1.  The very last dim is assumed\n    // to store the variable length sequences.\n    std::vector<int64_t> group_dims(truth_st_shape.dims() - 1);\n    std::iota(group_dims.begin(), group_dims.end(), 0);\n\n    TensorShape output_shape;\n    for (int d = 0; d < static_cast<int>(group_dims.size()); ++d) {\n      output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                   truth_st_shape.dim_size(d)));\n    }\n    const auto output_elements = output_shape.num_elements();\n    OP_REQUIRES(\n        ctx, output_elements > 0,\n        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n                                \" which has 0 elements\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n    auto output_t = output->flat<float>();\n    output_t.setZero();\n\n    std::vector<int64_t> output_strides(output_shape.dims());\n    output_strides[output_shape.dims() - 1] = 1;\n    for (int d = output_shape.dims() - 2; d >= 0; --d) {\n      output_strides[d] = output_strides[d + 1] * output_shape.dim_size(d + 1);\n    }\n\n    auto hypothesis_grouper = hypothesis.group(group_dims);\n    auto truth_grouper = truth.group(group_dims);\n\n    auto hypothesis_iter = hypothesis_grouper.begin();\n    auto truth_iter = truth_grouper.begin();\n\n    auto cmp = std::equal_to<T>();\n\n    while (hypothesis_iter != hypothesis_grouper.end() &&\n           truth_iter != truth_grouper.end()) {\n      sparse::Group truth_i = *truth_iter;\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto truth_seq = truth_i.values<T>();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n\n      if (g_truth == g_hypothesis) {\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) =\n            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n        if (normalize_) output_t(loc) /= truth_seq.size();\n\n        ++hypothesis_iter;\n        ++truth_iter;\n      } else if (g_truth > g_hypothesis) {  // zero-length truth\n        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = hypothesis_seq.size();\n        if (normalize_ && output_t(loc) != 0.0f) {\n          output_t(loc) = std::numeric_limits<float>::infinity();\n        }\n        ++hypothesis_iter;\n      } else {  // zero-length hypothesis\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require in writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n        ++truth_iter;\n      }\n    }\n    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = hypothesis_seq.size();\n      if (normalize_ && output_t(loc) != 0.0f) {\n        output_t(loc) = std::numeric_limits<float>::infinity();\n      }\n      ++hypothesis_iter;\n    }\n    while (truth_iter != truth_grouper.end()) {  // missing hypotheses\n      sparse::Group truth_i = *truth_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      auto truth_seq = truth_i.values<T>();\n      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require in writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n      ++truth_iter;\n    }\n  }", "func_hash": 330908344605810468129440704571471984591, "file_name": "edit_distance_op.cc", "file_hash": 218278977682570302037113861275408263141, "cwe": ["CWE-787"], "cve": "CVE-2022-29208", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29208", "file_path": "tensorflow/core/kernels/edit_distance_op.cc"}
{"idx": 235765, "project": "tensorflow", "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/30721cf564cb029d34535446d6a5a6357bebc8e7", "commit_message": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* hypothesis_indices;\n    const Tensor* hypothesis_values;\n    const Tensor* hypothesis_shape;\n    const Tensor* truth_indices;\n    const Tensor* truth_values;\n    const Tensor* truth_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_indices\", &hypothesis_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_values\", &hypothesis_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"hypothesis_shape\", &hypothesis_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_indices\", &truth_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_values\", &truth_values));\n    OP_REQUIRES_OK(ctx, ctx->input(\"truth_shape\", &truth_shape));\n\n    OP_REQUIRES_OK(\n        ctx, ValidateShapes(ctx, *hypothesis_indices, *hypothesis_values,\n                            *hypothesis_shape, *truth_indices, *truth_values,\n                            *truth_shape));\n\n    TensorShape hypothesis_st_shape;\n    OP_REQUIRES_OK(ctx,\n                   TensorShapeUtils::MakeShape(\n                       hypothesis_shape->vec<int64_t>().data(),\n                       hypothesis_shape->NumElements(), &hypothesis_st_shape));\n    TensorShape truth_st_shape;\n    OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n                            truth_shape->vec<int64_t>().data(),\n                            truth_shape->NumElements(), &truth_st_shape));\n\n    // Assume indices are sorted in row-major order.\n    std::vector<int64_t> sorted_order(truth_st_shape.dims());\n    std::iota(sorted_order.begin(), sorted_order.end(), 0);\n\n    sparse::SparseTensor hypothesis;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *hypothesis_indices, *hypothesis_values,\n                            hypothesis_st_shape, sorted_order, &hypothesis));\n\n    sparse::SparseTensor truth;\n    OP_REQUIRES_OK(ctx, sparse::SparseTensor::Create(\n                            *truth_indices, *truth_values, truth_st_shape,\n                            sorted_order, &truth));\n\n    // Group dims 0, 1, ..., RANK - 1.  The very last dim is assumed\n    // to store the variable length sequences.\n    std::vector<int64_t> group_dims(truth_st_shape.dims() - 1);\n    std::iota(group_dims.begin(), group_dims.end(), 0);\n\n    TensorShape output_shape;\n    for (int d = 0; d < static_cast<int>(group_dims.size()); ++d) {\n      output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\n                                   truth_st_shape.dim_size(d)));\n    }\n    const auto output_elements = output_shape.num_elements();\n    OP_REQUIRES(\n        ctx, output_elements > 0,\n        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\n                                \" which has 0 elements\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\n    auto output_t = output->flat<float>();\n    output_t.setZero();\n\n    std::vector<int64_t> output_strides(output_shape.dims());\n    output_strides[output_shape.dims() - 1] = 1;\n    for (int d = output_shape.dims() - 2; d >= 0; --d) {\n      output_strides[d] = output_strides[d + 1] * output_shape.dim_size(d + 1);\n    }\n\n    auto hypothesis_grouper = hypothesis.group(group_dims);\n    auto truth_grouper = truth.group(group_dims);\n\n    auto hypothesis_iter = hypothesis_grouper.begin();\n    auto truth_iter = truth_grouper.begin();\n\n    auto cmp = std::equal_to<T>();\n\n    while (hypothesis_iter != hypothesis_grouper.end() &&\n           truth_iter != truth_grouper.end()) {\n      sparse::Group truth_i = *truth_iter;\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto truth_seq = truth_i.values<T>();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n\n      if (g_truth == g_hypothesis) {\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, 0 <= loc && loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) =\n            gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\n        if (normalize_) output_t(loc) /= truth_seq.size();\n\n        ++hypothesis_iter;\n        ++truth_iter;\n      } else if (g_truth > g_hypothesis) {  // zero-length truth\n        auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, 0 <= loc && loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = hypothesis_seq.size();\n        if (normalize_ && output_t(loc) != 0.0f) {\n          output_t(loc) = std::numeric_limits<float>::infinity();\n        }\n        ++hypothesis_iter;\n      } else {  // zero-length hypothesis\n        auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                      output_strides.begin(), int64_t{0});\n        OP_REQUIRES(\n            ctx, 0 <= loc && loc < output_elements,\n            errors::Internal(\"Got an inner product \", loc,\n                             \" which would require writing to outside of \"\n                             \"the buffer for the output tensor (max elements \",\n                             output_elements, \")\"));\n        output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n        ++truth_iter;\n      }\n    }\n    while (hypothesis_iter != hypothesis_grouper.end()) {  // zero-length truths\n      sparse::Group hypothesis_j = *hypothesis_iter;\n      std::vector<int64_t> g_hypothesis = hypothesis_j.group();\n      auto hypothesis_seq = hypothesis_j.values<T>();\n      auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, 0 <= loc && loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = hypothesis_seq.size();\n      if (normalize_ && output_t(loc) != 0.0f) {\n        output_t(loc) = std::numeric_limits<float>::infinity();\n      }\n      ++hypothesis_iter;\n    }\n    while (truth_iter != truth_grouper.end()) {  // missing hypotheses\n      sparse::Group truth_i = *truth_iter;\n      std::vector<int64_t> g_truth = truth_i.group();\n      auto truth_seq = truth_i.values<T>();\n      auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\n                                    output_strides.begin(), int64_t{0});\n      OP_REQUIRES(\n          ctx, 0 <= loc && loc < output_elements,\n          errors::Internal(\"Got an inner product \", loc,\n                           \" which would require writing to outside of the \"\n                           \"buffer for the output tensor (max elements \",\n                           output_elements, \")\"));\n      output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\n      ++truth_iter;\n    }\n  }", "func_hash": 248166369480919859740493813092777127281, "file_name": "edit_distance_op.cc", "file_hash": 224900034498319197270351200055296266799, "cwe": ["CWE-787"], "cve": "CVE-2022-29208", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29208", "file_path": "tensorflow/core/kernels/edit_distance_op.cc"}
{"idx": 195984, "project": "gpac", "commit_id": "3dbe11b37d65c8472faf0654410068e5500b3adb", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/3dbe11b37d65c8472faf0654410068e5500b3adb", "commit_message": "fixed #2175", "target": 1, "func": "GF_Err diST_box_read(GF_Box *s, GF_BitStream *bs)\n{\n\tu32 i;\n\tchar str[1024];\n\tGF_DIMSScriptTypesBox *p = (GF_DIMSScriptTypesBox *)s;\n\n\ti=0;\n\tstr[0]=0;\n\twhile (1) {\n\t\tstr[i] = gf_bs_read_u8(bs);\n\t\tif (!str[i]) break;\n\t\ti++;\n\t}\n\tISOM_DECREASE_SIZE(p, i);\n\n\tp->content_script_types = gf_strdup(str);\n\treturn GF_OK;\n}", "func_hash": 337508066102203205232219987774332438264, "file_name": "box_code_3gpp.c", "file_hash": 236995747067078276861335410375287788449, "cwe": ["CWE-703"], "cve": "CVE-2022-1441", "cve_desc": "MP4Box is a component of GPAC-2.0.0, which is a widely-used third-party package on RPM Fusion. When MP4Box tries to parse a MP4 file, it calls the function `diST_box_read()` to read from video. In this function, it allocates a buffer `str` with fixed length. However, content read from `bs` is controllable by user, so is the length, which causes a buffer overflow.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1441", "file_path": "src/isomedia/box_code_3gpp.c"}
