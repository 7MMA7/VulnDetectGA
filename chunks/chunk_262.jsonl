{"idx": 210484, "project": "linux", "commit_id": "89c2b3b74918200e46699338d7bcc19b1ea12110", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=89c2b3b74918200e46699338d7bcc19b1ea12110", "commit_message": "io_uring: reexpand under-reexpanded iters\n\n[   74.211232] BUG: KASAN: stack-out-of-bounds in iov_iter_revert+0x809/0x900\n[   74.212778] Read of size 8 at addr ffff888025dc78b8 by task\nsyz-executor.0/828\n[   74.214756] CPU: 0 PID: 828 Comm: syz-executor.0 Not tainted\n5.14.0-rc3-next-20210730 #1\n[   74.216525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),\nBIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014\n[   74.219033] Call Trace:\n[   74.219683]  dump_stack_lvl+0x8b/0xb3\n[   74.220706]  print_address_description.constprop.0+0x1f/0x140\n[   74.224226]  kasan_report.cold+0x7f/0x11b\n[   74.226085]  iov_iter_revert+0x809/0x900\n[   74.227960]  io_write+0x57d/0xe40\n[   74.232647]  io_issue_sqe+0x4da/0x6a80\n[   74.242578]  __io_queue_sqe+0x1ac/0xe60\n[   74.245358]  io_submit_sqes+0x3f6e/0x76a0\n[   74.248207]  __do_sys_io_uring_enter+0x90c/0x1a20\n[   74.257167]  do_syscall_64+0x3b/0x90\n[   74.257984]  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nold_size = iov_iter_count();\n...\niov_iter_revert(old_size - iov_iter_count());\n\nIf iov_iter_revert() is done base on the initial size as above, and the\niter is truncated and not reexpanded in the middle, it miscalculates\nborders causing problems. This trace is due to no one reexpanding after\ngeneric_write_checks().\n\nNow iters store how many bytes has been truncated, so reexpand them to\nthe initial state right before reverting.\n\nCc: stable@vger.kernel.org\nReported-by: Palash Oswal <oswalpalash@gmail.com>\nReported-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>\nReported-and-tested-by: syzbot+9671693590ef5aad8953@syzkaller.appspotmail.com\nSigned-off-by: Pavel Begunkov <asml.silence@gmail.com>\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>", "target": 1, "func": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}", "func_hash": 240635131512739563674871384281451113000, "file_name": "io_uring.c", "file_hash": 270228936608432888169467151756461550796, "cwe": ["CWE-125"], "cve": "CVE-2022-1508", "cve_desc": "An out-of-bounds read flaw was found in the Linux kernel\u2019s io_uring module in the way a user triggers the io_read() function with some special parameters. This flaw allows a local user to read some memory out of bounds.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1508", "file_path": "fs/io_uring.c"}
{"idx": 436066, "project": "linux", "commit_id": "89c2b3b74918200e46699338d7bcc19b1ea12110", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=89c2b3b74918200e46699338d7bcc19b1ea12110", "commit_message": "io_uring: reexpand under-reexpanded iters\n\n[   74.211232] BUG: KASAN: stack-out-of-bounds in iov_iter_revert+0x809/0x900\n[   74.212778] Read of size 8 at addr ffff888025dc78b8 by task\nsyz-executor.0/828\n[   74.214756] CPU: 0 PID: 828 Comm: syz-executor.0 Not tainted\n5.14.0-rc3-next-20210730 #1\n[   74.216525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),\nBIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014\n[   74.219033] Call Trace:\n[   74.219683]  dump_stack_lvl+0x8b/0xb3\n[   74.220706]  print_address_description.constprop.0+0x1f/0x140\n[   74.224226]  kasan_report.cold+0x7f/0x11b\n[   74.226085]  iov_iter_revert+0x809/0x900\n[   74.227960]  io_write+0x57d/0xe40\n[   74.232647]  io_issue_sqe+0x4da/0x6a80\n[   74.242578]  __io_queue_sqe+0x1ac/0xe60\n[   74.245358]  io_submit_sqes+0x3f6e/0x76a0\n[   74.248207]  __do_sys_io_uring_enter+0x90c/0x1a20\n[   74.257167]  do_syscall_64+0x3b/0x90\n[   74.257984]  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nold_size = iov_iter_count();\n...\niov_iter_revert(old_size - iov_iter_count());\n\nIf iov_iter_revert() is done base on the initial size as above, and the\niter is truncated and not reexpanded in the middle, it miscalculates\nborders causing problems. This trace is due to no one reexpanding after\ngeneric_write_checks().\n\nNow iters store how many bytes has been truncated, so reexpand them to\nthe initial state right before reverting.\n\nCc: stable@vger.kernel.org\nReported-by: Palash Oswal <oswalpalash@gmail.com>\nReported-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>\nReported-and-tested-by: syzbot+9671693590ef5aad8953@syzkaller.appspotmail.com\nSigned-off-by: Pavel Begunkov <asml.silence@gmail.com>\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>", "target": 0, "func": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}", "func_hash": 272064897155914887448820335994410236838, "file_name": "io_uring.c", "file_hash": 29368837531971764003549686425861293292, "cwe": ["CWE-125"], "cve": "CVE-2022-1508", "cve_desc": "An out-of-bounds read flaw was found in the Linux kernel\u2019s io_uring module in the way a user triggers the io_read() function with some special parameters. This flaw allows a local user to read some memory out of bounds.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1508", "file_path": "fs/io_uring.c"}
