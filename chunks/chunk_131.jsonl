{"idx": 198452, "project": "tensorflow", "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921", "target": 1, "func": "void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                         TfLiteTensor* output, bool requires_broadcast) {\n  if (input1->type == kTfLiteUInt8 || input1->type == kTfLiteInt8) {\n    auto input1_offset = -input1->params.zero_point;\n    auto input2_offset = -input2->params.zero_point;\n    const int left_shift = 8;\n\n    int32 input1_multiplier;\n    int input1_shift;\n    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n                                        &input1_multiplier, &input1_shift);\n    int32 input2_multiplier;\n    int input2_shift;\n    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n                                        &input2_multiplier, &input2_shift);\n\n    ComparisonParams op_params;\n    op_params.left_shift = left_shift;\n    op_params.input1_offset = input1_offset;\n    op_params.input1_multiplier = input1_multiplier;\n    op_params.input1_shift = input1_shift;\n    op_params.input2_offset = input2_offset;\n    op_params.input2_multiplier = input2_multiplier;\n    op_params.input2_shift = input2_shift;\n    if (requires_broadcast) {\n      reference_ops::BroadcastComparison4DSlowWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    } else {\n      reference_ops::ComparisonWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    }\n  }\n}", "func_hash": 284336502909303651692457957640037138117, "file_name": "comparisons.cc", "file_hash": 224870261654956140630544765652331160875, "cwe": ["CWE-703"], "cve": "CVE-2022-29212", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29212", "file_path": "tensorflow/lite/kernels/comparisons.cc"}
{"idx": 274865, "project": "tensorflow", "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921", "target": 0, "func": "void ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                         TfLiteTensor* output, bool requires_broadcast) {\n  if (input1->type == kTfLiteUInt8 || input1->type == kTfLiteInt8) {\n    auto input1_offset = -input1->params.zero_point;\n    auto input2_offset = -input2->params.zero_point;\n    const int left_shift = 8;\n\n    int32 input1_multiplier;\n    int32 input2_multiplier;\n    int input1_shift;\n    int input2_shift;\n    QuantizeMultiplier(input1->params.scale, &input1_multiplier, &input1_shift);\n    QuantizeMultiplier(input2->params.scale, &input2_multiplier, &input2_shift);\n\n    ComparisonParams op_params;\n    op_params.left_shift = left_shift;\n    op_params.input1_offset = input1_offset;\n    op_params.input1_multiplier = input1_multiplier;\n    op_params.input1_shift = input1_shift;\n    op_params.input2_offset = input2_offset;\n    op_params.input2_multiplier = input2_multiplier;\n    op_params.input2_shift = input2_shift;\n    if (requires_broadcast) {\n      reference_ops::BroadcastComparison4DSlowWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    } else {\n      reference_ops::ComparisonWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    }\n  }\n}", "func_hash": 213386004946249159247710639352470904167, "file_name": "comparisons.cc", "file_hash": 191046017812634874260331571010514719419, "cwe": ["CWE-703"], "cve": "CVE-2022-29212", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29212", "file_path": "tensorflow/lite/kernels/comparisons.cc"}
