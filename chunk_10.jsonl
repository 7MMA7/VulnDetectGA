{"idx": 197395, "project": "tensorflow", "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1", "commit_message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c", "target": 1, "func": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& dims = context->input(1);\n\n    if (TensorShapeUtils::IsScalar(input.shape())) {\n      context->set_output(0, input);\n    } else {\n      const int input_dims = input.dims();\n      OP_REQUIRES(context, TensorShapeUtils::IsVector(dims.shape()),\n                  errors::InvalidArgument(\"'dims' must be 1-dimension, not \",\n                                          dims.dims()));\n\n      OP_REQUIRES(\n          context, input_dims == dims.dim_size(0),\n          errors::InvalidArgument(\n              \"'dims' must have the same number of values as 'input' has \"\n              \"dimensions. 'input' has \",\n              input_dims, \"'dims' has \", dims.dim_size(0), \" values\"));\n      OP_REQUIRES(context, input_dims <= 8,\n                  errors::Unimplemented(\n                      \"reverse is not implemented for tensors of rank > 8.\"));\n\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, input.shape(), &output));\n\n#define HANDLE_REVERSE(NDIMS)                                               \\\n  case NDIMS:                                                               \\\n    HandleReverseCase<Device, T, NDIMS>(context, dims.vec<bool>(), output); \\\n    return;\n\n      switch (input_dims) {\n        HANDLE_REVERSE(0);\n        HANDLE_REVERSE(1);\n        HANDLE_REVERSE(2);\n        HANDLE_REVERSE(3);\n        HANDLE_REVERSE(4);\n        HANDLE_REVERSE(5);\n        HANDLE_REVERSE(6);\n        HANDLE_REVERSE(7);\n        HANDLE_REVERSE(8);\n      }\n#undef HANDLE_REVERSE\n    }\n  }", "func_hash": 320359893140451578623172737965362672352, "file_name": "reverse_op.cc", "file_hash": 11850357512767152498311955295464965693, "cwe": ["CWE-369"], "cve": "CVE-2021-29556", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29556", "file_path": "tensorflow/core/kernels/reverse_op.cc"}
{"idx": 258082, "project": "tensorflow", "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1", "commit_message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c", "target": 0, "func": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    // If input is provided, check to make sure the first dimension is valid.\n    if (input.dims() > 0) {\n      OP_REQUIRES(\n          context, input.dim_size(0) != 0,\n          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\n    }\n    const Tensor& dims = context->input(1);\n\n    if (TensorShapeUtils::IsScalar(input.shape())) {\n      context->set_output(0, input);\n    } else {\n      const int input_dims = input.dims();\n      OP_REQUIRES(context, TensorShapeUtils::IsVector(dims.shape()),\n                  errors::InvalidArgument(\"'dims' must be 1-dimension, not \",\n                                          dims.dims()));\n\n      OP_REQUIRES(\n          context, input_dims == dims.dim_size(0),\n          errors::InvalidArgument(\n              \"'dims' must have the same number of values as 'input' has \"\n              \"dimensions. 'input' has \",\n              input_dims, \"'dims' has \", dims.dim_size(0), \" values\"));\n      OP_REQUIRES(context, input_dims <= 8,\n                  errors::Unimplemented(\n                      \"reverse is not implemented for tensors of rank > 8.\"));\n\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, input.shape(), &output));\n\n#define HANDLE_REVERSE(NDIMS)                                               \\\n  case NDIMS:                                                               \\\n    HandleReverseCase<Device, T, NDIMS>(context, dims.vec<bool>(), output); \\\n    return;\n\n      switch (input_dims) {\n        HANDLE_REVERSE(0);\n        HANDLE_REVERSE(1);\n        HANDLE_REVERSE(2);\n        HANDLE_REVERSE(3);\n        HANDLE_REVERSE(4);\n        HANDLE_REVERSE(5);\n        HANDLE_REVERSE(6);\n        HANDLE_REVERSE(7);\n        HANDLE_REVERSE(8);\n      }\n#undef HANDLE_REVERSE\n    }\n  }", "func_hash": 46291446365050561465946697163690877873, "file_name": "reverse_op.cc", "file_hash": 197535237441816623722096111592150464560, "cwe": ["CWE-369"], "cve": "CVE-2021-29556", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-29556", "file_path": "tensorflow/core/kernels/reverse_op.cc"}
{"idx": 197466, "project": "tensorflow", "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "commit_message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55", "target": 1, "func": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \"elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}", "func_hash": 252467620619020665053463064048093339685, "file_name": "save_restore_tensor.cc", "file_hash": 5161981891248921294380940461341356456, "cwe": ["CWE-476"], "cve": "CVE-2021-37639", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37639", "file_path": "tensorflow/core/kernels/save_restore_tensor.cc"}
{"idx": 259081, "project": "tensorflow", "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "commit_message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55", "target": 0, "func": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \" elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  {\n    const int64_t size = tensor_name_t.NumElements();\n    OP_REQUIRES(context, size > restore_index,\n                errors::InvalidArgument(\n                    \"Input 1 (file_pattern) must be a have at least \",\n                    restore_index + 1, \" elements\"));\n  }\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}", "func_hash": 180098336466556354723257120420152514513, "file_name": "save_restore_tensor.cc", "file_hash": 177675182218356821099377926276239457736, "cwe": ["CWE-476"], "cve": "CVE-2021-37639", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37639", "file_path": "tensorflow/core/kernels/save_restore_tensor.cc"}
{"idx": 197499, "project": "gpac", "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "commit_message": "fixed #2212", "target": 1, "func": "GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node, GF_FieldInfo *field, Bool is_mem_com)\n{\n\tGF_Err e;\n\tu32 NbBits, nbFields;\n\tu32 i;\n\tGF_ChildNodeItem *last;\n\tu8 qp_local, qp_on, initial_qp;\n\tGF_FieldInfo sffield;\n\n\tmemset(&sffield, 0, sizeof(GF_FieldInfo));\n\tsffield.fieldIndex = field->fieldIndex;\n\tsffield.fieldType = gf_sg_vrml_get_sf_type(field->fieldType);\n\tsffield.NDTtype = field->NDTtype;\n\tsffield.name = field->name;\n\n\tinitial_qp = qp_local = qp_on = 0;\n\n\t//vector description - alloc the MF size before\n\tNbBits = gf_bs_read_int(bs, 5);\n\tnbFields = gf_bs_read_int(bs, NbBits);\n\n\tif (codec->ActiveQP) {\n\t\tinitial_qp = 1;\n\t\t/*this is for QP 14*/\n\t\tgf_bifs_dec_qp14_set_length(codec, nbFields);\n\t}\n\n\tif (field->fieldType != GF_SG_VRML_MFNODE) {\n\t\te = gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields);\n\t\tif (e) return e;\n\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\te = gf_sg_vrml_mf_get_item(field->far_ptr, field->fieldType, & sffield.far_ptr, i);\n\t\t\tif (e) return e;\n\t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n\t\t\tif (e) return e;\n\t\t}\n\t} else {\n\t\tlast = NULL;\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n\t\t\tif (new_node) {\n\t\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n\t\t\t\tif (e) return e;\n\n\t\t\t\tif (node) {\n\t\t\t\t\t/*special case for QP, register as the current QP*/\n\t\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n\t\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n\t\t\t\t\t\t/*we have a QP in the same scope, remove previous\n\t\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n\t\t\t\t\t\twhether QP is cumulative or not*/\n\t\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n\n\t\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\tqp_on = 1;\n\t\t\t\t\t\tif (qp_local) qp_local = 2;\n\t\t\t\t\t\tif (codec->force_keep_qp) {\n\t\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tgf_node_register(new_node, NULL);\n\t\t\t\t\t\t\tgf_node_unregister(new_node, node);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\tif (e) return e;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*proto coding*/\n\t\t\t\telse if (codec->pCurrentProto) {\n\t\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n\t\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n\t\t\t\t\tif (e) return e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\t\t}\n\t\t/*according to the spec, the QP applies to the current node itself, not just children.\n\t\tIf IsLocal is TRUE remove the node*/\n\t\tif (qp_on && qp_local) {\n\t\t\tif (qp_local == 2) {\n//\t\t\t\tqp_local = 1;\n\t\t\t} else {\n\t\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n\t\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n//\t\t\t\tqp_local = 0;\n\t\t\t}\n\t\t}\n\t}\n\t/*finally delete the QP if any (local or not) as we get out of this node*/\n\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n\treturn GF_OK;\n}", "func_hash": 181633592491715085539951152559525218380, "file_name": "field_decode.c", "file_hash": 27053036293524314453415412309723108309, "cwe": ["CWE-416"], "cve": "CVE-2022-2453", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2453", "file_path": "src/bifs/field_decode.c"}
{"idx": 259515, "project": "gpac", "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "commit_message": "fixed #2212", "target": 0, "func": "GF_Err BD_DecMFFieldVec(GF_BifsDecoder * codec, GF_BitStream *bs, GF_Node *node, GF_FieldInfo *field, Bool is_mem_com)\n{\n\tGF_Err e;\n\tu32 NbBits, nbFields;\n\tu32 i;\n\tGF_ChildNodeItem *last;\n\tu8 qp_local, qp_on, initial_qp;\n\tGF_FieldInfo sffield;\n\n\tmemset(&sffield, 0, sizeof(GF_FieldInfo));\n\tsffield.fieldIndex = field->fieldIndex;\n\tsffield.fieldType = gf_sg_vrml_get_sf_type(field->fieldType);\n\tsffield.NDTtype = field->NDTtype;\n\tsffield.name = field->name;\n\n\tinitial_qp = qp_local = qp_on = 0;\n\n\t//vector description - alloc the MF size before\n\tNbBits = gf_bs_read_int(bs, 5);\n\tnbFields = gf_bs_read_int(bs, NbBits);\n\n\tif (codec->ActiveQP) {\n\t\tinitial_qp = 1;\n\t\t/*this is for QP 14*/\n\t\tgf_bifs_dec_qp14_set_length(codec, nbFields);\n\t}\n\n\tif (field->fieldType != GF_SG_VRML_MFNODE) {\n\t\te = gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields);\n\t\tif (e) return e;\n\n\t\tfor (i=0; i<nbFields; i++) {\n\t\t\te = gf_sg_vrml_mf_get_item(field->far_ptr, field->fieldType, & sffield.far_ptr, i);\n\t\t\tif (e) return e;\n\t\t\te = gf_bifs_dec_sf_field(codec, bs, node, &sffield, GF_FALSE);\n\t\t\tif (e) return e;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\te = GF_OK;\n\tlast = NULL;\n\tfor (i=0; i<nbFields; i++) {\n\t\tGF_Node *new_node = gf_bifs_dec_node(codec, bs, field->NDTtype);\n\t\tif (new_node) {\n\t\t\te = gf_node_register(new_node, is_mem_com ? NULL : node);\n\t\t\tif (e) goto exit;\n\n\t\t\tif (node) {\n\t\t\t\t/*special case for QP, register as the current QP*/\n\t\t\t\tif (gf_node_get_tag(new_node) == TAG_MPEG4_QuantizationParameter) {\n\t\t\t\t\tqp_local = ((M_QuantizationParameter *)new_node)->isLocal;\n\t\t\t\t\t/*we have a QP in the same scope, remove previous\n\t\t\t\t\tNB: we assume this is the right behavior, the spec doesn't say\n\t\t\t\t\twhether QP is cumulative or not*/\n\t\t\t\t\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_FALSE);\n\n\t\t\t\t\te = gf_bifs_dec_qp_set(codec, new_node);\n\t\t\t\t\tif (e) goto exit;\n\t\t\t\t\tqp_on = 1;\n\t\t\t\t\tif (qp_local) qp_local = 2;\n\t\t\t\t\tif (codec->force_keep_qp) {\n\t\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\t\tif (e) goto exit;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tgf_node_register(new_node, NULL);\n\t\t\t\t\t\tgf_node_unregister(new_node, node);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\te = gf_node_list_add_child_last(field->far_ptr, new_node, &last);\n\t\t\t\t\tif (e) goto exit;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*proto coding*/\n\t\t\telse if (codec->pCurrentProto) {\n\t\t\t\t/*TO DO: what happens if this is a QP node on the interface ?*/\n\t\t\t\te = gf_node_list_add_child_last( (GF_ChildNodeItem **)field->far_ptr, new_node, &last);\n\t\t\t\tif (e)goto exit;\n\t\t\t}\n\t\t} else {\n\t\t\te = codec->LastError ? codec->LastError : GF_NON_COMPLIANT_BITSTREAM;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\nexit:\n\n\t/*according to the spec, the QP applies to the current node itself, not just children.\n\tIf IsLocal is TRUE remove the node*/\n\tif (qp_on && qp_local) {\n\t\tif (qp_local == 2) {\n//\t\t\t\tqp_local = 1;\n\t\t} else {\n\t\t\t//ask to get rid of QP and reactivate if we had a QP when entering the node\n\t\t\tgf_bifs_dec_qp_remove(codec, initial_qp);\n//\t\t\t\tqp_local = 0;\n\t\t}\n\t}\n\n\t/*finally delete the QP if any (local or not) as we get out of this node*/\n\tif (qp_on) gf_bifs_dec_qp_remove(codec, GF_TRUE);\n\treturn e;\n}", "func_hash": 87913328330334973477048870942232615519, "file_name": "field_decode.c", "file_hash": 151388572550638562891846673305217274829, "cwe": ["CWE-416"], "cve": "CVE-2022-2453", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2453", "file_path": "src/bifs/field_decode.c"}
{"idx": 197511, "project": "libjpeg", "commit_id": "187035b9726710b4fe11d565c7808975c930895d", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d", "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.", "target": 1, "func": "void HierarchicalBitmapRequester::PrepareForDecoding(void)\n{\n#if ACCUSOFT_CODE\n\n  UBYTE i;\n\n  BuildCommon();\n\n  if (m_ppDecodingMCU == NULL) {\n    m_ppDecodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount*8);\n    memset(m_ppDecodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n\n  if (m_ppUpsampler == NULL) {\n    m_ppUpsampler = (class UpsamplerBase **)m_pEnviron->AllocMem(sizeof(class UpsamplerBase *) * m_ucCount);\n    memset(m_ppUpsampler,0,sizeof(class Upsampler *) * m_ucCount);\n\n    for(i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppUpsampler[i] = UpsamplerBase::CreateUpsampler(m_pEnviron,sx,sy,\n                                                          m_ulPixelWidth,m_ulPixelHeight,\n                                                          m_pFrame->TablesOf()->isChromaCentered());\n        m_bSubsampling   = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForDecoding();\n#endif\n}", "func_hash": 63468052144489012470048601021040613418, "file_name": "hierarchicalbitmaprequester.cpp", "file_hash": 34345221108539770458549868924228630502, "cwe": ["CWE-787"], "cve": "CVE-2022-31796", "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796", "file_path": "control/hierarchicalbitmaprequester.cpp"}
{"idx": 259619, "project": "libjpeg", "commit_id": "187035b9726710b4fe11d565c7808975c930895d", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d", "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.", "target": 0, "func": "void HierarchicalBitmapRequester::PrepareForEncoding(void)\n{\n#if ACCUSOFT_CODE\n  \n  BuildCommon();\n\n  if (m_ppEncodingMCU == NULL) {\n    m_ppEncodingMCU = (struct Line **)m_pEnviron->AllocMem(sizeof(struct Line *) * m_ucCount *8);\n    memset(m_ppEncodingMCU,0,sizeof(struct Line *) * m_ucCount * 8);\n  }\n  \n  if (m_ppDownsampler == NULL) {\n    m_ppDownsampler = (class DownsamplerBase **)m_pEnviron->AllocMem(sizeof(class DownsamplerBase *) * m_ucCount);\n    memset(m_ppDownsampler,0,sizeof(class DownsamplerBase *) * m_ucCount);\n    \n    for(UBYTE i = 0;i < m_ucCount;i++) {\n      class Component *comp = m_pFrame->ComponentOf(i);\n      UBYTE sx = comp->SubXOf();\n      UBYTE sy = comp->SubYOf();\n\n      if (sx > 1 || sy > 1) {\n        m_ppDownsampler[i] = DownsamplerBase::CreateDownsampler(m_pEnviron,sx,sy,\n                                                                m_ulPixelWidth,m_ulPixelHeight,\n                                                                m_pFrame->TablesOf()->\n                                                                isDownsamplingInterpolated());\n        m_bSubsampling     = true;\n      }\n    }\n  }\n\n  if (m_pLargestScale)\n    m_pLargestScale->PrepareForEncoding();\n#endif\n}", "func_hash": 163837755851062573337491873573690435408, "file_name": "hierarchicalbitmaprequester.cpp", "file_hash": 103246407112165898630439185486735063817, "cwe": ["CWE-787"], "cve": "CVE-2022-31796", "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31796", "file_path": "control/hierarchicalbitmaprequester.cpp"}
{"idx": 197518, "project": "tensorflow", "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58", "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }", "func_hash": 234673676615434385684756936171703208879, "file_name": "quantize_and_dequantize_op.cc", "file_hash": 339380707229520344979853528458088260159, "cwe": ["CWE-703"], "cve": "CVE-2022-29192", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192", "file_path": "tensorflow/core/kernels/quantize_and_dequantize_op.cc"}
{"idx": 259732, "project": "tensorflow", "commit_id": "098e7762d909bac47ce1dbabe6dfd06294cb9d58", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58", "commit_message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n    OP_REQUIRES(\n        ctx, axis_ >= -1,\n        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n                errors::InvalidArgument(\n                    \"Axis should be -1 or 0 or a positive value less than \",\n                    input.shape().dims(), \"but given axis value was \", axis_));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 0 or 1. Received \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 0 or 1. Received \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\n                  errors::InvalidArgument(\n                      \"input_min must be a scalar if axis is unspecified\"));\n      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\n                  errors::InvalidArgument(\n                      \"input_max must be a scalar if axis is unspecified\"));\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }", "func_hash": 287418587934128745776529470108188021327, "file_name": "quantize_and_dequantize_op.cc", "file_hash": 149077864405379849027595796830913818555, "cwe": ["CWE-703"], "cve": "CVE-2022-29192", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29192", "file_path": "tensorflow/core/kernels/quantize_and_dequantize_op.cc"}
{"idx": 197565, "project": "wolfMQTT", "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2", "project_url": "https://github.com/wolfSSL/wolfMQTT", "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2", "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free", "target": 1, "func": "static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n    byte wait_type, word16 wait_packet_id, int timeout_ms)\n{\n    int rc;\n    word16 packet_id;\n    MqttPacketType packet_type;\n#ifdef WOLFMQTT_MULTITHREAD\n    MqttPendResp *pendResp;\n    int readLocked;\n#endif\n    MqttMsgStat* mms_stat;\n    int waitMatchFound;\n\n    if (client == NULL || packet_obj == NULL) {\n        return MQTT_CODE_ERROR_BAD_ARG;\n    }\n\n    /* all packet type structures must have MqttMsgStat at top */\n    mms_stat = (MqttMsgStat*)packet_obj;\n\nwait_again:\n\n    /* initialize variables */\n    packet_id = 0;\n    packet_type = MQTT_PACKET_TYPE_RESERVED;\n#ifdef WOLFMQTT_MULTITHREAD\n    pendResp = NULL;\n    readLocked = 0;\n#endif\n    waitMatchFound = 0;\n\n#ifdef WOLFMQTT_DEBUG_CLIENT\n    PRINTF(\"MqttClient_WaitType: Type %s (%d), ID %d\",\n        MqttPacket_TypeDesc((MqttPacketType)wait_type),\n            wait_type, wait_packet_id);\n#endif\n\n    switch ((int)*mms_stat)\n    {\n        case MQTT_MSG_BEGIN:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Lock recv socket mutex */\n            rc = wm_SemLock(&client->lockRecv);\n            if (rc != 0) {\n                PRINTF(\"MqttClient_WaitType: recv lock error!\");\n                return rc;\n            }\n            readLocked = 1;\n        #endif\n\n            /* reset the packet state */\n            client->packet.stat = MQTT_PK_BEGIN;\n        }\n        FALL_THROUGH;\n\n    #ifdef WOLFMQTT_V5\n        case MQTT_MSG_AUTH:\n    #endif\n        case MQTT_MSG_WAIT:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if packet type and id have already completed */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, (MqttPacketType)wait_type, \n                    wait_packet_id, &pendResp)) {\n                    if (pendResp->packetDone) {\n                        /* pending response is already done, so return */\n                        rc = pendResp->packet_ret;\n                    #ifdef WOLFMQTT_DEBUG_CLIENT\n                        PRINTF(\"PendResp already Done %p: Rc %d\", pendResp, rc);\n                    #endif\n                        MqttClient_RespList_Remove(client, pendResp);\n                        wm_SemUnlock(&client->lockClient);\n                        wm_SemUnlock(&client->lockRecv);\n                        return rc;\n                    }\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            *mms_stat = MQTT_MSG_WAIT;\n\n            /* Wait for packet */\n            rc = MqttPacket_Read(client, client->rx_buf, client->rx_buf_len,\n                    timeout_ms);\n            /* handle failure */\n            if (rc <= 0) {\n                break;\n            }\n\n            /* capture length read */\n            client->packet.buf_len = rc;\n\n            /* Decode Packet - get type and id */\n            rc = MqttClient_DecodePacket(client, client->rx_buf,\n                client->packet.buf_len, NULL, &packet_type, NULL, &packet_id);\n            if (rc < 0) {\n                break;\n            }\n\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"Read Packet: Len %d, Type %d, ID %d\",\n                client->packet.buf_len, packet_type, packet_id);\n        #endif\n\n            *mms_stat = MQTT_MSG_READ;\n        }\n        FALL_THROUGH;\n\n        case MQTT_MSG_READ:\n        case MQTT_MSG_READ_PAYLOAD:\n        {\n            MqttPacketType use_packet_type;\n            void* use_packet_obj;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            readLocked = 1; /* if in this state read is locked */\n        #endif\n\n            /* read payload state only happens for publish messages */\n            if (*mms_stat == MQTT_MSG_READ_PAYLOAD) {\n                packet_type = MQTT_PACKET_TYPE_PUBLISH;\n            }\n\n            /* Determine if we received data for this request */\n            if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                 wait_type == packet_type ||\n                 MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n               (wait_packet_id == 0 || wait_packet_id == packet_id))\n            {\n                use_packet_obj = packet_obj;\n                waitMatchFound = 1;\n            }\n            else {\n                /* use generic packet object */\n                use_packet_obj = &client->msg;\n            }\n            use_packet_type = packet_type;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if we have a pending response for this packet */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, packet_type, packet_id,\n                                                               &pendResp)) {\n                    /* we found packet match this incoming read packet */\n                    pendResp->packetProcessing = 1;\n                    use_packet_obj = pendResp->packet_obj;\n                    use_packet_type = pendResp->packet_type;\n                    /* req from another thread... not a match */\n                    waitMatchFound = 0;\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            /* Perform packet handling for publish callback and QoS */\n            rc = MqttClient_HandlePacket(client, use_packet_type,\n                use_packet_obj, timeout_ms);\n\n        #ifdef WOLFMQTT_NONBLOCK\n            if (rc == MQTT_CODE_CONTINUE) {\n                /* we have received some data, so keep the recv\n                    mutex lock active and return */\n                return rc;\n            }\n        #endif\n\n            /* handle success case */\n            if (rc >= 0) {\n                rc = MQTT_CODE_SUCCESS;\n            }\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            if (pendResp) {\n                /* Mark pending response entry done */\n                if (wm_SemLock(&client->lockClient) == 0) {\n                    pendResp->packetDone = 1;\n                    pendResp->packet_ret = rc;\n                #ifdef WOLFMQTT_DEBUG_CLIENT\n                    PRINTF(\"PendResp Done %p\", pendResp);\n                #endif\n                    pendResp = NULL;\n                    wm_SemUnlock(&client->lockClient);\n                }\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n            break;\n        }\n\n        case MQTT_MSG_WRITE:\n        case MQTT_MSG_WRITE_PAYLOAD:\n        default:\n        {\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"MqttClient_WaitType: Invalid state %d!\", *mms_stat);\n        #endif\n            rc = MQTT_CODE_ERROR_STAT;\n            break;\n        }\n    } /* switch (*mms_stat) */\n\n#ifdef WOLFMQTT_NONBLOCK\n    if (rc != MQTT_CODE_CONTINUE)\n#endif\n    {\n        /* reset state */\n        *mms_stat = MQTT_MSG_BEGIN;\n    }\n\n#ifdef WOLFMQTT_MULTITHREAD\n    if (readLocked) {\n        wm_SemUnlock(&client->lockRecv);\n    }\n#endif\n    if (rc < 0) {\n    #ifdef WOLFMQTT_DEBUG_CLIENT\n        PRINTF(\"MqttClient_WaitType: Failure: %s (%d)\",\n            MqttClient_ReturnCodeToString(rc), rc);\n    #endif\n        return rc;\n    }\n\n    if (!waitMatchFound) {\n        /* if we get here, then the we are still waiting for a packet */\n        goto wait_again;\n    }\n\n    return rc;\n}", "func_hash": 2988390772969394657723865827973366134, "file_name": "mqtt_client.c", "file_hash": 187905589318508952285873561463064501412, "cwe": ["CWE-787"], "cve": "CVE-2021-45936", "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45936", "file_path": "src/mqtt_client.c"}
{"idx": 261220, "project": "wolfMQTT", "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2", "project_url": "https://github.com/wolfSSL/wolfMQTT", "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2", "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free", "target": 0, "func": "static int MqttClient_WaitType(MqttClient *client, void *packet_obj,\n    byte wait_type, word16 wait_packet_id, int timeout_ms)\n{\n    int rc;\n    word16 packet_id;\n    MqttPacketType packet_type;\n#ifdef WOLFMQTT_MULTITHREAD\n    MqttPendResp *pendResp;\n    int readLocked;\n#endif\n    MqttMsgStat* mms_stat;\n    int waitMatchFound;\n\n    if (client == NULL || packet_obj == NULL) {\n        return MQTT_CODE_ERROR_BAD_ARG;\n    }\n\n    /* all packet type structures must have MqttMsgStat at top */\n    mms_stat = (MqttMsgStat*)packet_obj;\n\nwait_again:\n\n    /* initialize variables */\n    packet_id = 0;\n    packet_type = MQTT_PACKET_TYPE_RESERVED;\n#ifdef WOLFMQTT_MULTITHREAD\n    pendResp = NULL;\n    readLocked = 0;\n#endif\n    waitMatchFound = 0;\n\n#ifdef WOLFMQTT_DEBUG_CLIENT\n    PRINTF(\"MqttClient_WaitType: Type %s (%d), ID %d\",\n        MqttPacket_TypeDesc((MqttPacketType)wait_type),\n            wait_type, wait_packet_id);\n#endif\n\n    switch ((int)*mms_stat)\n    {\n        case MQTT_MSG_BEGIN:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Lock recv socket mutex */\n            rc = wm_SemLock(&client->lockRecv);\n            if (rc != 0) {\n                PRINTF(\"MqttClient_WaitType: recv lock error!\");\n                return rc;\n            }\n            readLocked = 1;\n        #endif\n\n            /* reset the packet state */\n            client->packet.stat = MQTT_PK_BEGIN;\n        }\n        FALL_THROUGH;\n\n    #ifdef WOLFMQTT_V5\n        case MQTT_MSG_AUTH:\n    #endif\n        case MQTT_MSG_WAIT:\n        {\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if packet type and id have already completed */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, (MqttPacketType)wait_type, \n                    wait_packet_id, &pendResp)) {\n                    if (pendResp->packetDone) {\n                        /* pending response is already done, so return */\n                        rc = pendResp->packet_ret;\n                    #ifdef WOLFMQTT_DEBUG_CLIENT\n                        PRINTF(\"PendResp already Done %p: Rc %d\", pendResp, rc);\n                    #endif\n                        MqttClient_RespList_Remove(client, pendResp);\n                        wm_SemUnlock(&client->lockClient);\n                        wm_SemUnlock(&client->lockRecv);\n                        return rc;\n                    }\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            *mms_stat = MQTT_MSG_WAIT;\n\n            /* Wait for packet */\n            rc = MqttPacket_Read(client, client->rx_buf, client->rx_buf_len,\n                    timeout_ms);\n            /* handle failure */\n            if (rc <= 0) {\n                break;\n            }\n\n            /* capture length read */\n            client->packet.buf_len = rc;\n\n            /* Decode Packet - get type and id */\n            rc = MqttClient_DecodePacket(client, client->rx_buf,\n                client->packet.buf_len, NULL, &packet_type, NULL, &packet_id);\n            if (rc < 0) {\n                break;\n            }\n\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"Read Packet: Len %d, Type %d, ID %d\",\n                client->packet.buf_len, packet_type, packet_id);\n        #endif\n\n            *mms_stat = MQTT_MSG_READ;\n        }\n        FALL_THROUGH;\n\n        case MQTT_MSG_READ:\n        case MQTT_MSG_READ_PAYLOAD:\n        {\n            MqttPacketType use_packet_type;\n            void* use_packet_obj;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            readLocked = 1; /* if in this state read is locked */\n        #endif\n\n            /* read payload state only happens for publish messages */\n            if (*mms_stat == MQTT_MSG_READ_PAYLOAD) {\n                packet_type = MQTT_PACKET_TYPE_PUBLISH;\n            }\n\n            /* Determine if we received data for this request */\n            if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n                 wait_type == packet_type ||\n                 (MqttIsPubRespPacket(packet_type) &&\n                  MqttIsPubRespPacket(wait_type))) &&\n                (wait_packet_id == 0 || wait_packet_id == packet_id))\n            {\n                use_packet_obj = packet_obj;\n                waitMatchFound = 1;\n            }\n            else {\n                /* use generic packet object */\n                use_packet_obj = &client->msg;\n            }\n            use_packet_type = packet_type;\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            /* Check to see if we have a pending response for this packet */\n            pendResp = NULL;\n            rc = wm_SemLock(&client->lockClient);\n            if (rc == 0) {\n                if (MqttClient_RespList_Find(client, packet_type, packet_id,\n                                                               &pendResp)) {\n                    /* we found packet match this incoming read packet */\n                    pendResp->packetProcessing = 1;\n                    use_packet_obj = pendResp->packet_obj;\n                    use_packet_type = pendResp->packet_type;\n                    /* req from another thread... not a match */\n                    waitMatchFound = 0;\n                }\n                wm_SemUnlock(&client->lockClient);\n            }\n            else {\n                break; /* error */\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n\n            /* Perform packet handling for publish callback and QoS */\n            rc = MqttClient_HandlePacket(client, use_packet_type,\n                use_packet_obj, timeout_ms);\n\n        #ifdef WOLFMQTT_NONBLOCK\n            if (rc == MQTT_CODE_CONTINUE) {\n                /* we have received some data, so keep the recv\n                    mutex lock active and return */\n                return rc;\n            }\n        #endif\n\n            /* handle success case */\n            if (rc >= 0) {\n                rc = MQTT_CODE_SUCCESS;\n            }\n\n        #ifdef WOLFMQTT_MULTITHREAD\n            if (pendResp) {\n                /* Mark pending response entry done */\n                if (wm_SemLock(&client->lockClient) == 0) {\n                    pendResp->packetDone = 1;\n                    pendResp->packet_ret = rc;\n                #ifdef WOLFMQTT_DEBUG_CLIENT\n                    PRINTF(\"PendResp Done %p\", pendResp);\n                #endif\n                    pendResp = NULL;\n                    wm_SemUnlock(&client->lockClient);\n                }\n            }\n        #endif /* WOLFMQTT_MULTITHREAD */\n            break;\n        }\n\n        case MQTT_MSG_WRITE:\n        case MQTT_MSG_WRITE_PAYLOAD:\n        default:\n        {\n        #ifdef WOLFMQTT_DEBUG_CLIENT\n            PRINTF(\"MqttClient_WaitType: Invalid state %d!\", *mms_stat);\n        #endif\n            rc = MQTT_CODE_ERROR_STAT;\n            break;\n        }\n    } /* switch (*mms_stat) */\n\n#ifdef WOLFMQTT_NONBLOCK\n    if (rc != MQTT_CODE_CONTINUE)\n#endif\n    {\n        /* reset state */\n        *mms_stat = MQTT_MSG_BEGIN;\n    }\n\n#ifdef WOLFMQTT_MULTITHREAD\n    if (readLocked) {\n        wm_SemUnlock(&client->lockRecv);\n    }\n#endif\n    if (rc < 0) {\n    #ifdef WOLFMQTT_DEBUG_CLIENT\n        PRINTF(\"MqttClient_WaitType: Failure: %s (%d)\",\n            MqttClient_ReturnCodeToString(rc), rc);\n    #endif\n        return rc;\n    }\n\n    if (!waitMatchFound) {\n        /* if we get here, then the we are still waiting for a packet */\n        goto wait_again;\n    }\n\n    return rc;\n}", "func_hash": 88286430385104780024208637044722033295, "file_name": "mqtt_client.c", "file_hash": 315446679366477562127453021881917079842, "cwe": ["CWE-787"], "cve": "CVE-2021-45936", "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-45936", "file_path": "src/mqtt_client.c"}
{"idx": 197593, "project": "njs", "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53", "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.", "target": 1, "func": "njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n{\n    size_t              value_count, n;\n    njs_value_t         *start, *end, *p, **new, *value, **local;\n    njs_function_t      *function;\n    njs_native_frame_t  *active, *native;\n\n    *frame = *vm->active_frame;\n    frame->previous_active_frame = NULL;\n\n    native = &frame->native;\n\n    active = &vm->active_frame->native;\n    value_count = njs_function_frame_value_count(active);\n\n    function = active->function;\n\n    new = (njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE);\n    value = (njs_value_t *) (new + value_count\n                             + function->u.lambda->temp);\n\n\n    native->arguments = value;\n    native->arguments_offset = value + (function->args_offset - 1);\n    native->local = new + njs_function_frame_args_count(active);\n    native->temp = new + value_count;\n    native->pc = pc;\n\n    start = njs_function_frame_values(active, &end);\n    p = native->arguments;\n\n    while (start < end) {\n        *p = *start++;\n        *new++ = p++;\n    }\n\n    /* Move all arguments. */\n\n    p = native->arguments;\n    local = native->local + function->args_offset;\n\n    for (n = 0; n < function->args_count; n++) {\n        if (!njs_is_valid(p)) {\n            njs_set_undefined(p);\n        }\n\n        *local++ = p++;\n    }\n\n    return NJS_OK;\n}", "func_hash": 163196677430813133926152837345587363595, "file_name": "njs_function.c", "file_hash": 84952023387586829721392975850477495397, "cwe": ["CWE-416"], "cve": "CVE-2022-27007", "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27007", "file_path": "src/njs_function.c"}
{"idx": 261769, "project": "njs", "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53", "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.", "target": 0, "func": "njs_function_frame_save(njs_vm_t *vm, njs_frame_t *frame, u_char *pc)\n{\n    size_t              value_count, n;\n    njs_value_t         *start, *end, *p, **new, *value, **local;\n    njs_function_t      *function;\n    njs_native_frame_t  *active, *native;\n\n    *frame = *vm->active_frame;\n\n    frame->previous_active_frame = NULL;\n\n    native = &frame->native;\n    native->size = 0;\n    native->free = NULL;\n    native->free_size = 0;\n\n    active = &vm->active_frame->native;\n    value_count = njs_function_frame_value_count(active);\n\n    function = active->function;\n\n    new = (njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE);\n    value = (njs_value_t *) (new + value_count\n                             + function->u.lambda->temp);\n\n\n    native->arguments = value;\n    native->arguments_offset = value + (function->args_offset - 1);\n    native->local = new + njs_function_frame_args_count(active);\n    native->temp = new + value_count;\n    native->pc = pc;\n\n    start = njs_function_frame_values(active, &end);\n    p = native->arguments;\n\n    while (start < end) {\n        *p = *start++;\n        *new++ = p++;\n    }\n\n    /* Move all arguments. */\n\n    p = native->arguments;\n    local = native->local + function->args_offset;\n\n    for (n = 0; n < function->args_count; n++) {\n        if (!njs_is_valid(p)) {\n            njs_set_undefined(p);\n        }\n\n        *local++ = p++;\n    }\n\n    return NJS_OK;\n}", "func_hash": 189837450352856196976094747096042569901, "file_name": "njs_function.c", "file_hash": 202672725562392231743366783746381682256, "cwe": ["CWE-416"], "cve": "CVE-2022-27007", "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-27007", "file_path": "src/njs_function.c"}
{"idx": 197666, "project": "njs", "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/eafe4c7a326b163612f10861392622b5da5b1792", "commit_message": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.", "target": 1, "func": "njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n    njs_iterator_handler_t handler)\n{\n    double              idx;\n    int64_t             i, from, to, length;\n    njs_int_t           ret;\n    njs_array_t         *array, *keys;\n    njs_value_t         *entry, *value, prop, character, string_obj;\n    const u_char        *p, *end, *pos;\n    njs_string_prop_t   string_prop;\n    njs_object_value_t  *object;\n\n    value = args->value;\n    from = args->from;\n    to = args->to;\n\n    if (njs_is_array(value)) {\n        array = njs_array(value);\n\n        from += 1;\n\n        while (from-- > to) {\n            if (njs_slow_path(!array->object.fast_array)) {\n                goto process_object;\n            }\n\n            if (njs_fast_path(from < array->length\n                              && njs_is_valid(&array->start[from])))\n            {\n                ret = handler(vm, args, &array->start[from], from);\n\n            } else {\n                entry = njs_value_arg(&njs_value_invalid);\n                ret = njs_value_property_i64(vm, value, from, &prop);\n                if (njs_slow_path(ret != NJS_DECLINED)) {\n                    if (ret == NJS_ERROR) {\n                        return NJS_ERROR;\n                    }\n\n                    entry = &prop;\n                }\n\n                ret = handler(vm, args, entry, from);\n            }\n\n            if (njs_slow_path(ret != NJS_OK)) {\n                if (ret == NJS_DONE) {\n                    return NJS_DONE;\n                }\n\n                return NJS_ERROR;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (njs_is_string(value) || njs_is_object_string(value)) {\n\n        if (njs_is_string(value)) {\n            object = njs_object_value_alloc(vm, NJS_OBJ_TYPE_STRING, 0, value);\n            if (njs_slow_path(object == NULL)) {\n                return NJS_ERROR;\n            }\n\n            njs_set_object_value(&string_obj, object);\n\n            args->value = &string_obj;\n        }\n        else {\n            value = njs_object_value(value);\n        }\n\n        length = njs_string_prop(&string_prop, value);\n        end = string_prop.start + string_prop.size;\n\n        if ((size_t) length == string_prop.size) {\n            /* Byte or ASCII string. */\n\n            p = string_prop.start + from;\n\n            i = from + 1;\n\n            while (i-- > to) {\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, p, 1, 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p--;\n            }\n\n        } else {\n            /* UTF-8 string. */\n\n            p = njs_string_offset(string_prop.start, end, from);\n            p = njs_utf8_next(p, end);\n\n            i = from + 1;\n\n            while (i-- > to) {\n                pos = njs_utf8_prev(p);\n\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, pos, p - pos , 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p = pos;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (!njs_is_object(value)) {\n        return NJS_OK;\n    }\n\nprocess_object:\n\n    if (!njs_fast_object(from - to)) {\n        keys = njs_array_indices(vm, value);\n        if (njs_slow_path(keys == NULL)) {\n            return NJS_ERROR;\n        }\n\n        i = keys->length;\n\n        while (i > 0) {\n            idx = njs_string_to_index(&keys->start[--i]);\n\n            if (idx < to || idx > from) {\n                continue;\n            }\n\n            ret = njs_iterator_object_handler(vm, handler, args,\n                                              &keys->start[i], idx);\n            if (njs_slow_path(ret != NJS_OK)) {\n                njs_array_destroy(vm, keys);\n                return ret;\n            }\n        }\n\n        njs_array_destroy(vm, keys);\n\n        return NJS_OK;\n    }\n\n    i = from + 1;\n\n    while (i-- > to) {\n        ret = njs_iterator_object_handler(vm, handler, args, NULL, i);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    return NJS_OK;\n}", "func_hash": 204015889704330628062672866949061415790, "file_name": "njs_iterator.c", "file_hash": 335799250908607269245401986160656951958, "cwe": ["CWE-703"], "cve": "CVE-2022-31307", "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31307", "file_path": "src/njs_iterator.c"}
{"idx": 262721, "project": "njs", "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/eafe4c7a326b163612f10861392622b5da5b1792", "commit_message": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.", "target": 0, "func": "njs_object_iterate_reverse(njs_vm_t *vm, njs_iterator_args_t *args,\n    njs_iterator_handler_t handler)\n{\n    double              idx;\n    int64_t             i, from, to, length;\n    njs_int_t           ret;\n    njs_array_t         *array, *keys;\n    njs_value_t         *entry, *value, prop, character, string_obj;\n    const u_char        *p, *end, *pos;\n    njs_string_prop_t   string_prop;\n    njs_object_value_t  *object;\n\n    value = args->value;\n    from = args->from;\n    to = args->to;\n\n    if (njs_is_array(value)) {\n        array = njs_array(value);\n\n        from += 1;\n\n        while (from-- > to) {\n            if (njs_slow_path(!array->object.fast_array)) {\n                goto process_object;\n            }\n\n            if (njs_fast_path(from < array->length\n                              && njs_is_valid(&array->start[from])))\n            {\n                ret = handler(vm, args, &array->start[from], from);\n\n            } else {\n                entry = njs_value_arg(&njs_value_invalid);\n                ret = njs_value_property_i64(vm, value, from, &prop);\n                if (njs_slow_path(ret != NJS_DECLINED)) {\n                    if (ret == NJS_ERROR) {\n                        return NJS_ERROR;\n                    }\n\n                    entry = &prop;\n                }\n\n                ret = handler(vm, args, entry, from);\n            }\n\n            if (njs_slow_path(ret != NJS_OK)) {\n                if (ret == NJS_DONE) {\n                    return NJS_DONE;\n                }\n\n                return NJS_ERROR;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (njs_is_string(value) || njs_is_object_string(value)) {\n\n        if (njs_is_string(value)) {\n            object = njs_object_value_alloc(vm, NJS_OBJ_TYPE_STRING, 0, value);\n            if (njs_slow_path(object == NULL)) {\n                return NJS_ERROR;\n            }\n\n            njs_set_object_value(&string_obj, object);\n\n            args->value = &string_obj;\n        }\n        else {\n            value = njs_object_value(value);\n        }\n\n        length = njs_string_prop(&string_prop, value);\n        end = string_prop.start + string_prop.size;\n\n        if ((size_t) length == string_prop.size) {\n            /* Byte or ASCII string. */\n\n            p = string_prop.start + from;\n\n            i = from + 1;\n\n            while (i-- > to) {\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, p, 1, 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p--;\n            }\n\n        } else {\n            /* UTF-8 string. */\n\n            p = NULL;\n            i = from + 1;\n\n            if (i > to) {\n                p = njs_string_offset(string_prop.start, end, from);\n                p = njs_utf8_next(p, end);\n            }\n\n            while (i-- > to) {\n                pos = njs_utf8_prev(p);\n\n                /* This cannot fail. */\n                (void) njs_string_new(vm, &character, pos, p - pos , 1);\n\n                ret = handler(vm, args, &character, i);\n                if (njs_slow_path(ret != NJS_OK)) {\n                    if (ret == NJS_DONE) {\n                        return NJS_DONE;\n                    }\n\n                    return NJS_ERROR;\n                }\n\n                p = pos;\n            }\n        }\n\n        return NJS_OK;\n    }\n\n    if (!njs_is_object(value)) {\n        return NJS_OK;\n    }\n\nprocess_object:\n\n    if (!njs_fast_object(from - to)) {\n        keys = njs_array_indices(vm, value);\n        if (njs_slow_path(keys == NULL)) {\n            return NJS_ERROR;\n        }\n\n        i = keys->length;\n\n        while (i > 0) {\n            idx = njs_string_to_index(&keys->start[--i]);\n\n            if (idx < to || idx > from) {\n                continue;\n            }\n\n            ret = njs_iterator_object_handler(vm, handler, args,\n                                              &keys->start[i], idx);\n            if (njs_slow_path(ret != NJS_OK)) {\n                njs_array_destroy(vm, keys);\n                return ret;\n            }\n        }\n\n        njs_array_destroy(vm, keys);\n\n        return NJS_OK;\n    }\n\n    i = from + 1;\n\n    while (i-- > to) {\n        ret = njs_iterator_object_handler(vm, handler, args, NULL, i);\n        if (njs_slow_path(ret != NJS_OK)) {\n            return ret;\n        }\n    }\n\n    return NJS_OK;\n}", "func_hash": 126929931891431012577582567397865564778, "file_name": "njs_iterator.c", "file_hash": 301055713494261994912699784498872698249, "cwe": ["CWE-703"], "cve": "CVE-2022-31307", "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-31307", "file_path": "src/njs_iterator.c"}
{"idx": 197719, "project": "tensorflow", "commit_id": "be7a4de6adfbd303ce08be4332554dff70362612", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612", "commit_message": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3", "target": 1, "func": "  void Compute(OpKernelContext* context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n                                                &ragged_nested_splits_in));\n    const int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),\n                                                       &encoded_scalar));\n      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n      return;\n    }\n\n    // Unbatch the Ragged Tensor and encode the components.\n    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n    OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n                                batched_ragged_input, &unbatched_ragged_input));\n\n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n                                            &encoded_vector));\n    auto encoded_vector_t = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++) {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }", "func_hash": 87089111367695740407726211981017748791, "file_name": "ragged_tensor_to_variant_op.cc", "file_hash": 103790733078302023163492154550355279185, "cwe": ["CWE-125"], "cve": "CVE-2021-37666", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty. We have patched the issue in GitHub commit be7a4de6adfbd303ce08be4332554dff70362612. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37666", "file_path": "tensorflow/core/kernels/ragged_tensor_to_variant_op.cc"}
{"idx": 262803, "project": "tensorflow", "commit_id": "be7a4de6adfbd303ce08be4332554dff70362612", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612", "commit_message": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3", "target": 0, "func": "  void Compute(OpKernelContext* context) override {\n    // Read ragged_splits inputs.\n    OpInputList ragged_nested_splits_in;\n    OP_REQUIRES_OK(context, context->input_list(\"rt_nested_splits\",\n                                                &ragged_nested_splits_in));\n    const int ragged_nested_splits_len = ragged_nested_splits_in.size();\n    RaggedTensorVariant batched_ragged_input;\n    // Read ragged_values input.\n    batched_ragged_input.set_values(context->input(ragged_nested_splits_len));\n    batched_ragged_input.mutable_nested_splits()->reserve(\n        ragged_nested_splits_len);\n    for (int i = 0; i < ragged_nested_splits_len; i++) {\n      batched_ragged_input.append_splits(ragged_nested_splits_in[i]);\n    }\n\n    if (!batched_input_) {\n      // Encode as a Scalar Variant Tensor.\n      Tensor* encoded_scalar;\n      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({}),\n                                                       &encoded_scalar));\n      encoded_scalar->scalar<Variant>()() = std::move(batched_ragged_input);\n      return;\n    }\n\n    // Checked here instead of at input in case batched_input_ is false\n    OP_REQUIRES(context, ragged_nested_splits_len > 0,\n                errors::InvalidArgument(\n                    \"rt_nested_splits must be a list of one or more, but \"\n                    \"received rt_nested_splits of length 0.\"));\n\n    // Unbatch the Ragged Tensor and encode the components.\n    std::vector<RaggedTensorVariant> unbatched_ragged_input;\n    auto batched_splits_top_vec =\n        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n    int num_components = batched_splits_top_vec.size() - 1;\n    OP_REQUIRES(context, num_components >= 0,\n                errors::Internal(\"Invalid split argument.\"));\n    OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n                                batched_ragged_input, &unbatched_ragged_input));\n\n    // Bundle the encoded scalar Variant Tensors into a rank-1 Variant Tensor.\n    Tensor* encoded_vector;\n    int output_size = unbatched_ragged_input.size();\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({output_size}),\n                                            &encoded_vector));\n    auto encoded_vector_t = encoded_vector->vec<Variant>();\n    for (int i = 0; i < output_size; i++) {\n      encoded_vector_t(i) = unbatched_ragged_input[i];\n    }\n  }", "func_hash": 237493287424700681504663667406249273606, "file_name": "ragged_tensor_to_variant_op.cc", "file_hash": 123140748084438584715535064056963359547, "cwe": ["CWE-125"], "cve": "CVE-2021-37666", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty. We have patched the issue in GitHub commit be7a4de6adfbd303ce08be4332554dff70362612. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37666", "file_path": "tensorflow/core/kernels/ragged_tensor_to_variant_op.cc"}
{"idx": 197748, "project": "tensorflow", "commit_id": "c79ba87153ee343401dbe9d1954d7f79e521eb14", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ba87153ee343401dbe9d1954d7f79e521eb14", "commit_message": "Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610", "target": 1, "func": "Status TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}", "func_hash": 264434210200699405161022303469799474263, "file_name": "array_ops.cc", "file_hash": 212731692545100279573003636737252061446, "cwe": ["CWE-703"], "cve": "CVE-2021-41216", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference function for `Transpose` is vulnerable to a heap buffer overflow. This occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41216", "file_path": "tensorflow/core/ops/array_ops.cc"}
{"idx": 263382, "project": "tensorflow", "commit_id": "c79ba87153ee343401dbe9d1954d7f79e521eb14", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ba87153ee343401dbe9d1954d7f79e521eb14", "commit_message": "Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610", "target": 0, "func": "Status TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank || in_idx <= -rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}", "func_hash": 29167107704393377568596638979461909163, "file_name": "array_ops.cc", "file_hash": 283394420828634459233696628321427916283, "cwe": ["CWE-703"], "cve": "CVE-2021-41216", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference function for `Transpose` is vulnerable to a heap buffer overflow. This occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41216", "file_path": "tensorflow/core/ops/array_ops.cc"}
