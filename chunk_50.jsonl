{"idx": 198282, "project": "tensorflow", "commit_id": "4923de56ec94fff7770df259ab7f2288a74feb41", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41", "commit_message": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a", "target": 1, "func": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}", "func_hash": 228488147174937246000179946900319201208, "file_name": "reshape_util.cc", "file_hash": 224364433068010361888882257047924749715, "cwe": ["CWE-369"], "cve": "CVE-2021-37640", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37640", "file_path": "tensorflow/core/kernels/reshape_util.cc"}
{"idx": 271526, "project": "tensorflow", "commit_id": "4923de56ec94fff7770df259ab7f2288a74feb41", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41", "commit_message": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a", "target": 0, "func": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES(\n        context, dense_size > 0 && product > 0,\n        errors::InvalidArgument(\n            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n            input_shape.DebugString(), \") or output shape (\",\n            output_shape.DebugString(), \") is empty\"));\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}", "func_hash": 110342704301029445327548172085240958100, "file_name": "reshape_util.cc", "file_hash": 175969764047663062260521886402354193689, "cwe": ["CWE-369"], "cve": "CVE-2021-37640", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37640", "file_path": "tensorflow/core/kernels/reshape_util.cc"}
{"idx": 198350, "project": "owntone-server", "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "project_url": "https://github.com/owntone/owntone-server", "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug", "target": 1, "func": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get the port that was assigned\n  ret = getsockname(fd, ptr->ai_addr, &ptr->ai_addrlen);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not find address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n\n  net_port_get(port, (union net_sockaddr *)ptr->ai_addr);\n  net_address_get(addr, sizeof(addr), (union net_sockaddr *)ptr->ai_addr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}", "func_hash": 32546260713202661418218833633405896143, "file_name": "misc.c", "file_hash": 105075321496416144885475599863207164581, "cwe": ["CWE-416"], "cve": "CVE-2021-38383", "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383", "file_path": "src/misc.c"}
{"idx": 273091, "project": "owntone-server", "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "project_url": "https://github.com/owntone/owntone-server", "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug", "target": 0, "func": "net_bind(short unsigned *port, int type, const char *log_service_name)\n{\n  struct addrinfo hints = { 0 };\n  struct addrinfo *servinfo;\n  struct addrinfo *ptr;\n  union net_sockaddr naddr = { 0 };\n  socklen_t naddr_len = sizeof(naddr);\n  const char *cfgaddr;\n  char addr[INET6_ADDRSTRLEN];\n  char strport[8];\n  int yes = 1;\n  int no = 0;\n  int fd;\n  int ret;\n\n  cfgaddr = cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\");\n\n  hints.ai_socktype = (type & (SOCK_STREAM | SOCK_DGRAM)); // filter since type can be SOCK_STREAM | SOCK_NONBLOCK\n  hints.ai_family = (cfg_getbool(cfg_getsec(cfg, \"general\"), \"ipv6\")) ? AF_INET6 : AF_INET;\n  hints.ai_flags = cfgaddr ? 0 : AI_PASSIVE;\n\n  snprintf(strport, sizeof(strport), \"%hu\", *port);\n  ret = getaddrinfo(cfgaddr, strport, &hints, &servinfo);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Failure creating '%s' service, could not resolve '%s' (port %s): %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", strport, gai_strerror(ret));\n      return -1;\n    }\n\n  for (ptr = servinfo, fd = -1; ptr != NULL; ptr = ptr->ai_next)\n    {\n      if (fd >= 0)\n\tclose(fd);\n\n      fd = socket(ptr->ai_family, type | SOCK_CLOEXEC, ptr->ai_protocol);\n      if (fd < 0)\n\tcontinue;\n\n      // TODO libevent sets this, we do the same?\n      ret = setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      ret = setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));\n      if (ret < 0)\n\tcontinue;\n\n      if (ptr->ai_family == AF_INET6)\n\t{\n\t  // We want to be sure the service is dual stack\n\t  ret = setsockopt(fd, IPPROTO_IPV6, IPV6_V6ONLY, &no, sizeof(no));\n\t  if (ret < 0)\n\t    continue;\n\t}\n\n      ret = bind(fd, ptr->ai_addr, ptr->ai_addrlen);\n      if (ret < 0)\n\tcontinue;\n\n      break;\n    }\n\n  freeaddrinfo(servinfo);\n\n  if (!ptr)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Could not create service '%s' with address %s, port %hu: %s\\n\", log_service_name, cfgaddr ? cfgaddr : \"(ANY)\", *port, strerror(errno));\n      goto error;\n    }\n\n  // Get our address (as string) and the port that was assigned (necessary when\n  // caller didn't specify a port)\n  ret = getsockname(fd, &naddr.sa, &naddr_len);\n  if (ret < 0)\n    {\n      DPRINTF(E_LOG, L_MISC, \"Error finding address of service '%s': %s\\n\", log_service_name, strerror(errno));\n      goto error;\n    }\n  else if (naddr_len > sizeof(naddr))\n    {\n      DPRINTF(E_LOG, L_MISC, \"Unexpected address length of service '%s'\\n\", log_service_name);\n      goto error;\n    }\n\n  net_port_get(port, &naddr);\n  net_address_get(addr, sizeof(addr), &naddr);\n\n  DPRINTF(E_DBG, L_MISC, \"Service '%s' bound to %s, port %hu, socket %d\\n\", log_service_name, addr, *port, fd);\n\n  return fd;\n\n error:\n  close(fd);\n  return -1;\n}", "func_hash": 222091533748174549495589798239680166393, "file_name": "misc.c", "file_hash": 109030313181388769357445523159421396120, "cwe": ["CWE-416"], "cve": "CVE-2021-38383", "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-38383", "file_path": "src/misc.c"}
{"idx": 198374, "project": "tensorflow", "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a", "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor* x_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"x\", &x_tensor));\n\n    const Tensor* cs_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"cs_prev\", &cs_prev_tensor));\n\n    const Tensor* h_prev_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"h_prev\", &h_prev_tensor));\n\n    const Tensor* w_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"w\", &w_tensor));\n\n    const Tensor* wci_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wci\", &wci_tensor));\n\n    const Tensor* wcf_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wcf\", &wcf_tensor));\n\n    const Tensor* wco_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"wco\", &wco_tensor));\n\n    const Tensor* b_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->input(\"b\", &b_tensor));\n\n    const int64_t batch_size = x_tensor->dim_size(0);\n    const int64_t input_size = x_tensor->dim_size(1);\n    const int64_t cell_size = cs_prev_tensor->dim_size(1);\n\n    // Sanity checks for our input shapes.\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"cs_prev.dims(0) != batch_size: \",\n                                        cs_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, cs_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\"cs_prev.dims(1) != cell_size: \",\n                                        cs_prev_tensor->dim_size(1), \" vs. \",\n                                        cell_size));\n\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,\n                errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",\n                                        h_prev_tensor->dim_size(0), \" vs. \",\n                                        batch_size));\n    OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,\n                errors::InvalidArgument(\n                    \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),\n                    \" vs. \", cell_size));\n\n    OP_REQUIRES(ctx, w_tensor->dim_size(0) == input_size + cell_size,\n                errors::InvalidArgument(\n                    \"w.dim_size(0) != input_size + cell_size: \",\n                    w_tensor->dim_size(0), \" vs. \", input_size + cell_size));\n    OP_REQUIRES(ctx, w_tensor->dim_size(1) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"w.dim_size(1) != cell_size * 4: \", w_tensor->dim_size(1),\n                    \" vs. \", cell_size * 4));\n\n    OP_REQUIRES(ctx, b_tensor->dim_size(0) == cell_size * 4,\n                errors::InvalidArgument(\n                    \"b.dim_size(0) != cell_size * 4: \", b_tensor->dim_size(0),\n                    \" vs. \", cell_size * 4));\n\n    // Allocate our output tensors.\n    Tensor* i_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"h_prev\"}, \"i\",\n                            TensorShape({batch_size, cell_size}), &i_tensor));\n\n    Tensor* cs_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"cs\", TensorShape({batch_size, cell_size}),\n                                  &cs_tensor));\n\n    Tensor* f_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"f\", TensorShape({batch_size, cell_size}),\n                                  &f_tensor));\n\n    Tensor* o_tensor = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                            {\"cs_prev\"}, \"o\",\n                            TensorShape({batch_size, cell_size}), &o_tensor));\n\n    Tensor* ci_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"ci\", TensorShape({batch_size, cell_size}),\n                                  &ci_tensor));\n\n    Tensor* co_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"co\", TensorShape({batch_size, cell_size}),\n                                  &co_tensor));\n\n    Tensor* h_tensor = nullptr;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(\"h\", TensorShape({batch_size, cell_size}),\n                                  &h_tensor));\n\n    // Allocate our temp tensors.\n    Tensor xh_tensor;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(\n                            DataTypeToEnum<T>::v(),\n                            TensorShape({batch_size, input_size + cell_size}),\n                            &xh_tensor));\n\n    Tensor gates_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<T>::v(),\n                                      TensorShape({batch_size, cell_size * 4}),\n                                      &gates_tensor));\n\n    const Device& device = ctx->eigen_device<Device>();\n\n    functor::LSTMBlockCellFprop<Device, T, USE_CUBLAS, gate_layout>(\n        batch_size, input_size, cell_size)(\n        ctx, device, forget_bias_, cell_clip_, use_peephole_,\n        x_tensor->matrix<T>(), cs_prev_tensor->matrix<T>(),\n        h_prev_tensor->matrix<T>(), w_tensor->matrix<T>(), wci_tensor->vec<T>(),\n        wcf_tensor->vec<T>(), wco_tensor->vec<T>(), b_tensor->vec<T>(),\n        xh_tensor.matrix<T>(), i_tensor->matrix<T>(), cs_tensor->matrix<T>(),\n        f_tensor->matrix<T>(), o_tensor->matrix<T>(), ci_tensor->matrix<T>(),\n        co_tensor->matrix<T>(), gates_tensor.matrix<T>(),\n        h_tensor->matrix<T>());\n  }", "func_hash": 332787893197526379241591780916041422587, "file_name": "lstm_ops.cc", "file_hash": 94555141575162353468670590418949369497, "cwe": ["CWE-703"], "cve": "CVE-2022-29200", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-29200", "file_path": "tensorflow/core/kernels/rnn/lstm_ops.cc"}
