{"idx": 195720, "project": "mvfst", "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0", "project_url": "https://github.com/facebookincubator/mvfst", "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0", "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945", "target": 1, "func": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    CHECK(!conn.oneRttWriteCipher.get());\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}", "func_hash": 43735419078414129480912957086830640484, "file_name": "ServerStateMachine.cpp", "file_hash": 9223824505720776904271246874049398430, "cwe": ["CWE-703"], "cve": "CVE-2021-24029", "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24029", "file_path": "quic/server/state/ServerStateMachine.cpp"}
{"idx": 231710, "project": "mvfst", "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0", "project_url": "https://github.com/facebookincubator/mvfst", "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0", "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945", "target": 0, "func": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    if (conn.oneRttWriteCipher) {\n      throw QuicTransportException(\n          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);\n    }\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}", "func_hash": 131573153342571823274301341051505058759, "file_name": "ServerStateMachine.cpp", "file_hash": 204614198627642259228820961859917931421, "cwe": ["CWE-703"], "cve": "CVE-2021-24029", "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-24029", "file_path": "quic/server/state/ServerStateMachine.cpp"}
{"idx": 195752, "project": "tensorflow", "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/02cc160e29d20631de3859c6653184e3f876b9d7", "commit_message": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "target": 1, "func": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }", "func_hash": 111818826187244494245403789873500831419, "file_name": "sparse_tensor_slice_dataset_op.cc", "file_hash": 152047584060469134260687844063366554733, "cwe": ["CWE-476"], "cve": "CVE-2021-37647", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37647", "file_path": "tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc"}
{"idx": 232405, "project": "tensorflow", "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/02cc160e29d20631de3859c6653184e3f876b9d7", "commit_message": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "target": 0, "func": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n\n    const auto num_indices = indices->NumElements();\n    const auto num_values = values->NumElements();\n    if (num_indices == 0 || num_values == 0) {\n      OP_REQUIRES(ctx, num_indices == num_values,\n                  errors::InvalidArgument(\n                      \"If indices or values are empty, the other one must also \"\n                      \"be. Got indices of shape \",\n                      indices->shape().DebugString(), \" and values of shape \",\n                      values->shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }", "func_hash": 126239557450594194918340916106898261954, "file_name": "sparse_tensor_slice_dataset_op.cc", "file_hash": 188414793374606504588915566744198162485, "cwe": ["CWE-476"], "cve": "CVE-2021-37647", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37647", "file_path": "tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc"}
