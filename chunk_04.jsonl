{"idx": 195389, "project": "tensorflow", "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356", "target": 1, "func": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    DCHECK(a1_set.find(def.name()) == a1_set.end())\n        << \"AttrDef names must be unique, but '\" << def.name()\n        << \"' appears more than once\";\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}", "func_hash": 228350956694349821922378909162368693155, "file_name": "op_def_util.cc", "file_hash": 43202597261631718571985626227626810269, "cwe": ["CWE-617"], "cve": "CVE-2022-23565", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23565", "file_path": "tensorflow/core/framework/op_def_util.cc"}
{"idx": 225086, "project": "tensorflow", "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356", "target": 0, "func": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    if (a1_set.find(def.name()) != a1_set.end()) {\n      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()\n                 << \"' appears more than once\";\n    }\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}", "func_hash": 7221108948147885063916901261116103162, "file_name": "op_def_util.cc", "file_hash": 99670691263177784698689977477403265008, "cwe": ["CWE-617"], "cve": "CVE-2022-23565", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23565", "file_path": "tensorflow/core/framework/op_def_util.cc"}
{"idx": 195391, "project": "tensorflow", "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "commit_message": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "target": 1, "func": "  void Compute(tensorflow::OpKernelContext* context) override {\n    for (int ngram_width : ngram_widths_) {\n      OP_REQUIRES(\n          context, ngram_width > 0,\n          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n    }\n\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    if (splits_vec_size > 0) {\n      int prev_split = splits_vec(0);\n      OP_REQUIRES(context, prev_split == 0,\n                  errors::InvalidArgument(\"First split value must be 0, got \",\n                                          prev_split));\n      for (int i = 1; i < splits_vec_size; ++i) {\n        bool valid_splits = splits_vec(i) >= prev_split;\n        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n        OP_REQUIRES(context, valid_splits,\n                    errors::InvalidArgument(\n                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n                        prev_split, \", \", input_data_size, \"]\"));\n        prev_split = splits_vec(i);\n      }\n      OP_REQUIRES(context, prev_split == input_data_size,\n                  errors::InvalidArgument(\n                      \"Last split value must be data size. Expected \",\n                      input_data_size, \", got \", prev_split));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }", "func_hash": 93012019628610956612764593105283326156, "file_name": "string_ngrams_op.cc", "file_hash": 245905885483763938680185872776744444218, "cwe": ["CWE-190"], "cve": "CVE-2022-21733", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21733", "file_path": "tensorflow/core/kernels/string_ngrams_op.cc"}
{"idx": 225125, "project": "tensorflow", "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "commit_message": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "target": 0, "func": "  void Compute(tensorflow::OpKernelContext* context) override {\n    for (int ngram_width : ngram_widths_) {\n      OP_REQUIRES(\n          context, ngram_width > 0,\n          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\n    }\n\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    if (splits_vec_size > 0) {\n      int prev_split = splits_vec(0);\n      OP_REQUIRES(context, prev_split == 0,\n                  errors::InvalidArgument(\"First split value must be 0, got \",\n                                          prev_split));\n      for (int i = 1; i < splits_vec_size; ++i) {\n        bool valid_splits = splits_vec(i) >= prev_split;\n        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n        OP_REQUIRES(context, valid_splits,\n                    errors::InvalidArgument(\n                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n                        prev_split, \", \", input_data_size, \"]\"));\n        prev_split = splits_vec(i);\n      }\n      OP_REQUIRES(context, prev_split == input_data_size,\n                  errors::InvalidArgument(\n                      \"Last split value must be data size. Expected \",\n                      input_data_size, \", got \", prev_split));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n\n        // If reached here, pad_width should be > 0, pad_width_ = -1,\n        // which indicates max(ngram_widths) - 1 cannot be used here since\n        // ngram_width is not known.\n        OP_REQUIRES(\n            context, pad_width_ >= 0,\n            errors::InvalidArgument(\"Pad width should be >= 0 when \"\n                                    \"preserve_short_sequences is True and \"\n                                    \"ngram_widths are not provided, got \",\n                                    pad_width_));\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }", "func_hash": 39926051817459528222102206002528990438, "file_name": "string_ngrams_op.cc", "file_hash": 275635386609741564508341080525906256433, "cwe": ["CWE-190"], "cve": "CVE-2022-21733", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21733", "file_path": "tensorflow/core/kernels/string_ngrams_op.cc"}
{"idx": 195398, "project": "v4l2loopback", "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd", "project_url": "https://github.com/umlaeute/v4l2loopback", "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd", "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134", "target": 1, "func": "static int vidioc_querycap(struct file *file, void *priv,\n\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct v4l2_loopback_device *dev = v4l2loopback_getdevice(file);\n\tint labellen = (sizeof(cap->card) < sizeof(dev->card_label)) ?\n\t\t\t       sizeof(cap->card) :\n\t\t\t\t     sizeof(dev->card_label);\n\tint device_nr =\n\t\t((struct v4l2loopback_private *)video_get_drvdata(dev->vdev))\n\t\t\t->device_nr;\n\t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n\n\tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n\tsnprintf(cap->card, labellen, dev->card_label);\n\tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n\t\t \"platform:v4l2loopback-%03d\", device_nr);\n\n#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 1, 0)\n\t/* since 3.1.0, the v4l2-core system is supposed to set the version */\n\tcap->version = V4L2LOOPBACK_VERSION_CODE;\n#endif\n\n#ifdef V4L2_CAP_VIDEO_M2M\n\tcapabilities |= V4L2_CAP_VIDEO_M2M;\n#endif /* V4L2_CAP_VIDEO_M2M */\n\n\tif (dev->announce_all_caps) {\n\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_OUTPUT;\n\t} else {\n\t\tif (dev->ready_for_capture) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE;\n\t\t}\n\t\tif (dev->ready_for_output) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_OUTPUT;\n\t\t}\n\t}\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 7, 0)\n\tdev->vdev->device_caps =\n#endif /* >=linux-4.7.0 */\n\t\tcap->device_caps = cap->capabilities = capabilities;\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 3, 0)\n\tcap->capabilities |= V4L2_CAP_DEVICE_CAPS;\n#endif\n\n\tmemset(cap->reserved, 0, sizeof(cap->reserved));\n\treturn 0;\n}", "func_hash": 275249025528691740507199336736969659771, "file_name": "v4l2loopback.c", "file_hash": 113113223463037707180278012059265756483, "cwe": ["CWE-134"], "cve": "CVE-2022-2652", "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2652", "file_path": "v4l2loopback.c"}
{"idx": 225383, "project": "v4l2loopback", "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd", "project_url": "https://github.com/umlaeute/v4l2loopback", "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd", "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134", "target": 0, "func": "static int vidioc_querycap(struct file *file, void *priv,\n\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct v4l2_loopback_device *dev = v4l2loopback_getdevice(file);\n\tint labellen = (sizeof(cap->card) < sizeof(dev->card_label)) ?\n\t\t\t       sizeof(cap->card) :\n\t\t\t\t     sizeof(dev->card_label);\n\tint device_nr =\n\t\t((struct v4l2loopback_private *)video_get_drvdata(dev->vdev))\n\t\t\t->device_nr;\n\t__u32 capabilities = V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;\n\n\tstrlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver));\n\tsnprintf(cap->card, labellen, \"%s\", dev->card_label);\n\tsnprintf(cap->bus_info, sizeof(cap->bus_info),\n\t\t \"platform:v4l2loopback-%03d\", device_nr);\n\n#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 1, 0)\n\t/* since 3.1.0, the v4l2-core system is supposed to set the version */\n\tcap->version = V4L2LOOPBACK_VERSION_CODE;\n#endif\n\n#ifdef V4L2_CAP_VIDEO_M2M\n\tcapabilities |= V4L2_CAP_VIDEO_M2M;\n#endif /* V4L2_CAP_VIDEO_M2M */\n\n\tif (dev->announce_all_caps) {\n\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_OUTPUT;\n\t} else {\n\t\tif (dev->ready_for_capture) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_CAPTURE;\n\t\t}\n\t\tif (dev->ready_for_output) {\n\t\t\tcapabilities |= V4L2_CAP_VIDEO_OUTPUT;\n\t\t}\n\t}\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 7, 0)\n\tdev->vdev->device_caps =\n#endif /* >=linux-4.7.0 */\n\t\tcap->device_caps = cap->capabilities = capabilities;\n\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 3, 0)\n\tcap->capabilities |= V4L2_CAP_DEVICE_CAPS;\n#endif\n\n\tmemset(cap->reserved, 0, sizeof(cap->reserved));\n\treturn 0;\n}", "func_hash": 178769376518603723181418371440757147493, "file_name": "v4l2loopback.c", "file_hash": 138252299614112344688826607831650943411, "cwe": ["CWE-134"], "cve": "CVE-2022-2652", "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-2652", "file_path": "v4l2loopback.c"}
{"idx": 195399, "project": "tensorflow", "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf", "commit_message": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "target": 1, "func": "bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n                               const NodeDef& node) {\n  if ((IsIdentity(node) || IsIdentityNSingleInput(node)) &&\n      node.input_size() > 0) {\n    TensorId tensor_id = ParseTensorName(node.input(0));\n    if (IsTensorIdControlling(tensor_id)) {\n      return false;\n    }\n\n    NodeDef* input_node = graph.GetNode(tensor_id.node());\n    return IsSwitch(*input_node);\n  }\n  return false;\n}", "func_hash": 313619660222966312087557415210995637728, "file_name": "mutable_graph_view.cc", "file_hash": 11824580899895481141820753687530297202, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589", "file_path": "tensorflow/core/grappler/mutable_graph_view.cc"}
{"idx": 225473, "project": "tensorflow", "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf", "commit_message": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "target": 0, "func": "bool IsIdentityConsumingSwitch(const MutableGraphView& graph,\n                               const NodeDef& node) {\n  if ((IsIdentity(node) || IsIdentityNSingleInput(node)) &&\n      node.input_size() > 0) {\n    TensorId tensor_id = ParseTensorName(node.input(0));\n    if (IsTensorIdControlling(tensor_id)) {\n      return false;\n    }\n\n    NodeDef* input_node = graph.GetNode(tensor_id.node());\n    if (input_node == nullptr) {\n      return false;\n    }\n    return IsSwitch(*input_node);\n  }\n  return false;\n}", "func_hash": 186036134407007049668950369044144546274, "file_name": "mutable_graph_view.cc", "file_hash": 183902084895507336616240181892029435869, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23589", "file_path": "tensorflow/core/grappler/mutable_graph_view.cc"}
{"idx": 195402, "project": "tensorflow", "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b", "target": 1, "func": "int TfLiteIntArrayGetSizeInBytes(int size) {\n  static TfLiteIntArray dummy;\n\n  int computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n#if defined(_MSC_VER)\n  // Context for why this is needed is in http://b/189926408#comment21\n  computed_size -= sizeof(dummy.data[0]);\n#endif\n  return computed_size;\n}", "func_hash": 331591508579524081379498872268044006906, "file_name": "common.c", "file_hash": 227108095659128555473924245568634074234, "cwe": ["CWE-190"], "cve": "CVE-2022-23558", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558", "file_path": "tensorflow/lite/c/common.c"}
{"idx": 225547, "project": "tensorflow", "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b", "target": 0, "func": "size_t TfLiteIntArrayGetSizeInBytes(int size) {\n  static TfLiteIntArray dummy;\n\n  size_t computed_size = sizeof(dummy) + sizeof(dummy.data[0]) * size;\n#if defined(_MSC_VER)\n  // Context for why this is needed is in http://b/189926408#comment21\n  computed_size -= sizeof(dummy.data[0]);\n#endif\n  return computed_size;\n}", "func_hash": 132887753534839828949485916264712284974, "file_name": "common.c", "file_hash": 141963346575108043523158725755967478163, "cwe": ["CWE-190"], "cve": "CVE-2022-23558", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558", "file_path": "tensorflow/lite/c/common.c"}
{"idx": 195403, "project": "tensorflow", "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b", "target": 1, "func": "TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n  int alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n  if (alloc_size <= 0) return NULL;\n  TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n  if (!ret) return ret;\n  ret->size = size;\n  return ret;\n}", "func_hash": 64742066879088615123277599572040485093, "file_name": "common.c", "file_hash": 227108095659128555473924245568634074234, "cwe": ["CWE-190"], "cve": "CVE-2022-23558", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558", "file_path": "tensorflow/lite/c/common.c"}
{"idx": 225552, "project": "tensorflow", "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b", "target": 0, "func": "TfLiteIntArray* TfLiteIntArrayCreate(int size) {\n  size_t alloc_size = TfLiteIntArrayGetSizeInBytes(size);\n  if (alloc_size <= 0) return NULL;\n  TfLiteIntArray* ret = (TfLiteIntArray*)malloc(alloc_size);\n  if (!ret) return ret;\n  ret->size = size;\n  return ret;\n}", "func_hash": 125057143458607684207882855383643521977, "file_name": "common.c", "file_hash": 141963346575108043523158725755967478163, "cwe": ["CWE-190"], "cve": "CVE-2022-23558", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23558", "file_path": "tensorflow/lite/c/common.c"}
{"idx": 195404, "project": "tensorflow", "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "commit_message": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163", "target": 1, "func": "  void Compute(OpKernelContext* context) override {\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    constexpr int tensor_in_and_out_dims = 4;\n\n    const Tensor& tensor_in = context->input(0);\n    OP_REQUIRES(context, tensor_in.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n    std::vector<int> input_size(tensor_in_and_out_dims);\n    std::vector<int> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    // Output size.\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      // This must match the same logic in the shape function in\n      // core/ops/nn_ops.cc.\n      output_size[i] =\n          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));\n      DCHECK_GT(output_size[i], 0);\n    }\n\n    // Generate pooling sequence.\n    std::vector<int64_t> height_cum_seq;\n    std::vector<int64_t> width_cum_seq;\n    GuardedPhiloxRandom generator;\n    generator.Init(seed_, seed2_);\n    height_cum_seq = GeneratePoolingSequence(input_size[1], output_size[1],\n                                             &generator, pseudo_random_);\n    width_cum_seq = GeneratePoolingSequence(input_size[2], output_size[2],\n                                            &generator, pseudo_random_);\n\n    // Prepare output.\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0,\n                                TensorShape({output_size[0], output_size[1],\n                                             output_size[2], output_size[3]}),\n                                &output_tensor));\n    Tensor* output_height_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            1, TensorShape({static_cast<int64_t>(height_cum_seq.size())}),\n            &output_height_seq_tensor));\n    Tensor* output_width_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            2, TensorShape({static_cast<int64_t>(width_cum_seq.size())}),\n            &output_width_seq_tensor));\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), input_size[3],\n                               input_size[2] * input_size[1] * input_size[0]);\n\n    EigenMatrixMap out_mat(output_tensor->flat<T>().data(), output_size[3],\n                           output_size[2] * output_size[1] * output_size[0]);\n\n    // Initializes the output tensor with MIN<T>.\n    output_tensor->flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto output_height_seq_flat = output_height_seq_tensor->flat<int64_t>();\n    auto output_width_seq_flat = output_width_seq_tensor->flat<int64_t>();\n\n    // Set output tensors.\n    for (int i = 0; i < height_cum_seq.size(); ++i) {\n      output_height_seq_flat(i) = height_cum_seq[i];\n    }\n\n    for (int i = 0; i < width_cum_seq.size(); ++i) {\n      output_width_seq_flat(i) = width_cum_seq[i];\n    }\n\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_cum_seq.size() - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_cum_seq[hs];\n        int64_t height_end =\n            overlapping_ ? height_cum_seq[hs + 1] : height_cum_seq[hs + 1] - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_cum_seq.size() - 1; ++ws) {\n          const int64_t out_offset =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_cum_seq[ws];\n          int64_t width_end =\n              overlapping_ ? width_cum_seq[ws + 1] : width_cum_seq[ws + 1] - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_offset =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              out_mat.col(out_offset) =\n                  out_mat.col(out_offset).cwiseMax(in_mat.col(in_offset));\n            }\n          }\n        }\n      }\n    }\n  }", "func_hash": 329653208386215793548956261636203970964, "file_name": "fractional_max_pool_op.cc", "file_hash": 38088244475067119710916669469162645605, "cwe": ["CWE-369"], "cve": "CVE-2022-21735", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21735", "file_path": "tensorflow/core/kernels/fractional_max_pool_op.cc"}
{"idx": 225563, "project": "tensorflow", "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "commit_message": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163", "target": 0, "func": "  void Compute(OpKernelContext* context) override {\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    constexpr int tensor_in_and_out_dims = 4;\n\n    const Tensor& tensor_in = context->input(0);\n    OP_REQUIRES(context, tensor_in.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n    std::vector<int> input_size(tensor_in_and_out_dims);\n    std::vector<int> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n\n      OP_REQUIRES(\n          context, input_size[i] >= pooling_ratio_[i],\n          errors::InvalidArgument(\"Pooling ratio is higher than input \"\n                                  \"dimension size for dimension \",\n                                  i, \". Input dim size: \", input_size[i],\n                                  \" pooling ratio: \", pooling_ratio_[i]));\n    }\n    // Output size.\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      // This must match the same logic in the shape function in\n      // core/ops/nn_ops.cc.\n      output_size[i] =\n          static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));\n      DCHECK_GT(output_size[i], 0);\n    }\n\n    // Generate pooling sequence.\n    std::vector<int64_t> height_cum_seq;\n    std::vector<int64_t> width_cum_seq;\n    GuardedPhiloxRandom generator;\n    generator.Init(seed_, seed2_);\n    height_cum_seq = GeneratePoolingSequence(input_size[1], output_size[1],\n                                             &generator, pseudo_random_);\n    width_cum_seq = GeneratePoolingSequence(input_size[2], output_size[2],\n                                            &generator, pseudo_random_);\n\n    // Prepare output.\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0,\n                                TensorShape({output_size[0], output_size[1],\n                                             output_size[2], output_size[3]}),\n                                &output_tensor));\n    Tensor* output_height_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            1, TensorShape({static_cast<int64_t>(height_cum_seq.size())}),\n            &output_height_seq_tensor));\n    Tensor* output_width_seq_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            2, TensorShape({static_cast<int64_t>(width_cum_seq.size())}),\n            &output_width_seq_tensor));\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), input_size[3],\n                               input_size[2] * input_size[1] * input_size[0]);\n\n    EigenMatrixMap out_mat(output_tensor->flat<T>().data(), output_size[3],\n                           output_size[2] * output_size[1] * output_size[0]);\n\n    // Initializes the output tensor with MIN<T>.\n    output_tensor->flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto output_height_seq_flat = output_height_seq_tensor->flat<int64_t>();\n    auto output_width_seq_flat = output_width_seq_tensor->flat<int64_t>();\n\n    // Set output tensors.\n    for (int i = 0; i < height_cum_seq.size(); ++i) {\n      output_height_seq_flat(i) = height_cum_seq[i];\n    }\n\n    for (int i = 0; i < width_cum_seq.size(); ++i) {\n      output_width_seq_flat(i) = width_cum_seq[i];\n    }\n\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_cum_seq.size() - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_cum_seq[hs];\n        int64_t height_end =\n            overlapping_ ? height_cum_seq[hs + 1] : height_cum_seq[hs + 1] - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_cum_seq.size() - 1; ++ws) {\n          const int64_t out_offset =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_cum_seq[ws];\n          int64_t width_end =\n              overlapping_ ? width_cum_seq[ws + 1] : width_cum_seq[ws + 1] - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_offset =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              out_mat.col(out_offset) =\n                  out_mat.col(out_offset).cwiseMax(in_mat.col(in_offset));\n            }\n          }\n        }\n      }\n    }\n  }", "func_hash": 116843352571391588046661724660779526999, "file_name": "fractional_max_pool_op.cc", "file_hash": 167950097941581661250535285107700244508, "cwe": ["CWE-369"], "cve": "CVE-2022-21735", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21735", "file_path": "tensorflow/core/kernels/fractional_max_pool_op.cc"}
{"idx": 195405, "project": "ImageMagick6", "commit_id": "29c8abce0da56b536542f76a9ddfebdaab5b2943", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/29c8abce0da56b536542f76a9ddfebdaab5b2943", "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/4986", "target": 1, "func": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MaxTextExtent],\n    *density,\n    filename[MaxTextExtent],\n    geometry[MaxTextExtent],\n    *options,\n    input_filename[MaxTextExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->x_resolution == 0.0) || (image->y_resolution == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->x_resolution=geometry_info.rho;\n      image->y_resolution=image->x_resolution;\n      if ((flags & SigmaValue) != 0)\n        image->y_resolution=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MaxTextExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MaxTextExtent,\"%gx%g\",\n    image->x_resolution,image->y_resolution);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor((double) page.width*image->x_resolution/delta.x+\n    0.5);\n  page.height=(size_t) floor((double) page.height*image->y_resolution/delta.y+\n    0.5);\n  (void) FormatLocaleString(options,MaxTextExtent,\"-g%.20gx%.20g \",(double)\n     page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MaxTextExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MaxTextExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MaxTextExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MaxTextExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,&image->exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MaxTextExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->x_resolution/2.0;\n        image->magick_rows*=image->y_resolution/2.0;\n        image->columns*=image->x_resolution/2.0;\n        image->rows*=image->y_resolution/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}", "func_hash": 285956846610376765198872183403915882061, "file_name": "pcl.c", "file_hash": 338547174937023730341471137685130471169, "cwe": ["CWE-190"], "cve": "CVE-2022-32546", "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546", "file_path": "coders/pcl.c"}
{"idx": 225566, "project": "ImageMagick6", "commit_id": "29c8abce0da56b536542f76a9ddfebdaab5b2943", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/29c8abce0da56b536542f76a9ddfebdaab5b2943", "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/4986", "target": 0, "func": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MaxTextExtent],\n    *density,\n    filename[MaxTextExtent],\n    geometry[MaxTextExtent],\n    *options,\n    input_filename[MaxTextExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  int\n    c;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->x_resolution == 0.0) || (image->y_resolution == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->x_resolution=geometry_info.rho;\n      image->y_resolution=image->x_resolution;\n      if ((flags & SigmaValue) != 0)\n        image->y_resolution=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MaxTextExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n    height=(size_t) CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MaxTextExtent,\"%gx%g\",\n    image->x_resolution,image->y_resolution);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor((double) page.width*image->x_resolution/delta.x+\n    0.5);\n  page.height=(size_t) floor((double) page.height*image->y_resolution/delta.y+\n    0.5);\n  (void) FormatLocaleString(options,MaxTextExtent,\"-g%.20gx%.20g \",(double)\n     page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MaxTextExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MaxTextExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MaxTextExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MaxTextExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,&image->exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MaxTextExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->x_resolution/2.0;\n        image->magick_rows*=image->y_resolution/2.0;\n        image->columns*=image->x_resolution/2.0;\n        image->rows*=image->y_resolution/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}", "func_hash": 83929363874861063792960158581169163951, "file_name": "pcl.c", "file_hash": 19401947442598835469700605981025281430, "cwe": ["CWE-190"], "cve": "CVE-2022-32546", "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned long' at coders/pcl.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-32546", "file_path": "coders/pcl.c"}
{"idx": 195409, "project": "gpac", "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "commit_message": "fixed #2092", "target": 1, "func": "\nvoid gitn_box_del(GF_Box *s)\n{\n\tu32 i;\n\tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n\tif (ptr == NULL) return;\n\tfor (i=0; i<ptr->nb_entries; i++) {\n\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n\t}\n\tif (ptr->entries) gf_free(ptr->entries);\n\tgf_free(ptr);", "func_hash": 37642310110270321687625000100653046485, "file_name": "box_code_base.c", "file_hash": 212802147696207025803784466432150384318, "cwe": ["CWE-476"], "cve": "CVE-2021-4043", "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4043", "file_path": "src/isomedia/box_code_base.c"}
{"idx": 226029, "project": "gpac", "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "commit_message": "fixed #2092", "target": 0, "func": "\nvoid gitn_box_del(GF_Box *s)\n{\n\tu32 i;\n\tGroupIdToNameBox *ptr = (GroupIdToNameBox *)s;\n\tif (ptr == NULL) return;\n\tif (ptr->entries) {\n\t\tfor (i=0; i<ptr->nb_entries; i++) {\n\t\t\tif (ptr->entries[i].name) gf_free(ptr->entries[i].name);\n\t\t}\n\t\tgf_free(ptr->entries);\n\t}\n\tgf_free(ptr);", "func_hash": 265612189453593240220286582640125308421, "file_name": "box_code_base.c", "file_hash": 49851003819063672326837979869211393199, "cwe": ["CWE-476"], "cve": "CVE-2021-4043", "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4043", "file_path": "src/isomedia/box_code_base.c"}
{"idx": 195410, "project": "tensorflow", "commit_id": "965b97e4a9650495cda5a8c210ef6684b4b9eceb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/965b97e4a9650495cda5a8c210ef6684b4b9eceb", "commit_message": "Properly validate sparse tensor in `SparseTensorSliceDataset`\n\nExisting validation was incomplete.\n\nPiperOrigin-RevId: 415375048\nChange-Id: I14cd18f29ede73286f3ffac35171bd15828997e9", "target": 1, "func": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n\n    const auto num_indices = indices->NumElements();\n    const auto num_values = values->NumElements();\n    if (num_indices == 0 || num_values == 0) {\n      OP_REQUIRES(ctx, num_indices == num_values,\n                  errors::InvalidArgument(\n                      \"If indices or values are empty, the other one must also \"\n                      \"be. Got indices of shape \",\n                      indices->shape().DebugString(), \" and values of shape \",\n                      values->shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64_t>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64_t, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64_t>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }", "func_hash": 232798786480644222523895580158118045723, "file_name": "sparse_tensor_slice_dataset_op.cc", "file_hash": 20179985196620256343354076777909821072, "cwe": ["CWE-476"], "cve": "CVE-2022-21736", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseTensorSliceDataset` has an undefined behavior: under certain condition it can be made to dereference a `nullptr` value. The 3 input arguments to `SparseTensorSliceDataset` represent a sparse tensor. However, there are some preconditions that these arguments must satisfy but these are not validated in the implementation. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21736", "file_path": "tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc"}
{"idx": 226433, "project": "tensorflow", "commit_id": "965b97e4a9650495cda5a8c210ef6684b4b9eceb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/965b97e4a9650495cda5a8c210ef6684b4b9eceb", "commit_message": "Properly validate sparse tensor in `SparseTensorSliceDataset`\n\nExisting validation was incomplete.\n\nPiperOrigin-RevId: 415375048\nChange-Id: I14cd18f29ede73286f3ffac35171bd15828997e9", "target": 0, "func": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\"Input indices must be a matrix. Got: \",\n                                        indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n                                        values->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n                                        dense_shape->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values->shape().dim_size(0) == indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            values->shape().dim_size(0),\n            \" values, indices shape: \", indices->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, dense_shape->shape().dim_size(0) == indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", dense_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \", indices->shape().DebugString()));\n    OP_REQUIRES(ctx, dense_shape->NumElements() > 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64_t>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64_t, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64_t>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }", "func_hash": 227797014623034241967270311347340556143, "file_name": "sparse_tensor_slice_dataset_op.cc", "file_hash": 223168035118292217298610217555690212472, "cwe": ["CWE-476"], "cve": "CVE-2022-21736", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseTensorSliceDataset` has an undefined behavior: under certain condition it can be made to dereference a `nullptr` value. The 3 input arguments to `SparseTensorSliceDataset` represent a sparse tensor. However, there are some preconditions that these arguments must satisfy but these are not validated in the implementation. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21736", "file_path": "tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc"}
