{"idx": 195028, "project": "tensorflow", "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9", "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b", "target": 1, "func": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }", "func_hash": 67814436772398534036630434647873886403, "file_name": "decode_image_op.cc", "file_hash": 283519422605879710361255065504339887165, "cwe": ["CWE-401"], "cve": "CVE-2022-23585", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23585", "file_path": "tensorflow/core/kernels/image/decode_image_op.cc"}
{"idx": 220168, "project": "tensorflow", "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9", "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b", "target": 0, "func": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // If we reach this point, then there is data in `decode` which must be\n    // freed by the time we end execution in this function. We cannot call\n    // `png::CommonFreeDecode()` before an `OP_REQUIRES` because if\n    // `OP_REQUIRES` constraint is satisfied then the data would be freed\n    // prematurely. Instead, let's use a `Cleanup` object.\n    auto cleanup = gtl::MakeCleanup([&decode]() {\n      std::cerr << \"Cleanup called...\\n\";\n      png::CommonFreeDecode(&decode);\n    });\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }", "func_hash": 183944225263640230240348550837981668390, "file_name": "decode_image_op.cc", "file_hash": 140340118421060830961361158847913918052, "cwe": ["CWE-401"], "cve": "CVE-2022-23585", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23585", "file_path": "tensorflow/core/kernels/image/decode_image_op.cc"}
{"idx": 195029, "project": "tensorflow", "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c99d98cd189839dcf51aee94e7437b54b31f8abd", "commit_message": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24", "target": 1, "func": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        DCHECK(ix < node_t.args_size())\n            << \"input \" << i << \" should have an output \" << ix\n            << \" but instead only has \" << node_t.args_size()\n            << \" outputs: \" << node_t.DebugString();\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}", "func_hash": 285691869172413131662679092330979772991, "file_name": "graph.cc", "file_hash": 172099243927919341591512227523808328051, "cwe": ["CWE-125"], "cve": "CVE-2022-23592", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23592", "file_path": "tensorflow/core/graph/graph.cc"}
{"idx": 220201, "project": "tensorflow", "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c99d98cd189839dcf51aee94e7437b54b31f8abd", "commit_message": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24", "target": 0, "func": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        if (ix >= node_t.args_size()) {\n          LOG(WARNING) << name() << \" has bad type information: input \" << i\n                       << \" should have an output \" << ix\n                       << \" but instead only has \" << node_t.args_size()\n                       << \" outputs: \" << node_t.DebugString()\n                       << \"\\nThis indicates either \"\n                          \"a bug in op registration or a corrupted graph.\";\n          ClearTypeInfo();\n          return;\n        }\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}", "func_hash": 208747443072046126472677622190312892089, "file_name": "graph.cc", "file_hash": 252683577168046425270820661985512954953, "cwe": ["CWE-125"], "cve": "CVE-2022-23592", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23592", "file_path": "tensorflow/core/graph/graph.cc"}
{"idx": 195038, "project": "mruby", "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/27d1e0132a0804581dca28df042e7047fd27eaa8", "commit_message": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.", "target": 1, "func": "mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n{\n  struct RArray *a = mrb_ary_ptr(self);\n  mrb_int len = ARY_LEN(a);\n  mrb_int n;\n  mrb_value val;\n\n  if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n    return mrb_ary_shift(mrb, self);\n  };\n  ary_modify_check(mrb, a);\n  if (len == 0 || n == 0) return mrb_ary_new(mrb);\n  if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n  if (n > len) n = len;\n  val = mrb_ary_new_from_values(mrb, n, ARY_PTR(a));\n  if (ARY_SHARED_P(a)) {\n  L_SHIFT:\n    a->as.heap.ptr+=n;\n    a->as.heap.len-=n;\n    return val;\n  }\n  if (len > ARY_SHIFT_SHARED_MIN) {\n    ary_make_shared(mrb, a);\n    goto L_SHIFT;\n  }\n  else if (len == n) {\n    ARY_SET_LEN(a, 0);\n  }\n  else {\n    mrb_value *ptr = ARY_PTR(a);\n    mrb_int size = len-n;\n\n    while (size--) {\n      *ptr = *(ptr+n);\n      ++ptr;\n    }\n    ARY_SET_LEN(a, len-n);\n  }\n  return val;\n}", "func_hash": 88987793594626442814152795226896894437, "file_name": "array.c", "file_hash": 131985777969528154957566525214352537878, "cwe": ["CWE-476"], "cve": "CVE-2021-4188", "cve_desc": "mruby is vulnerable to NULL Pointer Dereference", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-4188", "file_path": "src/array.c"}
