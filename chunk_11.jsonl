{"idx": 224153, "project": "tensorflow", "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b", "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1", "target": 0, "func": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // Prevent copying uninitialized data, to solve harder to debug undefined\n    // behaviors that cannot be traced back to the original tensor.\n    OP_REQUIRES(\n        context, rhs.IsInitialized(),\n        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }", "func_hash": 305037740106398797533289727050001288809, "file_name": "assign_op.h", "file_hash": 227740622376075800348272805227748641889, "cwe": ["CWE-908"], "cve": "CVE-2022-23573", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-23573", "file_path": "tensorflow/core/kernels/assign_op.h"}
{"idx": 195294, "project": "tensorflow", "commit_id": "f57315566d7094f322b784947093406c2aea0d7d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f57315566d7094f322b784947093406c2aea0d7d", "commit_message": "Add a check for Key being scalar tensor for MapStage and OrderedMapStage ops.\n\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\n\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\n\nPiperOrigin-RevId: 413822112\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2e", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }", "func_hash": 121343016950748954777477429164526353429, "file_name": "map_stage_op.cc", "file_hash": 156634864064326951745718193254274952325, "cwe": ["CWE-843"], "cve": "CVE-2022-21734", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `MapStage` is vulnerable a `CHECK`-fail if the key tensor is not a scalar. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21734", "file_path": "tensorflow/core/kernels/map_stage_op.cc"}
{"idx": 224181, "project": "tensorflow", "commit_id": "f57315566d7094f322b784947093406c2aea0d7d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f57315566d7094f322b784947093406c2aea0d7d", "commit_message": "Add a check for Key being scalar tensor for MapStage and OrderedMapStage ops.\n\nAccording to documentation[1][2], key must be int64 value, but this wasn't enforced and the ops would fail with check failure for non-scalar key value.\n\n[1]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/ordered-map-stage\n[2]https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/map-stage\n\nPiperOrigin-RevId: 413822112\nChange-Id: I9d118faf990e6361900aa32272eff486ad9f0e2e", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    OP_REQUIRES(ctx, key_tensor->NumElements() == 1,\n                errors::InvalidArgument(\n                    \"key must be an int64 scalar, got tensor with shape: \",\n                    key_tensor->shape()));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }", "func_hash": 155761287933118551217083530225572870599, "file_name": "map_stage_op.cc", "file_hash": 98786060535014659477894352363015597620, "cwe": ["CWE-843"], "cve": "CVE-2022-21734", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `MapStage` is vulnerable a `CHECK`-fail if the key tensor is not a scalar. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-21734", "file_path": "tensorflow/core/kernels/map_stage_op.cc"}
{"idx": 195295, "project": "mruby", "commit_id": "c8c083cb750606b2da81582cd8e43b442bb143e6", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/c8c083cb750606b2da81582cd8e43b442bb143e6", "commit_message": "codegen.c: need to pack argument when `n==13` too.\n\nBecause we have extra 2 arguments coming (kw and rhs).", "target": 1, "func": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}", "func_hash": 41954898060187653186067747247923282324, "file_name": "codegen.c", "file_hash": 166306575091061367964033452033729491771, "cwe": ["CWE-125"], "cve": "CVE-2022-1276", "cve_desc": "Out-of-bounds Read in mrb_get_args in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1276", "file_path": "mrbgems/mruby-compiler/core/codegen.c"}
{"idx": 224192, "project": "mruby", "commit_id": "c8c083cb750606b2da81582cd8e43b442bb143e6", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/c8c083cb750606b2da81582cd8e43b442bb143e6", "commit_message": "codegen.c: need to pack argument when `n==13` too.\n\nBecause we have extra 2 arguments coming (kw and rhs).", "target": 0, "func": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 13 || n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}", "func_hash": 72719402367551467019466616883888506134, "file_name": "codegen.c", "file_hash": 21664036215001583958906059719703447460, "cwe": ["CWE-125"], "cve": "CVE-2022-1276", "cve_desc": "Out-of-bounds Read in mrb_get_args in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2022-1276", "file_path": "mrbgems/mruby-compiler/core/codegen.c"}
