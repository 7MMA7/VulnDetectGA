{"idx": 197239, "project": "tensorflow", "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9", "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      size_t depth = input_min_vec.NumElements();\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n      OP_REQUIRES(\n          ctx, input_min_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n                                  depth, \" was \", input_min_vec.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_vec.dim_size(0) == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.dim_size(0)));\n\n      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }", "func_hash": 324241400481110766657474950076141174434, "file_name": "mkl_requantize_per_channel_op.cc", "file_hash": 251676487738280920031977890166955496760, "cwe": ["CWE-20"], "cve": "CVE-2021-37665", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665", "file_path": "tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc"}
{"idx": 255787, "project": "tensorflow", "commit_id": "203214568f5bc237603dbab6e1fd389f1572f5c9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9", "commit_message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      size_t depth = input_min_vec.NumElements();\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      OP_REQUIRES(\n          ctx, input_max_vec.NumElements() == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.NumElements()));\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      if (out_type_ == DT_QINT8) {\n        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n                    errors::InvalidArgument(\n                        \"If out_type is QINT8, requested_output_max must be \"\n                        \"non negative, got \",\n                        input_requested_min_float));\n      }\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }", "func_hash": 201878661619754288848170161353082339443, "file_name": "mkl_requantize_per_channel_op.cc", "file_hash": 305646743359625407590451757209165637710, "cwe": ["CWE-20"], "cve": "CVE-2021-37665", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-37665", "file_path": "tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc"}
{"idx": 197262, "project": "tensorflow", "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "commit_message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d", "target": 1, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }", "func_hash": 281398484697111962957982643274603954439, "file_name": "sparse_matmul_op.cc", "file_hash": 108103579052154515117474451671828260520, "cwe": ["CWE-125"], "cve": "CVE-2021-41219", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41219", "file_path": "tensorflow/core/kernels/sparse_matmul_op.cc"}
{"idx": 256138, "project": "tensorflow", "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "commit_message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d", "target": 0, "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n                errors::InvalidArgument(\n                    \"Matrix dimensions cannot be negative: a: \",\n                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    // Return early if at least one of the output dimension size is 0.\n    if (m == 0 || n == 0) {\n      return;\n    }\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }", "func_hash": 324184408352079066865576775824843839346, "file_name": "sparse_matmul_op.cc", "file_hash": 60640554660394807532445387638343536122, "cwe": ["CWE-125"], "cve": "CVE-2021-41219", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "nvd_url": "https://nvd.nist.gov/vuln/detail/CVE-2021-41219", "file_path": "tensorflow/core/kernels/sparse_matmul_op.cc"}
